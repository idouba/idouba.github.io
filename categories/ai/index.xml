<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on 爱豆吧！</title>
    <link>https://idouba.com/categories/ai/</link>
    <description>Recent content in AI on 爱豆吧！</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>浙ICP备18050493号-1 浙公网安备 33010802006262号</copyright>
    <lastBuildDate>Fri, 07 Feb 2025 15:32:08 +0000</lastBuildDate><atom:link href="https://idouba.com/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>云原生工程师入坑AI深度学习系列（二）：给昌子解释DeepSeek的模型蒸馏</title>
      <link>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-make-changzi-understand-model-distillation-of-deepseek/</link>
      <pubDate>Fri, 07 Feb 2025 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-make-changzi-understand-model-distillation-of-deepseek/</guid>
      <description>
        
          
            背景 昨天，昌子突然微信问我“DeepSeek咋用”。回复“你不好好焊钢轨，打听这玩意儿干啥”。小哥说我就想闹明白我们中国这个技术是不是像有些短视频里说的抄了老美的。不用问，这小哥是过年在家闲的刷到OpenAI可能起诉DeepSeek的新闻了。虽然给他说Altman在咱们大年初六好已经承认不打算起诉了，但是说服昌子小哥还是费了不少口舌。为了说明没有抄，模型蒸馏的话题就绕不过。在沟通中临时起意提到小哥咱们很多年前的一段趣事，居然说明白了。觉得很有意思，就顺手归档下。
模型蒸馏概念初体验 首先，DeepSeek关于模型蒸馏的定义是这样的：
模型蒸馏通过将复杂模型（教师模型）的知识转移到简单模型（学生模型）中，实现模型压缩、加速推理并保持性能，适用于多种资源受限的场景。
是不是不太好理解，用咱们共同的一段经历做个不算太恰当的类别，可能更好理解。
还记得咱们上中专那会儿，正是十五六岁贪玩的年龄，那学期好像是安排去永济电机厂还是洛阳重机厂实习，我们疯玩了几个月，你总带哥去厂子的花园里捞鱼。临期末有一门考试好像是《公差与配合》，你和老七担心考不过，总磨着我给你俩补课。
其实只要自己老老实实地把课本过一遍，课后题做几遍，你俩保证都妥妥考得过。但你俩还是选择了个山寨老师补课。对应到模型训练过程，你俩作为学生模型没有选择从头看书、自己做题这种完全从头开始训练的方式，而是模仿学习一种你们信任的教师模型来获取知识。
但是你俩这个过程还是学习的过程，并没有直接抄哥这个山寨老师的。你们得自己学过去，然后期末考试时候才能考出来。正好对应模型训练和推理的过程。我们详细捋下咱们当时怎么干的。
一般你和老七会拿一道题目过来，让我给出我的答案。当然每道题，你们都是自己做过的。没记错的话，你们开始哪些答案都是凭着感觉蒙的 。然后我们会讨论题目，如最小最大实体尺寸对应于孔和轴分别是他们的最大极限尺寸还是最小极限尺寸。你们相信哥的答案一般是对的答案，在讨论过程中调整、形成自己的思考方式。看上去是哥在纠正你们，实际是你们在自己思考，接近你们心目中这个山寨老师对这段知识点的处理。
反复经历这个过程，然后你俩就越来越自信。最后，你们就出师了。自己可以独立判断，得出答案。尤其是老七，练习的可溜了。以至于后面他再磨我的时候，我非常坚定地说：“你都学到这个程度了，如果再考不过，我请你哥俩吃饭”。结果，结果你还记得吗？这么多年来每次见面喝酒你光记得有次学校附近有个叫双虎的小饭馆我们花生米、土豆丝、老白干搞得可爽了，背景还记得不？让哥这段讲完给你串起来，先不岔开，让哥再尝试给你讲点机械专业以外的新鲜东西。
在这个过程里，对应模型蒸馏的术语。哥这个山寨老师的叫教师模型，你俩那叫学生模型。一般教师模型复杂，学生模型简单。对应到咱们的实践，哥当时可是老老实实地把课本学过一遍，虽然跟你们玩，但是老师上课讲的都认真地听了的。所以教师模型里不只是塞了那些题，还塞了更多。而你俩呢，课本基本上是不看的，在你们那里课本都是些不一定必要的信息，你们只想学习满足期末考试需要的知识。即学生模型更简洁，模型蒸馏过程去掉了这些多余部分，让学生模型更简单、更高效地提供能力。
对应的一般教师模型参数多，学生模型参数少。记得开始拿到一个题目时，哥给你们讲的时候啰啰嗦嗦说一堆课本里的背景原理，然后推出结果，而后来我们练的根据简单的题目特征，就能找到对的答案。当时你经常说的一句话是“哥们记不清，简单点，好理解”。差不多对应到模型蒸馏，就是简化去掉无用参数，提高效率的同时，模型能力并没有下降很多。
通过这种有针对性的练习，学习老师模型总结过的知识，更有针对性，因此也更高效。你们用更简单的模型，通过更低的成本，但更高的效率达到了很高的模型质量。到考试前那阵子，特别是你，不止比我墨迹白天推导要快，有些时候也更准。这就是你们根据各自的逻辑理解学习的成果。
那段时间，咱们仨人一直鬼混一起，也就是一直在一起学。你和老七顶多就是过会儿拿书过来问我这个题我的答案是啥，为啥这样想的，然后你的答案是啥，为啥不一样。从外面行为看，我们整个状态都是学习的状态，认真学习的状态，你理也就每学期这时候有个学习的状态。从内在看，你俩是自己脑子在思考，在各自脑子里构造各自的模型。对于同一个题目，准确说是一块知识点，我这个山寨老师咋想的，你们咋想的，能得到尽量一致的答案。我没有把我的模型给你们抄，也没有途径啊，抄不着。顶多从这过程获取了一些重要知识，帮助你在考试时能同样方式去思考，选到一个对的答案。
我讲的都一样，你俩各自独立地在思考学习，各自在自己脑子里形成对《公差与配合》独立的思考。你和老七学到的也不一样，最终期末考试时在实际的测试数据集上验证，结果大不相同。结果留个彩蛋在后面。同样的教师模型，同样的训练过程，两个不同的学生模型，学到的效果不同。这也反证了，如果是抄，你俩应该抄的是一样的才对。同样的模型蒸馏，也是学，不是抄。只是学到了行为和能力，抄不到内部结构和实现。
模型蒸馏流程 上面简单类别，我们理解个概念：模型蒸馏是什么。下面简单了解下流程：模型蒸馏怎么做的。
大致能分四个步骤：
第一步：使用训练数据集训练教师模型。在咱们的那个过程里，就对应哥这个山寨老师认真上课、做题，能比较高准确率地完成《公差与配合》里的考试题目。至少你们是相信哥做那些题的质量比较高的。
第二步：定义学生模型。这是一个独立的模型，比教师模型简单，但也能独立完成相关的推理。对应咱们那个过程里的角色，就是你俩（的脑子，或者只是手指头），也要完成那次期末考试的同样一套题目。
第三步：通过模型蒸馏方式训练学生模型。这是最核心的流程，我们下面重点展开下，会少量参照咱们当时那个活动，尽量按照本来方式描述。
第四步：使用学生模型推理。把上一步训练好的学生模型在实际中应用。对应咱们的那个过程就是期末考试时，你、老七、我和咱班其他人一起拿着同一份卷子被考察。
重点是第三步。从外围看就是一个普通的神经网络模型训练过程，和上篇神经网络训练的主要流程差不多。先预测，再计算损失，然后根据损失函数计算梯度，并更像模型参数，一直迭代这个过程。通过模型蒸馏训练学生模型的过程中，模型训练的对象是学生模型，对应就是先计算学生模型的预测，在计算损失，计算梯度，更新模型参数。其中最大的差异是计算损失的方式不同。
首先，损失中要体现学生模型和他在学校的教师模型的差异。在模型蒸馏过程中，教师模型一般假设是更全面、强大，他的输出假设也是更全面、准确；对应的学生模型比较简单，预测的输出不太准确。这也复合咱们那个过程里的具体情况。哥这个山寨老师在你们眼里权威性还是有保证的，哥的答案你一般是信的。对应你们给的答案，心虚都写在脸上了，特别是老七。在模型蒸馏中一般通过KL散度（Kullback-Leibler Divergence）来描述学生模型预测结果的概率分别和对应教师模型预测结果概率分布之间的差异。KL散度越小说明教师模型和学生模型的差异越小，这个英文单词你不用读出来，理解就是你做题的思路和教你那个山寨老师的思路有多像。
在训练过程中，对学生模型的不断训练，在对应的数据集上，学生模型的月初概率分布与教师模型的概率分布越来越接近，这样正是学生模型学习教师模型的知识的过程。不只是对同样的训练数据得到和教师模型一致的结果，对每种答案的置信度也越来越接近。对应咱做《公差与配合》的单选题：比较孔或轴加工难易程度高低的依据是：A 标准公差因子；B 基本尺寸大小；C 公差等级；D 公差值大小 ，选A对的可能性1%；选B对的可能性3%；选C对的可能性95%；选D对的可能性1%。经过那段时间的练习后，你俩不止做题的结果和这个山寨老师越来越一致了，连思考问题的方式，至少是对某个结果的说法，都差不多了。从结果看学生模型可以更好地模拟教师模型的推理过程。前面这段描述里教师模型的输出不只包含标准答案，还包括更多的信息，如每个答案的概率，这种标签称为软标签。对应的是传统数据集上的每条样本的标签。
在模型蒸馏过程中，计算损失时，除了使用软标签，也要参考硬标签。即除了衡量学生模型预测和教师模型预测的差异外，也要衡量学生模型的输出和标准答案的差异。后者也称为交叉熵损失计算，和传统的神经网络模型训练计算损失的思路和方法一样。对应到咱们那个补课活动，就是老七买来那本练习书里的标准答案，这部分训练过程就是你们做那本书上的习题，然后对答案学习的过程。
模型蒸馏的过程中损失计算是把上面两种损失加权求和。即保证学生模型能学习到教师模型的思路方法，同时也能处理实际真实问题。类似咱们补课过程中，你俩一边跟着一个山寨老师学，一边自己做练习对答案。基于这种结合方式，通过硬标签可以适当纠正软标签的输出。一般模型蒸馏过程中软标签权重较大，如果教师模型模型输出有问题，就会较大地影响学生模型。对应到咱们那个补课活动，老七曾经拿着那本练习里的一个标准答案质疑哥有个地方可能讲错了。但是更多时候，你俩比较懒，也就听哥讲讲，那本练习是没怎么用上的，也就是硬标签作用有限。
最后一步，就是学生模型的应用，即使用训练好的学生模型在实际数据集上的推理。训练的目的是推理，就像你来问我DeepSeek怎么用，大家常用的就是下了个App，用它的推理能力来完成需要的任务。对应到咱们那次活动，学生模型推理流程对应的自然就是咱们那次期末考试了。这是咱们那个阶段的高潮，哥也刻意在这篇文档中整理这部分内容的时候把这部分设计为全文的高潮。我们的学生模型推理的结果是：你将将过，老七却挂了。
当时是一件有点悲伤但却给我们带了了很多额外快乐的事情，特别是当时我认赌服输请你俩去那个叫双虎的小饭店吃饭。老白干干得很爽，以至于这么多年后每次我去北京咱们吃喝的氛围和风格都是那次的延续。吃饭的话题留着咱下次吃饭再说，在这里还是把老七这个案例拿到这个技术话题里技术性地讨论下。专业分析要么是我这个教师模型不够强大，要么是我们模型蒸馏的过程有问题。也许是老七那个模型服务资源不够，训练没问题，模型也学习到位了，就是推理时候推不出来。当时我们吃饭时候调侃老七脑子不好，他的学生模型太简单了，你的刚刚好，老师出的题稍微变了下，你做出来了，他却没有。那最终原因可能还是你当年说的，丫的脑子不好使。唉，发现我们不小心从花双虎的生米里捏了几颗盐粒子洒在了老七的娇嫩的伤口上，下次见面喝酒时可怎么跟老七交代呢。
结合我们这个实践也能看到模型蒸馏的优点很明显，不需要从最初始训练一个模型，省下来大量的资源开销和时间。这点你俩应该神佑感触，不需自己从头翻书，跟着一个山寨老师来几遍就可以了。另外一个我们但是感知不明显的优势是不需要大量标注过的样本。模型训练中很重要的一部分是训练的样本数据，但是获取高质量的样本数据从来不是一件容易得事情。模型蒸馏中通过教师模型的软标签信息就可以有效地进行学生模型的训练。类似咱们那个补课案例中，你俩不需要买大量的带有标准答案的练习册，自己做很多题，再去对答案。特别是是考虑到咱们那个年代辅导书、练习册本来就很稀缺。但是如果处理不好会导致泛化能力可能有限，学生模型学习到了教师模型的基本能力，对于老师交的知识处理较好，但其他数据处理不好。可以简单理解成跟着老师模型学得太死，学到了然，没有学到所以然。咱们那次补课后的考试，老七就是因为学的稍微死了一点，期末考试的题目稍微变一变，他就没搞定。
DeepSeek关于模型蒸馏流程的描述如下，你只作为参照就好。比我们罗里吧嗦说半天要简洁、准确、权威。我们描述过程中为了方便你理解，有些内容刻意跳过了，有兴趣我们后面再补充。
0. 流程图 1[输入数据 X] 2 │ 3 ├─────► [教师模型（大型复杂模型，如BERT/ResNet）] ────► [软标签（Soft Targets，带温度参数 T）] 4 │ │ 5 │ ▼ 6 │ [概率分布（Softmax with Temperature T）] 7 │ │ 8 │ ▼ 9 └─────► [学生模型（小型轻量模型，如MobileNet/TinyBERT）] ◄──┐ 10 │ │ 11 ▼ │ 12 [概率分布（Softmax with Temperature T）] │ 13 │ │ 14 ▼ │ 15 [损失函数：软目标损失（KL散度） + 硬目标损失（交叉熵）] │ 16 │ │ 17 ▼ │ 18 [参数更新（反向传播）] ──────────────┘ 1.
          
          
        
      </description>
    </item>
    
    <item>
      <title>云原生工程师入坑AI深度学习系列（一）：从线性回归入门神经网络</title>
      <link>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-from-linear-regression-to-neural-network/</link>
      <pubDate>Sun, 06 Oct 2024 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-from-linear-regression-to-neural-network/</guid>
      <description>
        
          
            背景 最近团队的业务除了面向通用计算外，越来越多的要处理面向AI场景的软硬件资源的供给、分发、调度等。虽然还是在熟悉的云原生领域，折腾的还是哪些对象哪些事儿，适配到一种新场景。但为了避免新瓶装老酒，能有机会做的更扎实，做出价值，对这个要服务领域内的一些东西也想花点时间和精力稍微了解下。
国庆长假环太湖一圈回来，假期最后这两天豆哥被要求上课，正好难得集中时间可以稍微看些东西。暂时没有精力系统地构建，先入个门。作为一个云原生领域的从业者，目标是知道容器里跑的是什么，怎么跑的。
学新东西时习惯用自己的文字，尽可能简单易懂地总结记录贯通下，做不到严谨、全面、深入、专业。开始前定个小目标只要做到基本的通、透、够用即可。
说干就干，先从深度学习基础技术神经网络开始。Google一把，内容可真叫个多。确实最近身边不管曾经做什么的，摇身一变都能与AI扯上关系。这么多信息对我们这些局外人非常不友好。很多年前自学数学等相关基础课程时，习惯从稍微了解点的东西入手，有点脸熟的东西看着不怵。重拾十来年前尚老师Data Mining那门课程的部分内容，看看老的概念和新的技术能产生哪些联系。
切入点线性回归 线性回归可能是一个比较适当的切入点，模型简单好理解。线性回归时通过一组数据点来拟合线性模型，找出一个或者多个特征变量和目标结果之间的关系，有了这个关系就可以带入条件预测结果。一个非常经典的线性回归例子就是二手房价预测。
影响房价的因素很多，记得当时书上形式化表达是用了一个向量乘法y = wx + b。x向量由（x1,x2,x3,x4）组成，表示若干个属性。这里简单示意下假设只有两个因素x1、x2，分别表示屋子的房间数和面积，也不用向量乘了，就直接写成 y = w1 * x1 + w2 * x2 + b，y就房子价格。其中w1、w2和b称为线性回归模型的参数，w1、w2称为权重weight，b称为偏差bias。
可以看到，作为一种最简单的回归模型，线性回归使用这种线性回归方程对一个或者多个自变量和因变量之间的关系进行建模。有了这个假设的模型，就可以根据已有的二手房成交记录求解出模型上的参数w1、w2和b，这就是老听说的模型训练。完成模型训练求解出线性回归模型的参数，就可以把房间数、面积x1、x2带入表达式，得到房子的预测价格，这就是一个推理过程。
这个一个简单例子把模型的的表达、训练和推理过程最简单地顺一遍。省略了太多的信息和步骤，迭代着加上去应该就是关注的神经网络的关键内容。
首先是模型的表达，通过最基础的数学知识，这个线性回归的输入、输出和运算过程可以大致画成这样。
即使完全不了解神经网络，基于最朴素的概念理解，瞅着这个图上这些点的关系好像也已经和神经网络有点神似了。
神经网络的概念 神经网络这个典型术语标准定义很多，总结下简单理解神经网络就是一种模拟人脑处理信息的方式。从数据中获取关联，在输入和输出中建立关系，特别是复杂的输入和输出之间。类似我们人脑中神经元构成一个复杂、高度互联的网络，互相发送电信号处理信息。神经网络由人工神经元组成，在这些神经元上运行算法，求解各种复杂的模型，所以我们说的神经网络完整点描述其实是人工神经网络。
只是从外形简单比较，前面线性回归那个图看上去像一种单层或者单个神经元组成的神经网络，大致可以认为是神经网络的一个简单特例。
神经网络的结构 经典的神经网络包括输入层、输出层和隐藏层。
**输入层：**接受外部输入的数据，将数据输入给神经网络，简单处理后发给下一层。在预测房价这个线性模型中，输入层就是影响房价的两个属性。在另外一个典型应用图片分类中输入层就是像素，如100*100像素的图片就又10000个输入。 **隐藏层：**神经网络中大量的隐藏层从上一层，如输入层或者上一个隐藏层获取输入，进行数据处理，然后传递给下一层。神经网络的关键处理都集中在隐藏层，越复杂的模型、表达能力越强的模型，隐藏层的层数越多，隐藏层上的节点也越多。 **输出层：**输出神经网络对数据的最终处理结果。因为模型固定，输出层的节点数一般也是固定的，如上一个房价预测线性回归的图中，就只有一个输出。如果是分类的模型，一般有几个分类，就对应输出层有几个节点。 不考虑内部复杂实现，只看这个外部结构，从我们程序员的语言看，一个神经网络就像我们编程的一个方法。输入层对应这个方法定义的入参，输出层对应方法定义的返回值，隐藏层可以简单类比我们的方法实现逻辑。模型训练好后，去做推理时就是传入参数调用这个方法，得到返回值的过程。
从数学的视角可能更准确一些，一个神经网络对应一个映射函数，输入层对应函数的自变量x1、x2，输出层对应函数的因变量y。训练过程就是找到函数表达式中的各个参数。有了这个求解的函数表达式，其他任意参数x1、x2带进去也能得到相应基本正确的y。
作为映射函数，只要有一组输入就能映射到一组输出。除了这个根据房子大小、房间数映射出房价外，其他更强大的神经网络可以拟合更复杂的函数。对于大多数深度学习的应用，虽然我们没有办法像这个预测房价的例子这么直观地写出一个具体表达式，但还是可以理解存在这样一个函数映射，或者说通过训练有办法逼近一个理想的函数映射。
记得从哪里看到黄教主说过“AI深度学习，也是一种解决难以指定的问题的算法和一种开发软件的新方法。想象我们有一个任意维度的通用函数逼近器”。如果设计的神经网络足够深、参数足够多，足够复杂就可以逼近任意复杂的函数映射。不只是预测房价这个简单的线性回归，也不只是当年学习的Han Jiawei的Data Mining课本上的分类、聚类、啤酒尿布频繁项这些业务固定的应用。
为了便于理解把以上简单类比总结成下表。
神经网络 程序视角 数学视角 模型 代码方法 映射函数 输入层 入参定义 自变量 隐藏层 方法体实现 函数表达式 输出层 返回值定义 因变量 训练 构造实现并UT验证修正 求解函数参数 推理 实际方法调用 带入新的自变量求解因变量 样板特征 Feature UT测试用例输入 已知的符合表达式的自变量取值 样板标签 Label UT用例预期输出 已知的符合表达式的因变量取值 以上两个临时起意的类别，前一个更像神经网络的物理存在。不管多复杂的神经网络，最终都是一个方法调用。实际应用中通过Restful接口或者其他应用协议调到推理服务上，获得一个输出，返回给调用方使用。而数学的这个类比更像神经网络的逻辑定义，模型本身的定义和模型训练、推理过程。
          
          
        
      </description>
    </item>
    
  </channel>
</rss>

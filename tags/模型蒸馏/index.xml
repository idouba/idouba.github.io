<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>模型蒸馏 on 爱豆吧！</title>
    <link>https://idouba.com/tags/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/</link>
    <description>Recent content in 模型蒸馏 on 爱豆吧！</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>浙ICP备18050493号-1 浙公网安备 33010802006262号</copyright>
    <lastBuildDate>Fri, 07 Feb 2025 15:32:08 +0000</lastBuildDate><atom:link href="https://idouba.com/tags/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>云原生工程师入坑AI深度学习系列（二）：给昌子解释DeepSeek的模型蒸馏</title>
      <link>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-make-changzi-understand-model-distillation-of-deepseek/</link>
      <pubDate>Fri, 07 Feb 2025 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-make-changzi-understand-model-distillation-of-deepseek/</guid>
      <description>
        
          
            背景 昨天，昌子突然微信问我“DeepSeek咋用”。回复“你不好好焊钢轨，打听这玩意儿干啥”。小哥说我就想闹明白我们中国这个技术是不是像有些短视频里说的抄了老美的。不用问，这小哥是过年在家闲的刷到OpenAI可能起诉DeepSeek的新闻了。虽然给他说Altman在咱们大年初六好已经承认不打算起诉了，但是说服昌子小哥还是费了不少口舌。为了说明没有抄，模型蒸馏的话题就绕不过。在沟通中临时起意提到小哥咱们很多年前的一段趣事，居然说明白了。觉得很有意思，就顺手归档下。
模型蒸馏概念初体验 首先，DeepSeek关于模型蒸馏的定义是这样的：
模型蒸馏通过将复杂模型（教师模型）的知识转移到简单模型（学生模型）中，实现模型压缩、加速推理并保持性能，适用于多种资源受限的场景。
是不是不太好理解，用咱们共同的一段经历做个不算太恰当的类别，可能更好理解。
还记得咱们上中专那会儿，正是十五六岁贪玩的年龄，那学期好像是安排去永济电机厂还是洛阳重机厂实习，我们疯玩了几个月，你总带哥去厂子的花园里捞鱼。临期末有一门考试好像是《公差与配合》，你和老七担心考不过，总磨着我给你俩补课。
其实只要自己老老实实地把课本过一遍，课后题做几遍，你俩保证都妥妥考得过。但你俩还是选择了个山寨老师补课。对应到模型训练过程，你俩作为学生模型没有选择从头看书、自己做题这种完全从头开始训练的方式，而是模仿学习一种你们信任的教师模型来获取知识。
但是你俩这个过程还是学习的过程，并没有直接抄哥这个山寨老师的。你们得自己学过去，然后期末考试时候才能考出来。正好对应模型训练和推理的过程。我们详细捋下咱们当时怎么干的。
一般你和老七会拿一道题目过来，让我给出我的答案。当然每道题，你们都是自己做过的。没记错的话，你们开始哪些答案都是凭着感觉蒙的 。然后我们会讨论题目，如最小最大实体尺寸对应于孔和轴分别是他们的最大极限尺寸还是最小极限尺寸。你们相信哥的答案一般是对的答案，在讨论过程中调整、形成自己的思考方式。看上去是哥在纠正你们，实际是你们在自己思考，接近你们心目中这个山寨老师对这段知识点的处理。
反复经历这个过程，然后你俩就越来越自信。最后，你们就出师了。自己可以独立判断，得出答案。尤其是老七，练习的可溜了。以至于后面他再磨我的时候，我非常坚定地说：“你都学到这个程度了，如果再考不过，我请你哥俩吃饭”。结果，结果你还记得吗？这么多年来每次见面喝酒你光记得有次学校附近有个叫双虎的小饭馆我们花生米、土豆丝、老白干搞得可爽了，背景还记得不？让哥这段讲完给你串起来，先不岔开，让哥再尝试给你讲点机械专业以外的新鲜东西。
在这个过程里，对应模型蒸馏的术语。哥这个山寨老师的叫教师模型，你俩那叫学生模型。一般教师模型复杂，学生模型简单。对应到咱们的实践，哥当时可是老老实实地把课本学过一遍，虽然跟你们玩，但是老师上课讲的都认真地听了的。所以教师模型里不只是塞了那些题，还塞了更多。而你俩呢，课本基本上是不看的，在你们那里课本都是些不一定必要的信息，你们只想学习满足期末考试需要的知识。即学生模型更简洁，模型蒸馏过程去掉了这些多余部分，让学生模型更简单、更高效地提供能力。
对应的一般教师模型参数多，学生模型参数少。记得开始拿到一个题目时，哥给你们讲的时候啰啰嗦嗦说一堆课本里的背景原理，然后推出结果，而后来我们练的根据简单的题目特征，就能找到对的答案。当时你经常说的一句话是“哥们记不清，简单点，好理解”。差不多对应到模型蒸馏，就是简化去掉无用参数，提高效率的同时，模型能力并没有下降很多。
通过这种有针对性的练习，学习老师模型总结过的知识，更有针对性，因此也更高效。你们用更简单的模型，通过更低的成本，但更高的效率达到了很高的模型质量。到考试前那阵子，特别是你，不止比我墨迹白天推导要快，有些时候也更准。这就是你们根据各自的逻辑理解学习的成果。
那段时间，咱们仨人一直鬼混一起，也就是一直在一起学。你和老七顶多就是过会儿拿书过来问我这个题我的答案是啥，为啥这样想的，然后你的答案是啥，为啥不一样。从外面行为看，我们整个状态都是学习的状态，认真学习的状态，你理也就每学期这时候有个学习的状态。从内在看，你俩是自己脑子在思考，在各自脑子里构造各自的模型。对于同一个题目，准确说是一块知识点，我这个山寨老师咋想的，你们咋想的，能得到尽量一致的答案。我没有把我的模型给你们抄，也没有途径啊，抄不着。顶多从这过程获取了一些重要知识，帮助你在考试时能同样方式去思考，选到一个对的答案。
我讲的都一样，你俩各自独立地在思考学习，各自在自己脑子里形成对《公差与配合》独立的思考。你和老七学到的也不一样，最终期末考试时在实际的测试数据集上验证，结果大不相同。结果留个彩蛋在后面。同样的教师模型，同样的训练过程，两个不同的学生模型，学到的效果不同。这也反证了，如果是抄，你俩应该抄的是一样的才对。同样的模型蒸馏，也是学，不是抄。只是学到了行为和能力，抄不到内部结构和实现。
模型蒸馏流程 上面简单类别，我们理解个概念：模型蒸馏是什么。下面简单了解下流程：模型蒸馏怎么做的。
大致能分四个步骤：
第一步：使用训练数据集训练教师模型。在咱们的那个过程里，就对应哥这个山寨老师认真上课、做题，能比较高准确率地完成《公差与配合》里的考试题目。至少你们是相信哥做那些题的质量比较高的。
第二步：定义学生模型。这是一个独立的模型，比教师模型简单，但也能独立完成相关的推理。对应咱们那个过程里的角色，就是你俩（的脑子，或者只是手指头），也要完成那次期末考试的同样一套题目。
第三步：通过模型蒸馏方式训练学生模型。这是最核心的流程，我们下面重点展开下，会少量参照咱们当时那个活动，尽量按照本来方式描述。
第四步：使用学生模型推理。把上一步训练好的学生模型在实际中应用。对应咱们的那个过程就是期末考试时，你、老七、我和咱班其他人一起拿着同一份卷子被考察。
重点是第三步。从外围看就是一个普通的神经网络模型训练过程，和上篇神经网络训练的主要流程差不多。先预测，再计算损失，然后根据损失函数计算梯度，并更像模型参数，一直迭代这个过程。通过模型蒸馏训练学生模型的过程中，模型训练的对象是学生模型，对应就是先计算学生模型的预测，在计算损失，计算梯度，更新模型参数。其中最大的差异是计算损失的方式不同。
首先，损失中要体现学生模型和他在学校的教师模型的差异。在模型蒸馏过程中，教师模型一般假设是更全面、强大，他的输出假设也是更全面、准确；对应的学生模型比较简单，预测的输出不太准确。这也复合咱们那个过程里的具体情况。哥这个山寨老师在你们眼里权威性还是有保证的，哥的答案你一般是信的。对应你们给的答案，心虚都写在脸上了，特别是老七。在模型蒸馏中一般通过KL散度（Kullback-Leibler Divergence）来描述学生模型预测结果的概率分别和对应教师模型预测结果概率分布之间的差异。KL散度越小说明教师模型和学生模型的差异越小，这个英文单词你不用读出来，理解就是你做题的思路和教你那个山寨老师的思路有多像。
在训练过程中，对学生模型的不断训练，在对应的数据集上，学生模型的月初概率分布与教师模型的概率分布越来越接近，这样正是学生模型学习教师模型的知识的过程。不只是对同样的训练数据得到和教师模型一致的结果，对每种答案的置信度也越来越接近。对应咱做《公差与配合》的单选题：比较孔或轴加工难易程度高低的依据是：A 标准公差因子；B 基本尺寸大小；C 公差等级；D 公差值大小 ，选A对的可能性1%；选B对的可能性3%；选C对的可能性95%；选D对的可能性1%。经过那段时间的练习后，你俩不止做题的结果和这个山寨老师越来越一致了，连思考问题的方式，至少是对某个结果的说法，都差不多了。从结果看学生模型可以更好地模拟教师模型的推理过程。前面这段描述里教师模型的输出不只包含标准答案，还包括更多的信息，如每个答案的概率，这种标签称为软标签。对应的是传统数据集上的每条样本的标签。
在模型蒸馏过程中，计算损失时，除了使用软标签，也要参考硬标签。即除了衡量学生模型预测和教师模型预测的差异外，也要衡量学生模型的输出和标准答案的差异。后者也称为交叉熵损失计算，和传统的神经网络模型训练计算损失的思路和方法一样。对应到咱们那个补课活动，就是老七买来那本练习书里的标准答案，这部分训练过程就是你们做那本书上的习题，然后对答案学习的过程。
模型蒸馏的过程中损失计算是把上面两种损失加权求和。即保证学生模型能学习到教师模型的思路方法，同时也能处理实际真实问题。类似咱们补课过程中，你俩一边跟着一个山寨老师学，一边自己做练习对答案。基于这种结合方式，通过硬标签可以适当纠正软标签的输出。一般模型蒸馏过程中软标签权重较大，如果教师模型模型输出有问题，就会较大地影响学生模型。对应到咱们那个补课活动，老七曾经拿着那本练习里的一个标准答案质疑哥有个地方可能讲错了。但是更多时候，你俩比较懒，也就听哥讲讲，那本练习是没怎么用上的，也就是硬标签作用有限。
最后一步，就是学生模型的应用，即使用训练好的学生模型在实际数据集上的推理。训练的目的是推理，就像你来问我DeepSeek怎么用，大家常用的就是下了个App，用它的推理能力来完成需要的任务。对应到咱们那次活动，学生模型推理流程对应的自然就是咱们那次期末考试了。这是咱们那个阶段的高潮，哥也刻意在这篇文档中整理这部分内容的时候把这部分设计为全文的高潮。我们的学生模型推理的结果是：你将将过，老七却挂了。
当时是一件有点悲伤但却给我们带了了很多额外快乐的事情，特别是当时我认赌服输请你俩去那个叫双虎的小饭店吃饭。老白干干得很爽，以至于这么多年后每次我去北京咱们吃喝的氛围和风格都是那次的延续。吃饭的话题留着咱下次吃饭再说，在这里还是把老七这个案例拿到这个技术话题里技术性地讨论下。专业分析要么是我这个教师模型不够强大，要么是我们模型蒸馏的过程有问题。也许是老七那个模型服务资源不够，训练没问题，模型也学习到位了，就是推理时候推不出来。当时我们吃饭时候调侃老七脑子不好，他的学生模型太简单了，你的刚刚好，老师出的题稍微变了下，你做出来了，他却没有。那最终原因可能还是你当年说的，丫的脑子不好使。唉，发现我们不小心从花双虎的生米里捏了几颗盐粒子洒在了老七的娇嫩的伤口上，下次见面喝酒时可怎么跟老七交代呢。
结合我们这个实践也能看到模型蒸馏的优点很明显，不需要从最初始训练一个模型，省下来大量的资源开销和时间。这点你俩应该神佑感触，不需自己从头翻书，跟着一个山寨老师来几遍就可以了。另外一个我们但是感知不明显的优势是不需要大量标注过的样本。模型训练中很重要的一部分是训练的样本数据，但是获取高质量的样本数据从来不是一件容易得事情。模型蒸馏中通过教师模型的软标签信息就可以有效地进行学生模型的训练。类似咱们那个补课案例中，你俩不需要买大量的带有标准答案的练习册，自己做很多题，再去对答案。特别是是考虑到咱们那个年代辅导书、练习册本来就很稀缺。但是如果处理不好会导致泛化能力可能有限，学生模型学习到了教师模型的基本能力，对于老师交的知识处理较好，但其他数据处理不好。可以简单理解成跟着老师模型学得太死，学到了然，没有学到所以然。咱们那次补课后的考试，老七就是因为学的稍微死了一点，期末考试的题目稍微变一变，他就没搞定。
DeepSeek关于模型蒸馏流程的描述如下，你只作为参照就好。比我们罗里吧嗦说半天要简洁、准确、权威。我们描述过程中为了方便你理解，有些内容刻意跳过了，有兴趣我们后面再补充。
0. 流程图 1[输入数据 X] 2 │ 3 ├─────► [教师模型（大型复杂模型，如BERT/ResNet）] ────► [软标签（Soft Targets，带温度参数 T）] 4 │ │ 5 │ ▼ 6 │ [概率分布（Softmax with Temperature T）] 7 │ │ 8 │ ▼ 9 └─────► [学生模型（小型轻量模型，如MobileNet/TinyBERT）] ◄──┐ 10 │ │ 11 ▼ │ 12 [概率分布（Softmax with Temperature T）] │ 13 │ │ 14 ▼ │ 15 [损失函数：软目标损失（KL散度） + 硬目标损失（交叉熵）] │ 16 │ │ 17 ▼ │ 18 [参数更新（反向传播）] ──────────────┘ 1.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>

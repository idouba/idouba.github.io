<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>最佳实践 on 爱豆吧！</title>
    <link>https://idouba.com/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link>
    <description>Recent content in 最佳实践 on 爱豆吧！</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>浙ICP备18050493号-1 浙公网安备 33010802006262号</copyright>
    <lastBuildDate>Wed, 21 Aug 2024 15:32:08 +0000</lastBuildDate><atom:link href="https://idouba.com/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>最佳实践：Karmda和Istio提高分布式云的负载与流量韧性</title>
      <link>https://idouba.com/best-practice-karmada-and-istio-improve-workload-traffic-resilience-of-production-distributed-cloud/</link>
      <pubDate>Wed, 21 Aug 2024 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/best-practice-karmada-and-istio-improve-workload-traffic-resilience-of-production-distributed-cloud/</guid>
      <description>
        
          
            记录在2024年8月21日在香港Kubecon上发表的技术演讲《Best Practice: Karmada &amp;amp; Istio Improve Workload &amp;amp; Traffic Resilience of Production Distributed Cloud》
大家好，我是张超盟，来自华为云 ，我今天带来的是一个有关服务韧性的话题。将介绍在分布式云场景下，Karmada和Istio相互配合，管理多K8s集群的负载和流量，改善服务韧性的实践。
我是华为云分布式云原生的架构师，在过去的近十年里在华为云从事云原生相关的设计开发工作，包括过去几年里一直负责华为云应用服务网格产品。
演讲的内容包括：韧性的背景，K8s和Istio作为云原生领域的基座技术，能力很丰富也很强大，我们从韧性角度简单审视下相关能力。然后介绍分布式云如何改善单云的韧性，又引入了哪些新的挑战。 重点是实践的内容，介绍在分布式云环境下：Karmada如何提高多集群的负载韧性，Istio如何提高多集群的流量韧性；以及Karmada和Istio相互配合提供完整的多集群应用韧性的最佳实践。
简单讲，韧性描述了这样一种能力，系统在过载、故障或在遭受攻击的时候还能够完成基本功能。韧性告诉我们，①虽然我们不想要失败，但是我们得承认失败总是会发生。因而我们需要为失败而设计系统，减少故障对系统的影响。有个著名的说法，韧性不能保证你多挣到钱，但是可以保证你少赔钱。竞争力可能决定产品的上线，韧性才能保证产品的下线。韧性应用于工程世界的所有系统。计算机世界里韧性是系统设计需要考虑的关键因素。
下面简单看下K8s和Istio提供的韧性能力。K8s大家都非常熟悉，K8s提供了Deployment，Replica Set和Service三个核心对象。 Deployment和Replica Set声明式控制负载实例的副本数和配置。 Service让为每个服务器提供了统一的访问入口，自动在多个实例间负载均衡。k8s基于这三种关键机制实现了应用部署、升级、访问的自动化。较之传统虚拟机方式，除了带来了轻量、敏捷、弹性的特点外，同时也提供了丰富的平台能力，提高应用的韧性。
我们尝试通过韧性角度认识下这些我们熟悉的能力。首先K8s自动控制负载实例数，通过多实例提供冗余容错能力，提高可用性。特别是提供了节点、AZ的反亲和部署，保证局部资源故障时服务总体仍然可用。另外滚动升级，交替创建新Pod、停止老Pod。通过平滑升级减少了升级的停机时间。水平扩缩容 HPA快速自动弹性扩缩容实例，避免了业务量大资源不足导致的系统过载。Liveness和Readiness的健康检查，实现应用故障自动检测和自愈。
此外k8s还提供了其他能力，间接改善韧性。如： 提供RBAC，保护应用和数据的安全。内置的日志、事件和监控，通过平台方式提供了应用运维和Troubleshooting的关键能力。ConfigMap和Secret，方便用户把配置从代码中独立处理，避免了重新部署带来的变更风险。CICD，对接流水线自动化提高上线变更效率，也减小了人工风险。
可以看到大量我们平时用到并且非常熟悉的k8s能力，都是基于韧性目标设计的。
Istio的机制大家也比较熟悉，通过透明代理拦截流量，代替应用执行流量动作，从而以非侵入方式提供了七层的流量能力。.Istio提供的能力非常丰富，这里我们也同样从韧性的视角审视Istio提供的众多能力。可能会发现原来我们经常用到的Istio能力很多都和韧性相关。
我们都说Istio在k8s基础设能力之上，提供了面向应用的上层能力增强，这种增强的配合关系同样适用于韧性方面。Istio提供的不只是四层负载均衡，而是基于七层的流量提供了更多的能力。包括：访问亲和性、故障倒换等能力。通过自动重试提高访问成功率；通过限流防止系统过载。基于七层流量特征的灰度分流策略，在不同版本间分配流量，降低版本升级引起的风险。不同于k8s的的Readiness，Istio提供了基于熔断器的故障隔离和故障恢复能力。 另外非侵入的调用链、访问日志，跟踪服务间调用细节，方便故障定位定界。通过非侵入故障注入，提前发现产品缺陷。可以看到，Istio以非侵入方式提供了大量面向应用的韧性。
如前面总结Kubernetes提供了负载多实例，并支持基于节点、AZ的反亲和部署提高应用韧性。但这些能力仅局限于一个Kubernetes集群内部，不能在更大范围提供应用的韧性。这样对于Kubernetes集群自身的故障无能为力。当客户业务都集中在一个集群时，集群异常引发了全局的业务断服宕机。生产中这种事故频繁发生在集群升级时。
这种现象的根本原因是故障半径的问题。就像把所有的鸡蛋放在一个篮子里，一旦篮子有问题，没有一个鸡蛋能幸存下来。解决这类问题直观的思路就是减小故障半径，把鸡蛋分开放到多个篮子里。
有一种分布式云的架构可以在一定程度上解决这个问题。
分布式云是一种基础设施架构；可以在多个物理位置，包括公有云自己的数据中心、其他云提供商的数据中心、用户本地或者第三方数据中心、边缘，运行公有云的基础设施。并且从单个控制平面统一管理这些云资源。
对于云原生场景的分布式云，我们称为分布式云原生。华为云分布式云原生服务UCS，将云原生基础设施分发到各种物理位置，使得用户可以在业务期望的任意位置运行云原生应用，并且通过公有云上集中的云原生控制面统一管理。
可以看到，较之单云架构，分布式云提供的优势包括：
分布式部署的数据和应用可以更接近用户，使得响应时间更短。Less latency, closer to end users. 数据和应用可以限定在规定的范围内，更容易满足合规性要求。Increased regulatory compliance 可以结合分布式的资源快速构建业务，扩展性更强 Better scalability 此外还可以通过统一的控制台，监控运维分布式环境部署的应用。Improved visibility 当然我们关注的韧性改善也包括在内。天然分布式环境部署，提供了冗余和容错，一个地域或者某个云环境故障，其他环境的可以故障倒换，接管业务。
当然,分布式云也引入了众多挑战：
复杂性(Complexity)：管理地理上可能跨越多个云提供商和本地数据中心分散的云资源，会带来新的复杂性。 安全性(Security)：在分布式环境中，保护数据和应用程序安全会更加困难。 异质性(Heterogeneity)：分布式云环境通常涉及不同硬件、软件、操作系统和云提供商的服务。 延时(Latency and Network Performance)分布式云在某些情况下有助于减少延迟，但如果使用不当，会引入新的网络延时 在云原生场景下，k8s本身定义了标准统一的接口，一定程度简化了其中复杂性和异构资源问题。.但是如何将分布式在不同物理位置，不同的k8s管理起来，并且提供和单个k8s集群类似的体验，还是有很大的挑战。Karmada可能是一个答案。
简单介绍下Karmada。Karmada的设计目标，是使开发人员能够像使用单个 Kubernetes 集群一样使用多集群能力，管理跨集群的资源；对用户提供一个可以不断扩展的容器资源池；并通过多集群方式进一步提高云原生应用的韧性。
这里简单列举了Karmada提供的关键功能。包括：多集群管理、跨集群负载分发、全局资源视图、多集群服务发现等。 我们重点关注两个与今天分享主题密切相关的特征： 一个是Karmada怎样解决前面讲到的分布式云的管理复杂性问题。另外一个是Karmada的分布式云多集群管理，具体怎么实践多集群韧性目标的。
          
          
        
      </description>
    </item>
    
    <item>
      <title>基于实际案例解析Istio访问日志ResponseFlag系列</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-index/</link>
      <pubDate>Sun, 15 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-index/</guid>
      <description>
        
          
            背景： 访问日志是应用系统运维的重要手段，可以有效地帮助我们进行问题的定位定界。
在服务网格中，访问日志也是可观测性能力的一块重要内容。不同于指标提供访问的统计信息，访问日志记录了每一次访问的详细信息。不管是作为安全审计，还是做系统运维，访问日志都是最得力的手段。
访问日志记录了每次访问的时间、请求、应答、耗时、源服务和目标服务等信息。帮助运维人员进行有效的故障定位定界。生产中我们也经常会检索分析一批日志看特点，如是否慢的请求的应答体都比较大，来自某个特定服务的服务接口总出错，或者来自某个特定源服务的访问不正常等，帮助我们发现系统问题。
对于七层的访问日志一般我们会通过HTTP响应码了解请求的状况，如503、502、404、403等。Envoy在访问日志中引入了应答标记Response Flag，辅助HTTP响应码，进一步描述访问或连接的细节问题。如发生 了503错误后，通过503 UH、 503 UF、 503 UC、 503 NC 等区分各种不同的503产生的原因，提供线索让运维人员针对性地解决问题。
但是Envoy 和Istio社区的访问日志对于Response Flag的信息非常少，所有的内容也只是如下非常干巴的把组合的单词展开，没有解释清楚每个标记的含义，更没有说明哪种情况下会出现这个标记。身边的同事，还有我们的客户经常在生产中碰到了这些应Response Flag不知道如何处理。有客户的工程师反馈说，看到了Response Code里那几个奇怪UC、UH等字符比看见503还让人抓狂。
Long name Short name Description DownstreamConnectionTermination DC Downstream connection termination. FailedLocalHealthCheck LH Local service failed health check request in addition to 503 response code. UpstreamRequestTimeout UT Upstream request timeout in addition to 504 response code. LocalReset LR Connection local reset in addition to 503 response code. UpstreamRemoteReset UR Upstream remote reset in addition to 503 response code.
          
          
        
      </description>
    </item>
    
    <item>
      <title>SpringClod到Istio最佳实践</title>
      <link>https://idouba.com/best-practice-from-spring-cloud-to-istio/</link>
      <pubDate>Tue, 23 Feb 2021 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/best-practice-from-spring-cloud-to-istio/</guid>
      <description>
        
          
            记录在北京时间2月23日，在全球首届社区峰会IstioCon 2021中，发表的《Best practice:from Spring Cloud to Istio》技术演讲。回答经常被客户和同事们问到的一个问题，SpringCloud和Istio的关系，如何演进。
以下为演讲全文: 大家好，我是来自华为云的工程师。很荣幸有机会和大家分享Istio在生产中使用的实际案例。
华为云应用服务网格从2018年在公有云上线， 作为全球最早的几个网格服务之一，经历和见证了从早期对网格的了解、尝试到当前大规模使用的过程。服务的客户越来越多，场景也越来越复杂。这其中的通用功能作为feature大都贡献到Istio社区，解决方案层面的实践也希望通过这样的机会和大家交流。
本次我选取的主题是Spring Cloud to Istio。来自我们客户的Spring cloud的项目和Istio的结合与迁移案例。
演讲主要包含四部分的内容： 1）背景介绍
2）使用Spring cloud微服务框架遇到的问题
3）解决方案
4）通过示例来描述方案的实践细节
背景介绍 还是以微服务为切入点，微服务的诸多优势非常明显，但相应给整个系统带来的复杂度也非常显著。单体的系统变成了分布式后，网络问题，服务如何找到并访问到对端的服务发现问题，网络访问的容错保护问题等。连当年最简单的通过日志中的调用栈就能实现的问题定位，微服务化后必须要通过分布式调用链才能支持。怎样解决微服务带来的这些挑战？
微服务SDK曾经是一个常用的解决方案。将微服务化后通用的能力封装在一个开发框架中，开发者使用这个框架开发写自己的业务代码，生成的微服务自然就内置了这些能力。在很长的一段时间内，这种形态是微服务治理的标配，以至于初学者以为只有这些SDK才是微服务。
服务网格则通过另一种形态提供治理能力。不同于SDK方式，服务治理的能力在一个独立的代理进程中提供，完全和开发解耦。虽然从图上看两者差异非常小，后面我们将会从架构和实际案例来分析两者在设计理念上的差异，来体会前者是一个开发框架，而后者是一个基础设施。
SDK形态中Spring cloud是最有影响力的代表项目。Spring cloud提供了构建分布式应用的开发工具集，如列表所示。其中被大部分开发者熟知的是微服务相关项目，如：服务注册发现eureka、配置管理 config、负载均衡ribbon、熔断容错Hystrix、调用链埋点sleuth、网关zuul或Spring cloud gateway等项目。在本次分享中提到的Spring cloud也特指Spring cloud的微服务开发套件。
而网格形态中，最有影响力的项目当属Istio。Istio的这张架构图在这次演讲中会高频出现。作为本次分享的背景，我们只要知道架构上由控制面和数据面组成，控制面管理网格里面的服务和对服务配置的各种规则。数据面上每个服务间的出流量和入流量都会被和服务同POD的数据面代理拦截和执行流量管理的动作。
除了架构外，作为背景的另外一个部分，我们挑两个基础功能稍微打开看下两者的设计和实现上的相同和不同。首先是服务发现和负载均衡。
左边是Spring cloud，所有的微服务都会先注册中心，一般是Eureka进行服务注册，然后在服务访问时，consumer去注册中心进行服务发现得到待访问的目标服务的实例列表，使用客户端负载均衡ribbon选择一个服务实例发起访问。
右边Istio不需要服务注册的过程，只需要从运行平台k8s中获取服务和实例的关系，在服务访问时，数据面代理Envoy拦截到流量，选择一个目标实例发送请求。可以看到都是基于服务发现数据进行客户端负载均衡，差别是服务发现数据来源不同，负载均衡的执行体不同。
下面比较下熔断：
左边为经典的Hystrix的状态迁移图。一段时间内实例连续的错误次数超过阈值则进入熔断开启状态，不接受请求；隔离一段时间后，会从熔断状态迁移到半熔断状态，如果正常则进入熔断关闭状态，可以接收请求；如果不正常则还是进入熔断开启状态。
Istio中虽然没有显示的提供这样一个状态图，但是大家熟悉Istio规则和行为应该会发现，Istio中OutlierDection的阈值规则也都是这样设计的。两者的不同是Spring cloud的熔断是在SDK中Hystrix执行，Istio中是数据面proxy执行。Hystrix因为在业务代码中，允许用户通过编程做一些控制。
以上分析可以看到服务发现、负载均衡和熔断，能力和机制都是类似的。如果忽略图上的某些细节，粗的看框图模型都是完全一样的，对比表格中也一般只有一项就是执行位置不同，这一点不同在实际应用中带来非常大的差异。
使用Spring cloud微服务框架遇到的问题 本次演讲的重点是实践。以下是我们客户找到我们TOP的几个的问题，剖析下用户使用传统微服务框架碰到了哪些问题，这些大部分也是他们选择网格的最大动力。
1）多语言问题 在企业应用开发下，一个业务使用统一的开发框架是非常合理常见的，很多开发团队为了提升效率，经常还会维护有自己公司或者团队的通用开发框架。当然因为大部分业务系统都是基于Java开发，所以Spring cloud开发框架，或者衍生于Spring cloud的各种开发框架使用的尤其广泛。
但是在云原生场景下，业务一般更加复杂多样，特别是涉及到很多即存的老系统。我们不能要求为了微服务化将在用的一组成熟服务用Spring cloud重写下。用户非常希望有一种方式不重写原来的系统也能对其进行应用层服务访问管理。
2）将Spring cloud的微服务运行在K8s上会有很大的概率出现服务发现不及时 前面介绍过Spring cloud服务发现是基于各个微服务先向注册中心进行服务注册的数据来实现的，在传统Spring cloud场景下，当微服务部署在VM上，服务动态变化要求没有那么高，顶多个别实例运行不正常，通过服务发现的健康检查就足够了。但是在k8s场景下，服务实例动态迁移是非常正常场景。如图示，producer的某个Pod已经从一个节点迁移到另外一个节点了，这时需要新的pod2的producer实例向eureka注册，老实例Pod1要去注册。
如果该情况频繁发生，会出现注册中心数据维护不及时，导致服务发现和负载均衡到旧的实例pod1上，从而引起访问失败的情况。
3）升级所有应用以应对服务管理需求变化 第三个问题是一个比较典型的问题。客户有一个公共团队专门维护了一套基于Spring cloud的自有开发框架，在每次升级开发框架时，不得不求着业务团队来升级自己的服务。经常会SDK自身修改测试工作量不大，但却要制定很长周期的升级计划，来对上千个基于这个SDK开发的服务分组重新编译，打包，升级，而且经常要陪着业务团队在夜间变更。业务团队因为自身没有什么改动，考虑到这个升级带来的工作量和线上风险，一般也没有什么动力。
4）从单体式架构向微服务架构迁移 这是一个比较普遍的问题，就是渐进的微服务化。马丁福勒在著名的文章单体到微服务的拆分中（https://martinfowler.com/articles/break-monolith-into-microservices.html ）也提到了对渐进微服务化的倡议，如何能从业务上将一个大的业务分割，解耦，然后逐步微服务化。马丁福勒强调 “解耦的是业务能力不是代码” ，大神将代码的解耦留给了开发者。
但是站在开发者的角度讲渐进的微服务不是一个容易的事情。以基于Spring cloud框架进行微服务开发为例，为了所有的微服务间进行统一的服务发现、负载均衡，消费和执行同样的治理策略，必须要求所有的微服务基于同样的，甚至是统一版本的SDK来开发。
          
          
        
      </description>
    </item>
    
  </channel>
</rss>

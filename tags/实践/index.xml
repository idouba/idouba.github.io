<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>实践 on 爱豆吧！</title>
    <link>https://idouba.com/tags/%E5%AE%9E%E8%B7%B5/</link>
    <description>Recent content in 实践 on 爱豆吧！</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>浙ICP备18050493号-1 浙公网安备 33010802006262号</copyright>
    <lastBuildDate>Sun, 12 Dec 2021 15:50:08 +0000</lastBuildDate><atom:link href="https://idouba.com/tags/%E5%AE%9E%E8%B7%B5/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>KubeCon2021：服务网格替代 Hystrix 提升在线视频服务韧性的生产实践</title>
      <link>https://idouba.com/kubecon2021-online-video-upgrades-resilience-from-sc-circuit-breaker-to-service-mesh-kubecon2021/</link>
      <pubDate>Sun, 12 Dec 2021 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/kubecon2021-online-video-upgrades-resilience-from-sc-circuit-breaker-to-service-mesh-kubecon2021/</guid>
      <description>
        
          
            KubeCon2021 和世宇做的一个技术实践分享，总结了下一起把网格在人人视频中落地的部分经验。
摘要： 作为中国领先的在线视频共享平台，人人视频业务的快速发展给其 IT 基础设施带来了巨大挑战。日益增长的复杂性、容量和韧性要求给当前基于 Spring Cloud 熔断器的微服务带来了新的问题。
在KubeCon2021上，华为云应用服务网格架构师张超盟和人人视频技术主管徐世宇介绍了大规模生产环境中的服务网格韧性实践，包括不健康实例的透明自动隔离、故障自动恢复和自我修复、连接池管理、重试、限流、超时和分布式跟踪等。通过分析熔断器模式和比较 Spring Cloud 熔断器与服务网格在各自生产实践中不同的实现方式，结果表明优化不只是改善了系统的可靠性和可用性，还使得开发和操作工作更简单便捷。
正文： 我是张超盟，来自华为云。本次大会我和人人视频的架构师徐世宇带来关于服务韧性的分享。结合一个生产中的实际案例，介绍网格等云原生解决方案替换原有基于Spring Cloud Hystrix在提升服务韧性的实践细节。
我是华为云应用服务网格的架构师，在华为云主要从事容器、网格等云原生相关设计开发工作；世宇是人人视频的架构师，负责人人视频后台服务云原生落地的架构、方案和实施工作。
演讲主要包含三部分的内容：
首先，概要的介绍韧性的背景； 第二部分，案例的业务背景和架构，包括原有Spring Cloud框架中基于Hystrix的韧性能力的使用细节； 第三部分是本次演讲的重点内容，介绍服务网格等云原生技术全面提升服务韧性的实践。 关于韧性 “任何事物任何时候都可能故障”，这是AWS的沃纳关于故障的经典描述。在系统架构设计，特别是韧性、可靠性可用性设计中被广泛引用。因为不断的经验教训告诉我们，对于一个系统，我们所面临的不是是否失败，而是什么时候失败的问题。
不管前期我们投入多少财力、精力和资源去加固系统，失败总不可避免。预防失败是一方面，更重要的是接受失败，在失败时候保证业务影响小，并尽快的从失败中恢复。
韧性正是描述了这样一种能力，韧性强调的是系统在过载、故障或在遭受攻击的时候还能够使用。韧性告诉我们，虽然我们并不想要失败，但是我们承认失败会发生的现实。因而我们需要为失败而设计系统，在故障发生时，减少故障对系统的影响，进而减小对用户业务的影响，特别是核心业务的影响。即构建能处理这些故障并自我修复的系统。有个著名的说法，韧性不能保证你多挣到钱，但是可以保证你少赔钱。套用当前一个流行的说法是，产品的竞争力或者业务能力能帮我们冲击更高的上线，但是韧性能帮助我们守住我们的下线。
韧性应用于工程世界的所有系统。计算机世界里韧性设计一直是一个非常重要的研究方向。不管是自研的传统服务，还是现网上运行的云服务。
在本次分享中我们将聚焦服务间访问的韧性，主要是客户场景中微服务的服务间访问比较频繁的场景。
以上关于故障的观点在规模小的系统里体现可能不明显，在规模比较大的系统里尤其是微服务场景下体现的非常明显。局部的访问影响整个系统，进而影响最终业务。
如Hystrix关于韧性的理论模型中描述了：对于依赖 30 个服务的应用程序，即使每个服务的正常运行时间为 99.99%，系统总的正常运行也只有99.7%，每个月会引入超过2个小时的停机。考虑到微服务分布式系统的网络带宽、延时、可靠性、安全、业务自身问题、资源等情况会变的更加复杂。
业务场景和挑战 接下来由人人视频的架构师徐世宇介绍实践的实际场景、系统架构，和早期基于Spring Cloud的熔断器Hystrix提供微服务韧性保护的实践细节以及遇到的挑战。
人人视频是以美日韩泰视频内容为主的在线视频点播APP。当前拥有2亿+注册用户，日活最高达到1000万，月活用户5500万，并且近日人人视频迎来了第七个周年纪念日。作为中国领先的在线视频共享平台，人人视频业务的快速发展给其 IT 基础设施带来了巨大挑战。
人人视频主要业务架构如上图所示，该业务架构主要分为四层：网关层、业务聚合BFF层、基础服务层、中间件层。其中基础服务层由用户中心、内容中心、市场变现中心、数据中心五大中心构成：
用户中心主要以用户信息、用户标签鉴权构成； 内容中心主要以视频基础信息、视频解析、视频分发、视频标签等媒资处理构成； 社区中心主要包含评论、弹幕交互、社区广场； 市场变现中心主要包含活动、任务、广告、商城、支付等内容； 数据中心以智能推荐、海量数据搜索、业务风控等构成； 中间件层主要包含kafka、redis等高并发场景组件，并且采用了mysql、mongoDB、Elasticsearch、Hbase等多元化数据存储方案。整个业务容器由CCE进行托管编排，并且采用了ASM进行服务的韧性保护。
随着人人视频业务蓬勃发展，其架构模式也进行了多次迭代调整。早期由于业务量级不够大，架构上也缺乏相应的容错机制保护，比如未采用熔断机制进行微服务治理。此架构模式下，当下游服务出现故障时会积压阻塞上游服务的请求，从而使得上游服务进行级联性的崩溃，最终导致服务集群的雪崩而完全不可用。
为解决此致命性问题，我们在架构中引入了hystrix熔断保护机制。此保护模式下，当下游服务出现故障时，上游服务能快速的对下游服务采用熔断降级的措施，从而使得该服务不会受到下游异常服务的影响。
下面主要介绍hystrix配置在人人视频的实践，例如在updateUser场景主要设置coreSize为20，maximumSize为40，maxQueueSize为1000，queueSizeRejectionThreshold为800；此设置和基本的线程池原理一致，当业务请求创建的线程数还未达到coreSize时会新建线程去处理，当创建的线程数达到coreSize之后的业务请求会放入队列等待处理，当队列里等待的业务数达到maxQueueSize时会再新建线程处理，直到达到maximumSize。这是hystrix的一个线程池设置，此时我们又该如何设置熔断触发的参数。熔断触发主要由断路器参数进行控制，比如我们在默认的时间窗10s内至少有200个请求（requestVolumeThreshold：200）并且错误率达到了50%（errorThresholdPercentage：50）即触发熔断，触发熔断10000ms（sleepWindowInMilliseconds：10000）后会释放少量请求去探测下游服务是否正常，如果正常则断路器关闭，后面的所有请求则正常请求下游服务，如果不正常断路器则继续打开直到下一个休眠时间后继续探测下游服务正常与否。
但随着业务架构的不断迭代调整，使用hystrix进行熔断保护的弊端也随之产生。当前人人视频正在利用go语言的优势将BFF层服务采用go进行重构，但由于hystrix组件的语言限制，并不能在go的框架中进行使用，并且hystrix的使用代码侵入性强，比如需要引入相应的jar包，使用相关的注解，开启相关的配置等。并且当我们需要使用限流方案时，hystrix也不能直接提供成熟的解决方案。当我们使用混沌工程来进行正常业务的故障注入以便更早的暴露出问题时，hystrix也将无能为力。针对这些问题，我们也在探索一些新的方案来解决，实践证明网格等云原生技术能很好地解决业务中碰到的这些问题。
服务网格韧性实践 下面我们介绍服务网格的云原生解决方案中，如何提供完整的韧性能力，在实践中帮助用户商业成功。
在基于云原生的韧性方案中，我们不只提供了面向应用的熔断器，而是提供了从开发、测试到基础设施，到应用运行的整个韧性保证。也包括运行期的Ops，保证快速发现问题，进而解决问题。从而做到故障模拟与测试、隔离与恢复、定界与定位等全纬度的处理。进而避免故障蔓延与故障影响业务，特别是对核心业务的影响。
熔断 Circuit Breaker 左图是项目中之前实施的经典的Hystrix的状态迁移图。一段时间内实例连续的错误次数超过阈值则进入熔断开启状态，不接受请求；隔离一段时间后，会从熔断状态迁移到半熔断状态，如果正常则进入熔断关闭状态，可以接收请求；如果不正常则仍然进入熔断开启状态。
网格中虽然没有显式提供这样一个状态图，但是Istio中异常点检查的阈值规则也都是这样设计的。两者的不同是Spring Cloud的熔断是在SDK中Hystrix执行，Istio中是数据面proxy执行。Hystrix因为在业务代码中，允许用户通过编程做一些控制。
下面看下网格的熔断实施的效果。这是一个典型的故障场景。其中一个服务实例故障，当没有进行任何故障处理措施时，流量还是均衡的分发到三个实例上，对于服务访问者而言，将会有三分之一的几率得到失败的应答，影响最终用户的业务。
**韧性的重要一点要求是故障发生时不影响用户最终业务。**对于这种部分实例故障，基于网格的异常点检查，隔离故障实例使得请求只发到健康的实例上。具体规则是：考察服务实例的访问情况，在一段时间内如果连续失败次数达到阈值条件，则该实例会被隔离，得不到流量。
如图配置：当一个实例在4分钟内，连续5次502 503 或504故障，将会被隔离10分钟；在这10分钟里，隔离的实例会被标记为不健康，不能得到流量。在10分钟后，这个实例会被自动加回来，尝试重新接收流量。如果继续检测出是故障，则隔离时间会加倍。如这个例子中，第二次连续故障会被隔离20分钟，下次30分钟，从而使得一直故障的实例一直被隔离，减少对业务的影响。
**隔离故障的详细过程如下：**从拓扑图上可以看到第一个实例异常满足熔断阈值，触发了熔断，网格数据面向这个故障实例上分发的流量逐渐减少，直到完全没有流量，即故障实例被隔离。
这样，所有访问流量只会分发到两个健康实例上，通过这种熔断保护保障服务整体访问的成功率。
**除了隔离外，韧性中另外有一个非常重要的要求是系统的故障自愈能力。这里三个流量拓扑演示了从刚才的故障中恢复的过程。**可以看到：初始状态这个故障实例被隔离中，没有流量；当实例自身正常后，网格数据面在将其隔离配置的间隔后，重新尝试分配流量，当满足阈值要求则该实例会被认为是正常实例，可以和其他两个实例一样接收请求。最终可以看到三个实例上均衡的处理请求。即实现了故障恢复。
网格熔断提供的另外一组保护机制是非侵入的连接池管理。可以对四层的连接，七层的请求进行限制。当实际的连接和请求超过配置的阈值时，则断路连接，从而保护上游的服务。
          
          
        
      </description>
    </item>
    
  </channel>
</rss>

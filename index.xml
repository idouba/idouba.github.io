<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爱豆吧！</title>
    <link>https://idouba.com/</link>
    <description>Recent content on 爱豆吧！</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>浙ICP备18050493号-1 浙公网安备 33010802006262号</copyright>
    <lastBuildDate>Wed, 02 Oct 2024 15:32:08 +0000</lastBuildDate><atom:link href="https://idouba.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>云原生工程师入坑AI深度学习系列（一）：从线性回归入门神经网络</title>
      <link>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-from-linear-regression-to-neural-network/</link>
      <pubDate>Wed, 02 Oct 2024 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/cloud-native-engineer-learn-deeplearning-session1-from-linear-regression-to-neural-network/</guid>
      <description>
        
          
            背景 最近团队的业务除了面向通用计算外，越来越多的要处理面向AI场景的软硬件资源的供给、分发、调度等。虽然还是在熟悉的云原生领域，折腾的还是哪些对象哪些事儿，适配到一种新场景。但为了避免新瓶装老酒，能有机会做的更扎实，做出价值，对这个要服务领域内的一些东西也想花点时间和精力稍微了解下。
国庆长假环太湖一圈回来，假期最后这两天豆哥被要求上课，正好难得集中时间可以稍微看些东西。暂时没有精力系统地构建，先入个门。作为一个云原生领域的从业者，目标是知道容器里跑的是什么，怎么跑的。
学新东西时习惯用自己的文字，尽可能简单易懂地总结记录贯通下，做不到严谨、全面、深入、专业。开始前定个小目标只要做到基本的通、透、够用即可。
说干就干，先从深度学习基础技术神经网络开始。Google一把，内容可真叫个多。确实最近身边不管曾经做什么的，摇身一变都能与AI扯上关系。这么多信息对我们这些局外人非常不友好。很多年前自学数学等相关基础课程时，习惯从稍微了解点的东西入手，有点脸熟的东西看着不怵。重拾十来年前尚老师Data Mining那门课程的部分内容，看看老的概念和新的技术能产生哪些联系。
切入点线性回归 线性回归可能是一个比较适当的切入点，模型简单好理解。线性回归时通过一组数据点来拟合线性模型，找出一个或者多个特征变量和目标结果之间的关系，有了这个关系就可以带入条件预测结果。一个非常经典的线性回归例子就是二手房价预测。
影响房价的因素很多，记得当时书上形式化表达是用了一个向量乘法y = wx + b。x向量由（x1,x2,x3,x4）组成，表示若干个属性。这里简单示意下假设只有两个因素x1、x2，分别表示屋子的房间数和面积，也不用向量乘了，就直接写成 y = w1 * x1 + w2 * x2 + b，y就房子价格。其中w1、w2和b称为线性回归模型的参数，w1、w2称为权重weight，b称为偏差bias。
可以看到，作为一种最简单的回归模型，线性回归使用这种线性回归方程对一个或者多个自变量和因变量之间的关系进行建模。有了这个假设的模型，就可以根据已有的二手房成交记录求解出模型上的参数w1、w2和b，这就是老听说的模型训练。完成模型训练求解出线性回归模型的参数，就可以把房间数、面积x1、x2带入表达式，得到房子的预测价格，这就是一个推理过程。
这个一个简单例子把模型的的表达、训练和推理过程最简单地顺一遍。省略了太多的信息和步骤，迭代着加上去应该就是关注的神经网络的关键内容。
首先是模型的表达，通过最基础的数学知识，这个线性回归的输入、输出和运算过程可以大致画成这样。
即使完全不了解神经网络，基于最朴素的概念理解，瞅着这个图上这些点的关系好像也已经和神经网络有点神似了。
神经网络的概念 神经网络这个典型术语标准定义很多，总结下简单理解神经网络就是一种模拟人脑处理信息的方式。从数据中获取关联，在输入和输出中建立关系，特别是复杂的输入和输出之间。类似我们人脑中神经元构成一个复杂、高度互联的网络，互相发送电信号处理信息。神经网络由人工神经元组成，在这些神经元上运行算法，求解各种复杂的模型，所以我们说的神经网络完整点描述其实是人工神经网络。
只是从外形简单比较，前面线性回归那个图看上去像一种单层或者单个神经元组成的神经网络，大致可以认为是神经网络的一个简单特例。
神经网络的结构 经典的神经网络包括输入层、输出层和隐藏层。
**输入层：**接受外部输入的数据，将数据输入给神经网络，简单处理后发给下一层。在预测房价这个线性模型中，输入层就是影响房价的两个属性。在另外一个典型应用图片分类中输入层就是像素，如100*100像素的图片就又10000个输入。 **隐藏层：**神经网络中大量的隐藏层从上一层，如输入层或者上一个隐藏层获取输入，进行数据处理，然后传递给下一层。神经网络的关键处理都集中在隐藏层，越复杂的模型、表达能力越强的模型，隐藏层的层数越多，隐藏层上的节点也越多。 **输出层：**输出神经网络对数据的最终处理结果。因为模型固定，输出层的节点数一般也是固定的，如上一个房价预测线性回归的图中，就只有一个输出。如果是分类的模型，一般有几个分类，就对应输出层有几个节点。 不考虑内部复杂实现，只看这个外部结构，从我们程序员的语言看，一个神经网络就像我们编程的一个方法。输入层对应这个方法定义的入参，输出层对应方法定义的返回值，隐藏层可以简单类比我们的方法实现逻辑。模型训练好后，去做推理时就是传入参数调用这个方法，得到返回值的过程。
从数学的视角可能更准确一些，一个神经网络对应一个映射函数，输入层对应函数的自变量x1、x2，输出层对应函数的因变量y。训练过程就是找到函数表达式中的各个参数。有了这个求解的函数表达式，其他任意参数x1、x2带进去也能得到相应基本正确的y。
作为映射函数，只要有一组输入就能映射到一组输出。除了这个根据房子大小、房间数映射出房价外，其他更强大的神经网络可以拟合更复杂的函数。对于大多数深度学习的应用，虽然我们没有办法像这个预测房价的例子这么直观地写出一个具体表达式，但还是可以理解存在这样一个函数映射，或者说通过训练有办法逼近一个理想的函数映射。
记得从哪里看到黄教主说过“AI深度学习，也是一种解决难以指定的问题的算法和一种开发软件的新方法。想象我们有一个任意维度的通用函数逼近器”。如果设计的神经网络足够深、参数足够多，足够复杂就可以逼近任意复杂的函数映射。不只是预测房价这个简单的线性回归，也不只是当年学习的Han Jiawei的Data Mining课本上的分类、聚类、啤酒尿布频繁项这些业务固定的应用。
为了便于理解把以上简单类比总结成下表。
神经网络 程序视角 数学视角 模型 代码方法 映射函数 输入层 入参定义 自变量 隐藏层 方法体实现 函数表达式 输出层 返回值定义 因变量 训练 构造实现并UT验证修正 求解函数参数 推理 实际方法调用 带入新的自变量求解因变量 样板特征 Feature UT测试用例输入 已知的符合表达式的自变量取值 样板标签 Label UT用例预期输出 已知的符合表达式的因变量取值 以上两个临时起意的类别，前一个更像神经网络的物理存在。不管多复杂的神经网络，最终都是一个方法调用。实际应用中通过Restful接口或者其他应用协议调到推理服务上，获得一个输出，返回给调用方使用。而数学的这个类比更像神经网络的逻辑定义，模型本身的定义和模型训练、推理过程。
          
          
        
      </description>
    </item>
    
    <item>
      <title>豆哥国庆环太湖Day2：三国城（宜兴-无锡-常州）</title>
      <link>https://idouba.com/doudou-and-douba-drive-around-taihu-day2-sanguo-city/</link>
      <pubDate>Wed, 02 Oct 2024 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/doudou-and-douba-drive-around-taihu-day2-sanguo-city/</guid>
      <description>
        
          
            路线： 游记： 第一天晚上豆哥做完作业早早睡着了，简单规划了下第二天的目的地。和第一天一样，不规划详细路线，定个目的地就开过去，沿路随意。 在无锡一众鼋头渚、拈花湾、蠡园选择了三国水浒城，豆哥在很小时候就收集了三国人物卡，经常对其中人物战斗力智慧值有不同见解。现场体验下应该会很兴奋。
预订的双床房不太好，临时升级了高级大床房。一晚上俩人抢被子盖，没抢过他。早上挺早就起来吃早餐。早餐很简单，和豆哥之前出来旅游经历的丰盛自住早餐不同。我吃了玉米红薯馒头稀饭，豆哥给自己烤面包见番茄酱，热牛奶。
养成了个不错的习惯，下楼吃饭前各自整理各自行李，房间收拾干净，吃完饭拿行李时再检查一遍，确保没落下小东西。起床时说好了，不同于之前总住一个酒店房间，这次每天换一个地方，敏捷机动，要随时收拾好东西准备转移。
出门开车，比起昨天的大风天，天气晴好，在小县城的街道里开着很惬意。但得开得更小心，因为随时有横穿马路的行人，还有不打转向灯随时快速变道的车子。出了县城沿范蠡大道一直开，比昨天的高速还通畅，偶尔还能飞过太湖水流过来的某个大桥，开得很舒服，豆哥坐在后排那叫一个惬意。
好心情在一个拐弯就戛然而止，下了范蠡大道，拐进了一段好像叫周铁的县道，路窄车多。穿过村庄穿过庄稼地，就到了另外一段太湖边。明亮的湖面，和昨天湖州那边湖至少有两点不同。第一颜色没有那么黄，更清澈。第二湖面基本没有浪，很安静，猜想可能与昨天大风天今天大晴天有一点关系，更重要的应该还是不同区域自身不同的水文特点。早上九点多的太阳照在湖面上，在透过车窗反射到眼里，微微有点刺眼。但不是草泥马的远光灯那种，不难受。就想起豆哥作文中描写西湖湘湖用烂了的四个字：波光粼粼。
经历了刚才堵车的焦躁，幸福来的太突然。俩人都还没缓过劲来。不知道豆哥有没有领悟到，这就是生活。
故意减慢了速度，沿着湖一直开。开过一段常州的太湖，很快又进入无锡的太湖。路边走一段就有各种湖边绿地上露营，车子沿公路两边停的满满当当。因为赶时间，没有来及下车停留，和豆哥商量，地址Mark下了，下次带着妈妈一起来这边湖边走走看看。地址好像是中华孝道园附近。
再往前就进入无锡市区了，能看见公交和地铁站了。车很多，和杭州一样多，特别是进景区的地方，和杭州一样堵。四五个车道，满满当当，看不到头。
排着队一点点往前，经过一个大十字，就进入了市区的湖边，应该是湖边的市区，其实就是景区。豆哥说和杭州更像了，右边的湖，湖边的路，路边的树，树下的车 一模一样。这个角落的太湖，湖水和湖边的小风景都和西湖很像。不同是西湖看远处能看见尽头的群山，这里看远处，没有边。
车子沿湖再前开过一段树荫的小路，和闻涛路一桥往西的一段感觉很像，按照导航停到了无锡蠡湖八号酒店。这边有一点点开阔，车子路边就可以停。跟着一个接驳大巴前往三国水浒城。越接近越堵，最后一段八百米走了十几分钟。
门口的文字提示这里的标准名称是：中央电视总台无锡影视基地。
我们进的门是水浒城，左右两边分别是一百单八将的名号，前面四个铜人分别是武松 李逵 鲁智深和林冲。和其中几个匆匆合个影，豆哥就急着去找卢俊义。费了半天劲，终于在宋江附近找到了。然后才检票进去。
导游鼓动大家买电瓶车的票，说指着地图说从一边到另一边有多远，豆哥很兴奋地说那样走起来才得劲。全车就这爷俩没被忽悠观光车。
进来第一感觉像北方的小公园，可能是为了复现山东好汉的生活，里面的树木各种都更像北方的，个别地方有点像济南的大明湖。
第一站水泊梁山，可惜晁天王们的聚义堂关闭了，只在山下看了看。沿着湖往前瞎溜达，走进了一个小村庄，看介绍是阮氏三兄弟的家，水浒传里劫生辰纲就是在这里拍的。
湖面上不断有各种游船里里外外，停靠水泊梁山码头。等了大半个小时终于等到我们的船，不同于前面看到几艘多层华丽又威猛的大船，这是一艘只有一层的小体格游船，豆哥还有点失望。登船一看船头的旗号“诸葛”，原来这是孔明先生的船。
不同于穿梭于景区里面，会有一种只见树木不见森林的感觉，从湖上游船上在一个较远的视角更能感受到全貌。水泊梁山的山头，外侧无边的太湖水，内测沿湖修建影视城，先是水浒城、然后是三国城。比起水浒城的各种小场景，前方的三国城要宏伟的多。宏伟到了极致的是诸葛游船的终点——东吴水寨。
电视里三国演义这段场面已经完全不记得了，眼前高大的营寨大门立在无边的太湖水中，透漏出的霸气和威武视觉上非常有冲击，特别是从游船上远眺，到船靠近时的仰望。有点像被周大都督检阅的感觉。
要说检阅那必须是周瑜点将台。下了码头豆哥就带着爬上了这个大高台，就在水寨的附近。豆哥擂了鼓，还和周都督合了影。
水寨门口的周都督的操练场上操练了一把，天气很好，参与的很欢乐。
周瑜点将台往太湖边上走一点就到了周瑜的死对头诸葛亮借东风的地方。雕塑的诸葛亮披头散发地持剑正在作法。比起刚才对周瑜的热情和仰慕，豆哥对这个孔明先生貌似不太感冒，围着转了小圈就拉着下到跟前的太湖水边去看风景。
今天早先都是站在高处观看湖水，这会儿才有机会跟湖州那边一样，能俯下身子，去感受湖水。发现这里的湖水也有浪，虽然没有湖州那边的浪大，但也有节奏地拍打着脚下的湖边大石头。
沿湖走走就又走到了水寨。刚才下了船就只是乘客身份从水寨里穿出来赶路，这会儿才真正游客身份在水寨前观赏。不同于水上视角的广阔雄伟，在岸上看是另外一番气势。特别是迎风呼啦啦响的东吴军旗后面一艘艘战船忙碌地穿梭的背景，威武之外多了生动和活力。气氛到了，豆哥跟东吴军旗的合影也显露了几分英姿飒爽了。
穿过深入到湖中间的一长段水上走廊，又经过岸边的一个孙尚香饭堂、微缩版的赤壁战船群。来到了岸上最雄伟的建筑吴王宫。@TODO豆哥补充
然后穿过桃源三结义的花园和曹操点将台，终于找到了豆哥进入院门就心心念的三英战吕布马场。整个表演场的面积跟一个足球场差不多大。或者还要大一点，马跑的场子当然是比人跑的要大。提前四十分钟到现场，已经满满当当了。往里走有个坐第一排的热心人挪了挪给我们俩挤出一小块位置，坐进去迎着下午正热的太阳那叫一个晒。虽然前排有人撑伞，但是两位绅士考虑到可能影响后排人看表演，还是选择了硬扛。扛了一会儿，发现比大太阳更刺激的，更刺鼻的是浓郁的马粪味道，第一排离得最近，味道最爽。平时有点矫情的豆哥这次却非常淡定，想着半个小时后就要开场的三英战吕布这一切都是值得的。
果然，表演的精彩大大超出了我们的预期。@TODO豆哥浓墨重彩描述 出来又回到吴王宫观看一个盛大的表演刘备招亲。三国演义中周瑜给孙权献计假传把孙权妹妹孙尚香嫁给刘备骗刘备来到东吴。场面确实很华丽壮观，豆哥却完全没有兴趣，嘀咕繁琐无聊。小哥还是年轻啊！安抚着既然来了还是看完。
表演不好好看，小哥却给我总结他整个三国片场的感想：三国演义中虽然蜀国戏份最多但是硬件实力最弱，你看整个三国城没有蜀国一个特有的拍摄景点，估计就是室内或者战场上一般的情节 但是东吴和曹魏就不同了，各种营寨、宫殿、点将台等设施。这个有意思的特征在刚才桃园三结义后面那组三国人物雕塑群上都暗示了：曹操领着一群大将骑着马，东吴孙权和他的几个大将站在家个战车上指挥战斗，而蜀国这边，刘备领着诸葛亮关羽张飞和零零碎碎几个士兵站在哪里。这不正说明了东吴有车，曹魏有马，刘备啥都没有吗？ 有图有真相，小哥分析的对啊。
至此三国城就完整游览了一遍。豆哥领着我又通过园区陆地杀回水浒城，目的地是水浒城的一个武松斗杀西门庆的表演。第一次现场看到这样人被威亚吊着飞来飞去，打打杀杀，豆哥看得很过瘾。
出来时已经天慢慢黑了，在门口宋朝市集上各吃了一碗小面，就继续水浒城的游览。进到一个县衙里豆哥和一群大的小的男孩对那些刑具表现出了兴趣，林冲的枷锁非都往自己身上招呼，还让大人给拍照，结果都被拒了，有个小朋友还被他奶奶收拾了 。
再穿过松江家的宅子和几个院子里这个时间里面灯光暗淡，进去瞅一眼就都马上出来了。直奔宋皇宫，据说宋徽宗这个才子皇帝今晚要展现才艺，来一场精彩的表演。
宋徽宗的Rap开场非常劲爆，华丽的宫殿，秀丽的灯光，配合着徽宗的律动和音乐，因引爆了现场气氛。豆哥和其他大部分游客一样在皇宫台阶下的石板地上席地而坐，挥舞着荧光棒，很享受这个热闹的气氛。
皇宫节目挺丰富的，都很精彩。暂告一段落时宫里公公宣布等下这边结束了徽宗还要到市集上与民同乐。
豆哥虽然还想接着看，看着已经快八点了，想到今晚落脚点不在无锡，而是在常州，决定还是抓紧赶路。
出门打车到停车地方，导航常州恐龙园隔壁酒店，一脚油门朝北狂奔。无锡上高速前的高架隧道都很畅通，加上高速六十公里很快就赶到常州，还没下高速恐龙的各种信息就扑面而来。豆哥发现这里从高速到市区的很多路牌上都是恐龙相关的园区设施的指引。下了高速跟着导航很快就到了酒店。
第一次住这种没有前台的酒店，俩人都有点不习惯。车子开到地下车库找车位费了点劲，最后找到了一个划为人防干厕所的位置停下来，捎带给豆哥讲了半天车库和人防的关系。还不容易从车库电梯到地面，找到酒店入口，上楼到房间所在楼层，手机蓝牙开门终于进到房间。
看着房间落地窗下正对着的恐龙园的五彩的灯光，豆哥对这个位置很满意。洗洗睡了，攒足精神明早早起杀向恐龙园。
          
          
        
      </description>
    </item>
    
    <item>
      <title>豆哥国庆环太湖Day1：遇太湖（杭州-湖州-宜兴）</title>
      <link>https://idouba.com/doudou-and-douba-drive-around-taihu-day1-first-touch-taihu/</link>
      <pubDate>Tue, 01 Oct 2024 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/doudou-and-douba-drive-around-taihu-day1-first-touch-taihu/</guid>
      <description>
        
          
            帮豆哥流水账地记录下国庆五天环太湖的经历。这是第一天。
路线： 游记： 因为一些状况，临到放假前一天才定了行程，没法和之前一样跑到很远的一个目标地，爷俩就开着车周边闲逛，不涉及机票高铁票，也不提前订酒店。国庆当天各自收拾了一个小箱子，一个背包。豆哥除了给自己的卡拉羊小箱子里塞了五/条内裤五双袜子外，还带了不少书和作业。
出发时已经十点了，导航设置先到达湖州的新港口灯塔，然后开始环湖。
出门两三公里就堵在了复兴大桥入口，上了高速只是偶尔小堵一阵子，因为车多或者高速上追尾事故。
下午两点钟到达新港口灯塔附近。掉了两次头才把车停在一个桥下，踩着泥地冲到灯塔下。湖边风很大，俩人都穿上外套还是有点冷。终于见到了心心念的太湖，停车的第一站，俩人都很兴奋。迎着风冲到灯塔下。
习惯了西湖那种城里的一滩水，第一次见到太湖这种看不到边际的湖水，豆哥感叹，这哪是湖啊，明明就是海啊。湖里浪伴着大风拍打着岸边的水草，和西湖那种安静完全是不同的体验。
在灯塔短暂停留后，豆哥在一块石头上刮干净脚上的泥就窜上了车，继续环湖前行。咕咕叫的肚子提醒得找个地方吃点东西。
没走多远，就被路右边湖里一个圆形的建筑吸引了。靠过去靠过去，豆哥指挥着，完全不管规划的途径点还有一公里。绕了一圈才找到入口，原来就是传说中的月亮湾。人挺多，简单转了转就赶紧找地方吃饭。步行导航到一个太湖渔村的饭店，门口服务员通知说中饭已经结束了，需要在等半小时厨师吃好饭才能开始晚饭。豆哥饿得半分钟都不想等，拉着就往前冲，准备找前面大食堂先来碗面。幸运地半路上碰到了一家还在营业的餐厅，俩人点了个188的套餐，鱼、虾、蛋、蟹、鸡、肉、豆腐、青菜一大桌。有些吃的惯，有些不太惯，但吃的很饱。饭店紧挨着湖水，打算紧挨着湖水走回去找车，发现因为风浪太大，临近湖边的木板走廊都被拦起来了。
找到车继续往前开，跳过几个途径点直接到达太湖观景台。其实就是西边太湖边一个小平台，不是想想中的一个大高台。站在湖边的大石头上迎着风拍照还是很拉风，不知道那一波浪就能排到脚后跟上。豆哥最拉风的是这里的一个小插曲。这边属于比较荒的小景点，没有公共卫生间，小哥急了就拉我去公路对面小树林解决，茂密的树林下是一个大河沟，担心滑下去，前进到差不多不影响马路上市容，正准备行动。突然正前方，不对准确说是正前下方传来一阵紧急的咳咳声。这是含蓄的信号在警告我们这个不文明行为啊。“stop，小心，你们下游前面深沟里有人！我知道你们要干什么，因为我正在以比你们更低的姿态做类似的事情。”爷俩会意赶紧撤离现场。
回到车上正准备挪车走，一个穿着礼服的年轻人示意我们能不能等等再开走。原来车侧面拍婚纱照的新娘正在换道具。咱家稍微高点的车居然无意中帮了人家这么大一个忙。
接着往前开这段一直紧贴着湖边，豆哥看的惊叹得都词穷了。湖边道路对环湖骑行非常友好，不但有紧挨着湖边的骑行道，每隔一段还有个骑行休息区。
湖边骑行的人很多，估计都是借着这个假期在地图上在自己的心里画一个完整的圈，有一群群很专业的公路车速度很快地竞速，也有一个个山地车托着行李缓慢前行。
问豆哥咱明年也这样来一圈，装作入神地看风景，没有回应。
就这样贴着湖开了好长一段，开得很惬意，很放松，开车的人，坐车的人，还有车子，都很省油。傍晚了，湖边村子里的袅袅青烟升起，风好像也小了，湖里的浪也小了。车外面安静了，车里面豆哥经历了刚才无边湖景的兴奋，也安静下来了。
直到一个导航提示左转的路口。“导航怎么提示左转呢，分明前面这个变窄的公路还可以往前开，还可以离湖边更近，我还没看够呢”。好，那咱就继续直行。
“怎么开了这么久，前面一辆车没有，后面也一辆车没有，连骑行的也没有了，咱只碰到过一群本地老太太傍晚散步的，爸，还往前不，天快黑了，有点慌啊”，豆哥提醒我。“没事，前面总有个左拐的地方开到大路上去”。
确实在尽头有个左拐的涵洞穿过这段临湖的高速公里。涵洞很窄，左边高一点应该是非机动车和行人，右边是机动车，里面好像有一点积水。老司机谢谢咱这虽然是城市越野，也是高底盘的越野，正要往里开。“咱家车是不是太高了啊，我看水面里这个顶好近啊，咱家车钻不过去吧”副驾驶豆哥提醒。对啊，下车检查下看。不看不知道一看吓一跳，这水面到洞子顶太近可不怪涵洞挖的矮，只是因为水太深了。刚才是准备要重进一个深水池啊。
想想这前不着村后不着店的地方，天已经慢慢黑下来了，刚才如果一脚油冲进去…，想想都后怕，掉头沿原路赶紧往回跑。
和刚才开过来一样，路上没有车。
和刚才开过来一样，湖水还很美。
导航经过的下一个途径点是香山公路驿站，我猜是跟刚才几个一样的小景点，豆哥说根据名字判断他觉得就是给那些骑车人休息的地方。
豆哥蒙对了。比前面经过的那些休息点大一些，但就是个休息点。天已经慢慢黑了，抓紧赶路，也就没有下车。在车上对着这个1314号驿站随手拍了张照片，照片的C位是副驾驶位置豆妈给车子装饰的车载人。给豆哥说，一生一世，这个照片送给妈妈，虽然这次旅行她没来。豆哥没有像平时一样表达不屑或硬抬杠，好像嗯了一声好像没出声。可能是累了，我猜想是想妈妈了。
到酒店的规划的最后一个途径点是蜀山古南街，越开路越窄，人越多。天彻底黑了，跟着导航行驶在黑乎乎的小镇上，会车都要小心点。豆哥说饿了要么直接去酒店，安顿好再来。行，修改目的地，不到十分钟就到酒店了。
这趟出行前，提前和豆哥沟通过了，咋俩大老爷们，不用想你小时候一样总是订很好的度假酒店，有个地方睡觉就可以了。预期管理的不错，房卡刷开门，豆哥很满意。
看大众点评酒店对面人民饭店的韭菜鸡蛋饺子不错，就过马路冲进去。饭店里晚上有宴会刚结束，三三两两酒足饭饱的城里人正在饭店寒暄。应该是县城顶级的饭店，很亮堂，服务员说饺子不单卖，是一大桌招待的那种俩人出来边找别的饭店边给豆哥讲“之前在人民饭店上班的都是工人，我舅舅你舅爷就在我们县城人民饭店上班”。
在人民饭店正对面找到了另外家饺子店。饺子很大，大胃王的爷俩居然都没吃完。豆哥说他们是不是上错了，十二个咋这么大。我说你审题仔细一点，人家是十二块钱十五个，不是十五块钱十二个。
吃饱回酒店豆哥洗完澡换上睡衣给妈妈视频，介绍自己今天精彩的旅程，特别是观景台那段精彩的经历。然后掏出课本做作业，计划两个小时，结果不到一个小时就困得直打哈欠。
睡吧睡吧。
“爸爸，前面是个铁索桥”晚上梦话一大堆，就记住了这句，估计还在继续他的精彩旅行。
小县城这个小酒店睡的很安静舒服，下午那会儿还想临时改成湖州太湖旅游度假区那边酒店，感谢豆哥的坚持，让今天的旅行如此精彩。我们明天继续。今天的地图如下，明天我们继续环起来。
          
          
        
      </description>
    </item>
    
    <item>
      <title>豆哥军训归来</title>
      <link>https://idouba.com/doudou-military-training/</link>
      <pubDate>Sat, 14 Sep 2024 11:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/doudou-military-training/</guid>
      <description>
        
          
            豆哥，你哪天军训回来激动地给爸爸讲的四天训练营里各种有意思的事，真的很精彩。说到兴奋处你在咱家小客厅里给老爸一个人来了一段队列汇演。老爸生平第一次像个老首长一样地坐着检阅队伍，那个感觉还是相当不错滴。你讲了很多，包括你说开营第一天教官喊着对你们说话，当他凑近到你脸跟前给你说话时你都吓了一跳。后来慢慢就适应了，反倒是返校后排队时王老师温柔的指令声有点听不清楚。
但你老爸讲的所有这些中，印象最深刻的是你说自己训练第一天的故事。你说第一天队列练习时，第一次这样比较长时间的站立，你感觉自己有点站不住了，硬撑了一会儿还是有点不行，就给教官打报告出列在边上坐下来休息了一会儿，然后再申请入列参加训练，一直按照要求完成了当天和后面几天的训练，从中获得了不少乐趣。
因为是你自己亲身经历，你描述的生动，又详细。对着老师发的你穿迷彩服的照片，我脑子里能形象地回放出我儿子当时的表情、身体动作、甚至是细节的面部表情和心路历程。 这几天老爸脑海里总是反复回放着这段生动的电影画面。作为父亲，我的第一感觉是心疼。从你小时候开始，爸爸希望你经历的总是顺利、快乐、轻松。幼儿园或者小学刚开始任何的小的事件都会让我紧张。但随着你长大，老爸也成长了，甚至有些从容淡定了。老爸能平静接受发生在你身上一些不顺利、不理想，挫折、失败和眼泪。这些都是你成长过程中自然而然应该经历的。老爸静静地观察着你经历这些的反应，关注着这些挫折困难带给你成长的积极价值。
就像这次一样，你给我描述了当时的情况：“我有点坚持不住了，教官允许我们几个坐在旁边休息下。我休息了会儿，感觉好些了。虽然我觉得教官应该允许我再多休息一会儿，我自己也觉得到再多歇会儿真的很舒服。但我担心一直这样舒服着，会跟不上团队其他人的训练，后面可能就都跟不上了，我就掉队了。所以我就给教官报告归队了。”
老爸很欣慰，甚至有点自豪，你对待这个困难的态度和做出的反应。你发现没，碰到这些自己不适应的情况、需要克服的困难，只要你有意愿，有勇气去挑战，不管最终结果怎么样，一定比退却或者停留在原地要强的多。你那一刻坚持了，才能在当天挑战自己，在后面几天应急并战胜更大的挑战，回来信心满满、收获满满地给老爸讲你们训练营中各种趣事。试想你当时一念之差，想多坐一会儿，再坐一会儿，没有坚持，甚至当了逃兵。老爸接你回来，会是一个什么场景。即使老爸想出好办法来安慰你，也不能弥补挫败的感觉。
在我们的生活中，在你的成长过程中，这种时刻其实挺多的，我们鼓足勇气，过去了，除了本身学到东西，获得成长外，成就感，满足感是什么也换不来的。如老妈给我说你第一次学游泳的故事。老爸遗传给你的旱鸭子基因导致你小时候洗澡时眼睛碰一点水就大喊大叫，听说第一次到泳池你紧张哭着不敢下水，回来后还打退堂鼓不想去上课了。你后来怎么鼓足勇气跳到泳池里，你没有像这次一样能讲这么明白，但后来你成为了你们那届蛙泳新学员游得最好的。我记得你们结业考我是去了现场。你撅着自豪的屁股，作为表现最好的学员最后一个屁颠屁颠地走到泳池起点，跳下水英姿飒爽地完成了你的结业考。然后就一发不可收拾，到现在我再泳池里跟你一起游，连你的屁股都跟不上了，只能跟上脚丫子了。
更鲜活的经历是咱家最近的情况。妈妈照顾姥爷，我们不得不和妈妈分开这么久。爸爸能感受到你有多么伤心孤单，但每天我们还是按时上班上学，回家一起吃完饭后，爸爸去加班时，在家里按照之前妈妈培养的好习惯自己完成作业，做当天的复习和预习，你说作业质量还提高了呢。周末我们俩大清早起床赶高铁窜到济南，见到了妈妈。匆匆和妈妈待了两个半天，第二天中饭后吃了老济南的鲁菜我们就又得返杭了。虽然有很多不舍，在出租车上你还是安慰自己说分开有一点点难过，鼻子有一点点酸，但是昨天哭过了，今天不是很难受。妈妈继续辛苦地留在济南，我们坐着高铁返杭继续我们的工作学习，然后等着妈妈回来。
从你的身上老爸看到了长大的男子汉身上的力量、勇气和希望。
勇气，能指引我们去做自己认为对的有价值的事情。除了这些让自己感觉极端不适的困难外，也体现在我们平时生活中。养成习惯那就是勇敢，就是自律。就像今天晚上老爸重要把充电器从公司带回来了，吃完晚饭你给你的Pad充上电，来了把你心心念的蛋仔游戏。我能看到你真的很喜欢，明天就是三天的假期，可以放松多玩会儿。你还是在你自己规划的40分钟（额定30分钟加上周补10分钟）后合上了Pad。老爸发现你有很强的自律能力，看电视、Pad、电话手表等这些轻松喜欢的事情，喜欢搞搞，但会控制。周三晚上咱俩给你换新手表，吃完晚饭没有刷碗就折腾起来了，为了保证旧手表的数据能完整导入到新手表，我们查说明验证操作多花了些时间，看到八点多了还没有搞好，你觉得到了作业时间了，在这个上面花的时间超了不让我搞了。幸亏后面五分钟内解决问题，才没有耽误到你的计划。’
自律真的是非常了不起的品质，如果能养成习惯，会让我们一生受益匪浅。想着多少大人打游戏或者刷着短视频一直停不下来就能理解做到是多么不容易，爸爸直播吧一打开就停不下来，五大联赛赛况看完了，周边各种各种无聊新闻刷不停，像你学习。爸妈不会强迫你苦行僧一样的只许做这个不许做那个。希望你能按照自己的方式管理好哪些做哪些不做，哪些啥时候做，做多少，做到什么程度。一直这样坚持下去，养成习惯。时间会告诉我们不同。
又啰嗦了。在隔壁房间啪啪的敲键盘声音是不是吵到你了。给你搞了杯热水才打发回床上。我也睡了，明早跑步不叫你了，开学确实没有睡过一次懒觉。
          
          
        
      </description>
    </item>
    
    <item>
      <title>开学第一天和豆哥奇妙的拼车之旅</title>
      <link>https://idouba.com/doudou-first-day-of-new-term/</link>
      <pubDate>Sat, 31 Aug 2024 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/doudou-first-day-of-new-term/</guid>
      <description>
        
          
            很奇特的一段旅途。早上和儿子拼车，八点一个去学校参加开学的军训，另一个继续往机场赶十点的飞机。 老妈不在家这周，咱俩过得凑合没饿着。
每天，你早晚上课，中午下午在家。有时有点忙，大多数时候监控里的身影有点无聊寂寞。我在单位一如既往地忙，好几次两路会议同时进行时，还再加入你的手表来电。
早上，你撅着屁股还在睡，我冲下楼快速扫荡中饭和晚饭的菜。回来叫醒你，你洗漱，我也洗漱。你端盘子我拿粥碗，一起吃完早餐。中间经常你要紧急窜洗手间，搞得我们时间更赶。八点二十开车送你去上课，八点四十我到单位上班。
中午，你在家洗好择好菜，你知道当把电饭煲那个柴火饭按钮按下后一个小时，老爸一脚油就冲回来。厨房一顿瞎操练，咱中午饭就有了。你说老爸现在脱离小红书也能给你做一顿管饱的午餐，我说我得有时间看。
傍晚，重复中午的流程。换了菜单，流程不变，时间更短。你六点半有课，我七点有活要干。
每顿，我快速洗刷油多的几个锅和盘，马上赶回去上班，给你留下几个油不多的碗。 第一天中午回来看着你在厨房刷碗的背影，想着大家庭最近发生的事情，你老爹鼻子一酸。
感动妈妈的辛苦，这么多年边上班，每天回家把你喂养这么大，特别是每个这样的暑假。 除了三顿饭，同时还要辅导功课，理论上咱俩还没正式开展。
一周里，还没有找到时间坐下来对着书看，但我们在车上，饭桌上七拉八扯从来没有停止过。
那天，你从哪里看到青海湖绕一圈有四百公里，回想起咱之前骑行青山湖四十公里。我们讨论起前者面积大概是几个后者。你路上瞎蒙，回家在验算本上画画，发现假设形状是你之前学过的正方形，还是你正在预习下学期要学的圆形，结论居然差不多都是100。同时贯通了为什么占老师告诉你们长度单位加一个零，面积单位要加两个零。
周日，我们在西湖边和老爸当年修铁路的同事和他家哥哥一起吃了饭。两个大人聊到东北工地的很多往事。老爸捡到同事的一本英语词汇书，在工地闲着没事拿铁一局的机械材料账本抄了一些遍，回到西安，没有上过高中大学的背景就考过四级六级。然后自学考了个研究生，认识了妈妈，有了你。你估计只听故事一样的感兴趣那个叔叔讲的当时怎么帮爸爸从桥梁处转出档案才赶上西工大研究生报名，虽然不太相信英语那段，但前天你也尝试背下xdf整本读本，体验笨方法的乐趣和不同。
昨晚，你在自己房间对着王老师发的表格整理自己的衣服袜子牙膏牙刷洗发水洗衣皂，整齐排放在自己小箱子里。在隔壁房间，你老爸整理下出差材料，合上笔记本塞到包里，随手塞上剃须刀和两件衣服，准备临时安排的短差。
现在，你在学校应该见到了这几天一直心心念的老师同学，大巴车浩浩荡荡开赴未来四天的军营。老爸在南航的南航飞机上，想你和妈妈，飞行模式下写点文字，居然话多情谊浓地从杭州啰嗦到深圳上空。
飞机开始降落了，下飞机就要去赶场到地方，不得不收起啰嗦。
祝你军营生活顺利充实有收获。祝你按照自己习惯的喜欢的方式快乐成长。 祝福咱的亲人们都健康。所有人都辛苦了，所有人都还在辛苦着。老爸不时漫游在几个角色间，感受其中的压力、恐惧和辛苦。你也感受到了一些，不用担心慢慢都会好起来。
感谢你这几天的陪伴，有时我分不清是我在照顾你，还是你在照顾我。 谢谢你每天需要我。一起做事，一起扯淡，一起吃饱饭。谢谢你让我更充分参与到你的生活，除了之前教条概念的角色外，体验到有情感的父亲感觉。
最感谢学校和老师们。刚才在学校门口专门走上前给张校长打了招呼。 终于开学了，特别是四天在外面独立军训，可算歇口气了。终于不用每天早上睁开眼第一件事想着今天三顿饭吃什么，买啥菜。真真快顶不住了。。
          
          
        
      </description>
    </item>
    
    <item>
      <title>KubeCon2024：Karmda和Istio提高分布式云的负载与流量韧性的最佳实践</title>
      <link>https://idouba.com/kubecon2024-best-practice-karmada-and-istio-improve-workload-traffic-resilience-of-production-distributed-cloud/</link>
      <pubDate>Wed, 21 Aug 2024 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/kubecon2024-best-practice-karmada-and-istio-improve-workload-traffic-resilience-of-production-distributed-cloud/</guid>
      <description>
        
          
            记录在2024年8月21日在香港Kubecon上发表的技术演讲《Best Practice: Karmada &amp;amp; Istio Improve Workload &amp;amp; Traffic Resilience of Production Distributed Cloud》
议题： The Distributed cloud offers better resilience by providing redundancy, scalability and flexibility, especially for cloud native applications. However the complexity of multi-cluster workload and traffic management in hybrid or multi-cloud environment brings huge challenges in practice, such as the number of overall multi-cluster workload instances serve for customer request decreased when some unhealthy ones isolated in case of failures.
          
          
        
      </description>
    </item>
    
    <item>
      <title>KubeCon2023：基于实际案例解析Istio访问日志ResponseFlag系列</title>
      <link>https://idouba.com/kubecon2023-detailed-parse-and-reproduce-istio-response-flags-index/</link>
      <pubDate>Sun, 15 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/kubecon2023-detailed-parse-and-reproduce-istio-response-flags-index/</guid>
      <description>
        
          
            记录在2023年9月27日在上海Kubecon上发表的技术演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case 》
议题： 服务网格的访问日志在运维工作中发挥着非常关键的作用。特别是访问日志在HTTP响应码外提供应答标记Response Flags，通过针对性的标记提供有用的额外信息，帮助运维人员提高故障诊断的效率。但是Envoy社区官方文档中对应答标记的介绍非常简单，Istio社区也没有资料介绍这部分内容。在实际使用中当用户遇到包含DC、UF、UH等应答标记的日志时，很难找到权威材料参考来解决具体问题。 在本次演讲中，超盟将重现10多种生产中常碰到的应答标记的实践案例，解析每个标记的含义、产生场景，并介绍如何基于这些应答标记进行故障诊断和问题定界，进而解决案例中这些应答标记表示的问题。此外，还将解析生产用例中访问日志的6个有用的时间字段的含义，并介绍如何基于这些时间字段定界服务网格的延时相关问题。
Access logs of service mesh is practically important in ops work. Especially, Response Flags in each log help improve fault diagnosis efficiency by providing additional details of request. But the simple and brief definition of Response Flags in Envoy and Istio community makes it hard to refer to it to effectively find the real problem and root cause when running into logs containing “DC, UF, UH” like flags in practice.
          
          
        
      </description>
    </item>
    
    <item>
      <title>RL(服务限流)--Istio访问日志ResponseFlag重现与解析14</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-14-RL/</link>
      <pubDate>Wed, 11 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-14-RL/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第14个关注的Response Flag还是RL，全称是RateLimited，官方定义表示The request was ratelimited locally by the HTTP rate limit filter in addition to 429 response code. 不同于前一个RL的重现了服务端限流，本文将聚焦基于客户端限流重现RL。
含义： **RL **表示触发服务限流。限流是保障服务韧性的重要手段，防止系统过载，保障服务总体的可用性。在网格中配置了本地限流或者全局限流策略，若在单位时间内请求数超过配置的阈值，则触发限流。访问日志记录RL，一般会伴随返回“429”的HTTP状态码。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod注入Siecar。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 和上一个限流重现类似，在原有正常访问的环境基础上，通过Envoy Filter配置本地限流策略。不同在于，通过SIDECAR_OUTBOUND表示入流量限流，即作用在客户端的sidecar代理上。配置限流阈值是60秒10次。
1apiVersion: networking.istio.io/v1alpha3 2kind: EnvoyFilter 3metadata: 4 name: filter-local-ratelimit-client 5 namespace: accesslog 6spec: 7 configPatches: 8 - applyTo: HTTP_FILTER 9 match: 10 context: SIDECAR_OUTBOUND 11 .
          
          
        
      </description>
    </item>
    
    <item>
      <title>RL(服务限流)--Istio访问日志ResponseFlag重现与解析13</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-13-RL/</link>
      <pubDate>Tue, 10 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-13-RL/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第13个关注的Response Flag是RL，全称是RateLimited，官方定义表示The request was ratelimited locally by the HTTP rate limit filter in addition to 429 response code.
含义： **RL **表示触发服务限流。限流是保障服务韧性的重要手段，防止系统过载，保障服务总体的可用性。在网格中配置了本地限流或者全局限流策略，若在单位时间内请求数超过配置的阈值，则触发限流。访问日志记录RL，一般会伴随返回“429”的HTTP状态码。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod注入Siecar。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 在原有正常访问的环境基础上，通过Envoy Filter配置本地限流策略。以下策略中，通过SIDECAR_INBOUND表示入流量限流，即作用在服务端的sidecar代理上。配置限流阈值是60秒10次请求。
1apiVersion: networking.istio.io/v1alpha3 2kind: EnvoyFilter 3metadata: 4 name: filter-local-ratelimit 5 namespace: accesslog 6spec: 7 configPatches: 8 - applyTo: HTTP_FILTER 9 match: 10 context: SIDECAR_INBOUND 11 .
          
          
        
      </description>
    </item>
    
    <item>
      <title>UC(上游连接中断)--Istio访问日志ResponseFlag重现与解析12</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-12-UC/</link>
      <pubDate>Mon, 09 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-12-UC/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第12个关注的Response Flag是UC，全称是UpstreamConnectionTermination，官方定义表示Upstream connection termination in addition to 503 response code.
含义： UC表示上游连接中断，常见的一种现象是上游连接在返回应答前已经关闭。
重现环境： UC是一个不太好构建的场景，环境和前面的大多数略有不同。
客户端Pod，这里是特别写了一个Python程序。因为观测点在服务端代理，客户端是否注入Sidecar都可以。 目标服务，一个Cluster类型的Kubernetes服务，这里是一个代理了Nginx服务，多个服务实例。服务端Pod要求注入Siecar，观察服务端的访问日志。 重现步骤： 第一步： 配置nginx conf文件给Nginx添加一个后端后端服务。这里就是简单用tomcat容器在8080上起了一个服务。
1 location /ucbackend { 2 proxy_http_version 1.1; 3 proxy_pass http://tomcat.accesslog:8080; 4 } 第二步： 不同于前面的测试，都是通过客户端命令行curl进行访问。构造UC的客户端控制稍微复杂些，这里编写一个简单的Python脚本，请求目标Nginx代理的服务，脚本中以Post方式发送请求，请求包括头域“Content-Length: 300”，说明将发送300大小的请求体 ，但实际发送的请求大小是0。
当客户端容器中执行这个Python脚本时，服务端的Nginx会一直尝试接收300大小的请求，却一直收不齐，导致请求一直不会结束。这样就会触发Nginx默认的60秒超时，服务端Nginx在60秒后会自动断开连接，从而即构造出了上游连接断开的场景。
第三步： 在客户端容器中执行以上Python程序， 观察Python脚本我们打印的输出，会看到执行后60秒得到了503的返回。
第四步： 观察Nginx自身的日志记录了408，表示服务端不再等待，关闭了连接。
1127.0.0.6 - - [25/Aug/2023:03:33:17 +0000] &amp;#34;POST /ucbackend/ HTTP/1.1&amp;#34; 408 0 &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; 第五步： 同时服务端代理记录503UC，表示服务端断开了连接，能看到日志上请求60秒（日志显示60060毫米）的耗时。
          
          
        
      </description>
    </item>
    
    <item>
      <title>UT(上游请求超时)--Istio访问日志ResponseFlag重现与解析11</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-11-UT/</link>
      <pubDate>Sun, 08 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-11-UT/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第11个关注的Response Flag是UT，全称是UpstreamRequestTimeout，官方定义表示Upstream request timeout in addition to 504 response code.
含义： UT表示表示上游请求超时，一般伴随返回“504”的HTTP状态码。如典型场景在VirtualService中给目标服务配置了超时时间，当服务请求超过配置的超时时间，客户端代理自动超时，取消请求。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，为了模拟一个慢的服务，我们这个环境比前面的稍微复杂一些。把一个目标服务通过Ingress-gateway发布出来对外可以访问，同时给这个服务配置10秒的延迟；整个模拟一个慢的服务。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过Ingress-gateway的地址192.168.99.99:9999访问目标服务，观察代理的访问日志，得到正常的200响应码。从客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 通过Serviceentry定义这个服务服务的访问地址是nginx.external，这样这个通过Ingress-gateway访问的目标服务在网格中就完成了服务注册，可以通过这个nginx.external被网格内的服务访问，当然也可以对这个服务配置流量策略。
**第三步：**给nginx.external这个Serviceentry描述的目标服务通过VirtualService定义流量策略，即配置3秒的访问超时。
1apiVersion: networking.istio.io/v1beta1 2kind: VirtualService 3metadata: 4 name: nginx-se-vs 5 namespace: accesslog 6spec: 7 hosts: 8 - nginx.external 9 http: 10 - timeout: 3s 11 route: 12 - destination: 13 host: nginx.external 第四步： 在客户端容器中curl这个目标服务，3秒后得到504 的状态码提示，同时会提示request timeout。
          
          
        
      </description>
    </item>
    
    <item>
      <title>FI(注入错误故障)--Istio访问日志ResponseFlag重现与解析10</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-10-FI/</link>
      <pubDate>Sat, 07 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-10-FI/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第10个关注的Response Flag是DI，全称是FaultInjected，官方定义表示The request was aborted with a response code specified via fault injection.
含义： FI 表示故障注入错误。通过VirtualService给目标服务注入了一个特定状态码的故障。在客户端的访问日志中会返回配置的HTTP状态码，并记录FI。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 修改VirtualService，在路由上配置了一个HTTP状态码是418的模拟错误。
1apiVersion: networking.istio.io/v1beta1 2kind: VirtualService 3metadata: 4 name: nginx-80 5 namespace: accesslog 6spec: 7 hosts: 8 - nginx 9 http: 10 - fault: 11 abort: 12 httpStatus: 418 13 percentage: 14 value: 100 15 route: 16 - destination: 17 host: nginx.
          
          
        
      </description>
    </item>
    
    <item>
      <title>DI(注入延时故障)--Istio访问日志ResponseFlag重现与解析09</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-09-DI/</link>
      <pubDate>Fri, 06 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-09-DI/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第九个关注的Response Flag是DI，全称是DelayInjected，官方定义表示The request processing was delayed for a period specified via fault injection.
含义： DI表示请求中注入了一个延时故障。在VirtualService中配置了延时故障注入时，会在服务请求时产生配置的延时，并在访问日志中会记录DI的应答标记。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 修改目标服务的VirtualService，在路由上配置10秒的延时。
1apiVersion: networking.istio.io/v1beta1 2kind: VirtualService 3metadata: 4 name: nginx-80 5 namespace: accesslog 6spec: 7 hosts: 8 - nginx 9 http: 10 - fault: 11 delay: 12 fixedDelay: 10s 13 percentage: 14 value: 100 15 route: 16 - destination: 17 host: nginx.
          
          
        
      </description>
    </item>
    
    <item>
      <title>NR(没有匹配的路由)--Istio访问日志ResponseFlag重现与解析08</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-08-NR/</link>
      <pubDate>Thu, 05 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-08-NR/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第八个关注的Response Flag是NR，全称是NoRouteFound，官方定义表示No route configured for a given request in addition to 404 response code or no matching filter chain for a downstream connection.
含义： NR表示没有匹配的路由来处理请求的流量，一般伴随“404”状态码。比如实际的访问流量的特征不匹配VirtualService中定义的路由条件，因而没有找到匹配的路由处理请求，就会报404 NR。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
**第二步：**修改目标服务的VirtualService，在路由上添加一个HTTP 头域匹配条件，即只有满足条件的请求会发送到路由定义的后端上。
1apiVersion: networking.istio.io/v1beta1 2kind: VirtualService 3metadata: 4 name: nginx-80 5 namespace: accesslog 6spec: 7 hosts: 8 - nginx 9 http: 10 - match: 11 - headers: 12 log-flag: 13 exact: enable 14 route: 15 - destination: 16 host: nginx.
          
          
        
      </description>
    </item>
    
    <item>
      <title>NC(没有上游集群)--Istio访问日志ResponseFlag重现与解析07</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-07-NC/</link>
      <pubDate>Wed, 04 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-07-NC/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第七个关注的Response Flag是NC，全称是NoClusterFound，官方定义表示Upstream cluster not found&amp;quot;
含义： NC表示没有上游集群，即在网格流量路由中定义的目标服务后端不存在。Istio中比较典型的场景如分流策略中流量发送给V2标识的服务子集，但是DestinationRule中并没有定义该版本标识的服务子集。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 在原有正常访问的环境上，给目标服务配置VirtualService 和DestinationRule，在VirtualService中定义服务的流量发给v2的服务子集，而在DestinationRule中只定义v1的服务子集。
1apiVersion: networking.istio.io/v1beta1 2kind: VirtualService 3metadata: 4 name: nginx-80 5 namespace: accesslog 6spec: 7 hosts: 8 - nginx 9 http: 10 - route: 11 - destination: 12 host: nginx.accesslog.svc.cluster.local 13 subset: v2 # subset NOT exists 1apiVersion: networking.istio.io/v1beta1 2kind: DestinationRule 3metadata: 4 name: nginx 5 namespace: accesslog 6spec: 7 host: nginx 8 subsets: 9 - labels: 10 version: v1 11 name: v1 # Only v1 第三步： .
          
          
        
      </description>
    </item>
    
    <item>
      <title>DPE(下游协议错误)--Istio访问日志ResponseFlag重现与解析06</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-06-DPE/</link>
      <pubDate>Tue, 03 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-06-DPE/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第六个关注的Response Flag是DPE，全称是 DownstreamProtocolError ，官方定义表示&amp;quot;The downstream request had an HTTP protocol error&amp;quot;
含义： UPE表示下游协议错误。如下游客户端通过一个错误的协议访问目标服务时，一般服务端会记录400DPE的日志
重现环境： 客户端Pod，注入了Sidecar。注意这里选择的是busybox容器，确认容器中包含telnet命令。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 在客户端busybox容器中，telnet目标服务的服务地址和端口，会得到400 Bad Request的错误。表示因为客户端的请求错误导致访问失败，根本原因当然是客户端协议错误，没有如服务端要求发送HTTP协议的请求。
第三步： 观察访问日志，客户端日志是一条四层的访问日志，因为是四层的访问 。
1[2023-08-21T13:56:45.757Z] &amp;#34;- - -&amp;#34; 0 - - - &amp;#34;-&amp;#34; 25 162 53038 - &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; &amp;#34;-&amp;#34; &amp;#34;10.246.91.131:80&amp;#34; PassthroughCluster 10.66.0.38:45964 10.246.91.131:80 10.66.0.38:43958 - - 第四步： 服务端日志记录400 DPE 表示下游协议错误。
          
          
        
      </description>
    </item>
    
    <item>
      <title>UPE(上游服务协议错误)--Istio访问日志ResponseFlag重现与解析05</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-05-UPE/</link>
      <pubDate>Mon, 02 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-05-UPE/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第五个关注的Response Flag是UPE，全称是 UpstreamProtocolError ，官方定义表示&amp;quot;The upstream response had an HTTP protocol error.&amp;quot;
含义： UPE表示上游服务协议错误。在网格中定义的服务的协议和服务实际的协议不一致时，当服务访问时，客户端会得到502协议错误的响应。同时服务端的入流量日志会记录502 UPE。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 在第一个正常用例基础上修改服务端口为gRPC，可以是修改端口名或者AppProtocol字段。
1apiVersion: v1 2kind: Service 3metadata: 4 name: nginx 5 namespace: accesslog 6spec: 7 ports: 8 - name: grpc # modify protocol by port name or AppProtocol 9 port: 80 10 protocol: TCP 11 targetPort: 80 12 selector: 13 app: nginx 14 sessionAffinity: None 15 type: ClusterIP 第三步： 在客户端容器中正常的curl目标服务，得到502 Bad Gateway的错误，Reset reason 提示 protocol error。
          
          
        
      </description>
    </item>
    
    <item>
      <title>URX(上游超过重试次数)--Istio访问日志ResponseFlag重现与解析04</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-04-URX/</link>
      <pubDate>Sun, 01 Oct 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-04-URX/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第四个关注的Response Flag是URX，全称是 UpstreamRetryLimitExceded ，官方定义表示&amp;quot;The request was rejected because the upstream retry limit (HTTP) or maximum connect attempts (TCP) was reached..&amp;quot;
含义： URX表示超过了HTTP的请求重试阈值，或者TCP的重连阈值，而导致访问被拒绝。这时客户端的访问日志中会记录URX。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 在第一个正常用例基础上修改服务的target port为错误的服务端口888。
1apiVersion: v1 2kind: Service 3metadata: 4 name: nginx 5 namespace: accesslog 6spec: 7 ports: 8 - name: http 9 port: 80 10 protocol: TCP 11 targetPort: 888 # Modify target port 80-&amp;gt;888，make service instance request failed 12 selector: 13 app: nginx 14 type: ClusterIP 第三步： 在客户端容器中curl 目标服务，得到503错误，提示连接失败。
          
          
        
      </description>
    </item>
    
    <item>
      <title>UF(上游连接失败)--Istio访问日志ResponseFlag重现与解析03</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-03-UF/</link>
      <pubDate>Sat, 30 Sep 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-03-UF/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第三个关注的Response Flag是UF，UF的全称是 UpstreamConnectionFailure ，官方定义表示&amp;quot;Upstream connection failure in addition to 503 response code.&amp;quot;
含义： 表示上游连接失败。典型场景如目标服务的服务端口不通。如客户端通过错误的端口访问目标服务时，会导致客户端的服务访问失败，客户端代理的Outbound日志会记录503UF。
目标服务的服务实例端口不通，会导致服务端的服务访问失败，同时目标服务端代理的Inbound日志会记录503UF。我们构建一个服务不通客户端Outbound日志记录UF，服务端inbound 日志的503 U后面的在另外一个URX用例里可以看到，综合起来可以更完整理解UF的含义和出现场景。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中通过目标名和服务端口访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 在第一个正常访问的用例基础上修改服务端口为错误的服务端口888。
1apiVersion: v1 2kind: Service 3metadata: 4 name: nginx 5 namespace: accesslog 6spec: 7 ports: 8 - name: http 9 port: 888 # Modify service port 80-&amp;gt;888，make service request failed 10 protocol: TCP 11 targetPort: 80 12 selector: 13 app: nginx 14 type: ClusterIP 第三步： 在客户端容器中curl 目标服务端口80，curl命令返回503，错误信息包括：upstream connect error or disconnect/reset before headers.
          
          
        
      </description>
    </item>
    
    <item>
      <title>UH(上游没有健康的后端实例)--Istio访问日志ResponseFlag重现与解析02</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-02-UH/</link>
      <pubDate>Fri, 29 Sep 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-02-UH/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第二个关注的Response Flag是UH，UH的全称是NoHealthyUpstream，官方定义表示&amp;quot;No healthy upstream hosts in upstream cluster in addition to 503 response code.&amp;quot;
含义： 表示上游服务没有健康的后端实例。典型场景如目标服务的后端实例不可用，比如在Kubernetes中目标服务的实例数设置为0.。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个Cluster类型的Kubernetes服务，多个服务实例。服务端Pod可以注入Siecar，也可以不用注入。 重现步骤： 第一步： 从注入了网格代理的客户端Pod中访问目标服务，观察代理的访问日志，得到正常的200响应码。从服务端和客户端的访问日志上都可以看到服务在目标服务的多个实例上负载均衡。正常访问参照本系列的环境部分描述。
第二步： 在前面正常用例的基础上把目标服务的实例数scale到0，使得目标服务没有可用的实例。
1kubectl scale --replicas=0 deployment/nginx -naccesslog 第三步： 重复前面客户端的访问，即从注入了sidecar的源服务负载中curl目标服务。这时观察客户端会得到503 的错误码，并且包含错误信息no healthy upstream。
第四步： 观察客户端outbound的日志，记录了503 UH no_healthy_upstream 。
1[2023-08-19T07:50:46.616Z] &amp;#34;GET / HTTP/1.1&amp;#34; 503 UH no_healthy_upstream - &amp;#34;-&amp;#34; 0 19 0 - &amp;#34;-&amp;#34; &amp;#34;curl/7.
          
          
        
      </description>
    </item>
    
    <item>
      <title>DC(下游连接终止)--Istio访问日志ResponseFlag重现与解析01</title>
      <link>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-01-DC/</link>
      <pubDate>Thu, 28 Sep 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/detailed-parse-and-reproduce-istio-response-flags-01-DC/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
第一个关注的Response Flag是DC，DC的全称是DownstreamConnectionTermination，官方定义是”Downstream connection termination“。
含义： DC表示下游连接终止。
在访问目标服务时，在收到完整应答前，客户端主动断开连接时，会产生DC特征的应答标记。客户端断开应答的场景比较多，生产中我们经常碰到的是客户端设置了请求超时，超时后客户端断开了连接。则在访问日志中一般会记录本次请求的结果为DC。
重现环境： 客户端Pod，注入了Sidecar。 目标服务，一个花费一定时间才会返回的服务。为了有机会再客户端请求发出后，收到应答前有机会主动断开，我们访问的服务不能太快速返回，所以这里构造一个10秒才会响应的服务，模拟一个看上去有点慢的服务。可以是编码的一个10秒才相应的服务。当然基于Istio非侵入方式构造一个慢服务非常方便。这里的目标服务是把一个目标服务通过Ingress-gateway发布出来对外可以访问，同时给这个服务配置10秒的延迟，来模拟一个慢的服务。 重现步骤： 第一步： 进入客户端Pod中curl目标服务，观察客户端访问结果和客户端代理的访问日志，可以看到访问结果正常。只是目标服务有延迟，总的访问耗时10秒。这里为了突出重点，正常访问的内容略去。
第二步： 客户端通过命令行访问目标服务，客户端curl命令访问时，携带max-time参数，设置客户端curl的最大时间为2秒。观察访问结果。
1curl -v -s 192.168.99.99:9999s/ --header &amp;#34;Host: nginx. external&amp;#34; --max-time 2 从客户端调用的截图上可以看到请求在2秒后结束，服务访问失败。废物本身需要10秒钟返回结果，在2秒的时候客户端因为超时主动断开。
这里是为了模拟一种更接近真实应用的场景。在模拟环境下构造客户端断开更简单的办法是不设置超时，直接curl，在得到请求返回前ctl+c结束curl请求也可以得到类似的效果。
第三步： 观察客户端的outbound日志可以看到收到了0 DC downstream_remote_disconnect的信息。同时一个小细节，客户端访问日志可以看到本次访问的耗时DURATION是1999毫秒，与我们配置的2秒钟超时吻合。
1[2023-08-18T11:31:40.069Z] &amp;#34;GET / HTTP/1.1&amp;#34; 0 DC downstream_remote_disconnect - &amp;#34;-&amp;#34; 0 0 1999 - &amp;#34;-&amp;#34; &amp;#34;curl/7.52.1&amp;#34; &amp;#34;afe165f1-27ab-447e-823d-b5d50103d197&amp;#34; &amp;#34;nginx.external&amp;#34; &amp;#34;100.85.115.86:9090&amp;#34; outbound|9999||nginx.external 10.66.0.24:58540 192.168.99.99:9999 10.66.0.24:41660 - - 应对建议： DC一般无需特殊处理。
          
          
        
      </description>
    </item>
    
    <item>
      <title>正常访问--Istio访问日志ResponseFlag重现与解析00</title>
      <link>https://idouba.com/2023-09-27-detailed-parse-and-reproduce-istio-response-flags-00-Normal/</link>
      <pubDate>Wed, 27 Sep 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/2023-09-27-detailed-parse-and-reproduce-istio-response-flags-00-Normal/</guid>
      <description>
        
          
            KubeCon 2023在上海做的一个关于Istio访问日志的演讲《Detailed Parse and Reproduce Response Flags of Istio Access Log Based on Production Use Case》。解析和重现了在当时解决客户问题时碰到的各种应答日志。
在详细展开每种Response Flag前先介绍下本系列的必要前置信息。包括访问日志的背景、机制，以及重现这些Response Flag的基本环境，方便有兴趣的同学参照练习。
机制 早期的访问日志一般由应用程序输出，即要求用户在业务代码中记录每次访问。在服务网格中，和指标、调用链等可观测性能力类似，Istio通过非侵入方式提供访问日志的收集。
过程大致是：
1.网格数据面拦截流量，并根据配置的访问日志格式输出访问日志。
2.数据面根据配置的ALS(Access log Service)地址上报访问日志。
3.ALS服务端收集日志，存储在日志存储，如ES中，或其他的日志系统中。
4.服务端日志检索工具如Kibana或其他日服务索日志。
这是一个一般性流程机制，在Istio中日志可以通过ALS的gRPC的服务收集日志，也可以写日志文件、标准输出或者对接OpenTelemetry等通道，即各种标准接口对接各种日志系统和通道，日志格式可以动态定义。
环境 这是我这次实践的环境。
在一个accesslog的命名空间下，我们创建了两个服务。两个服务均注入了Sidecar。源服务内有curl命令，我们会通过curl访问目标服务，生成访问日志。目标服务是一个端口是80的Nginx容器。
1apiVersion: v1 2kind: Service 3metadata: 4 name: nginx 5 namespace: accesslog 6spec: 7 ports: 8 - name: http 9 port: 80 10 protocol: TCP 11 targetPort: 80 12 selector: 13 app: nginx 14 type: ClusterIP 可以看到整个环境是比较干净简单，我们会尽量在最简单的环境上构造各种不同的场景，重现大多数常见的Response Flag，方便大家理解。
          
          
        
      </description>
    </item>
    
    <item>
      <title>IstioCon2023：Cert-manager帮助增强Istio证书管理的安全性和灵活性</title>
      <link>https://idouba.com/istiocon2023-cert-manager-help-enhance-security-and-flexibility-of-istio-certificate-management/</link>
      <pubDate>Tue, 26 Sep 2023 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/istiocon2023-cert-manager-help-enhance-security-and-flexibility-of-istio-certificate-management/</guid>
      <description>
        
          
            记录在2023年9月26日在上海IstioCon上发表的技术演讲《cert-manager Help Enhance Security and Flexibility of Istio Certificate Management》
议题： 对等身份验证是 Istio 零信任安全模型的基本组成部分。默认情况下，Istio 创建私钥和自签名根证书，使用它们自动签署和颁发 X.509 证书给每个工作负载，并帮助应用程序实现互相 TLS，以实现无需更改代码的安全服务间通信。在生产环境中，强烈建议从 PKI 提供商颁发根 CA，以增强安全性并提供更多的灵活性。在这次演讲中，超盟将分享 cert-manager 的详细实践，它是一个强大且可扩展的 X.509 证书控制器，如何帮助 Istio 构建增强的零信任网络。演讲将说明 cert-manager 如何通过自动从指定的 PKI 提供商获取证书，并在到期前的配置时间内更新证书，以避免任何服务停机，从而简化 Istio 根 CA 的生命周期管理。
Peer authentication is fundamental part of Istio’s zero-trust security model. By default, Istio creates a private key and self-signed root certificate, uses them to automatically sign and issue X.509 certificates to every workload, and help application make mutual TLS to secure service-to-service communication without code changes.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【MeetTheAuthors】Istio社区指导委员会成员携新书《Istio权威指南》和6场技术演讲亮相KubeCon</title>
      <link>https://idouba.com/meet-the-authors-in-shanghai-kubecon.md/</link>
      <pubDate>Mon, 25 Sep 2023 15:22:57 +0000</pubDate>
      
      <guid>https://idouba.com/meet-the-authors-in-shanghai-kubecon.md/</guid>
      <description>
        
          
            9 月 26-28 日，由 Linux 基金会、云原生计算基金会（CNCF）主办的 KubeCon + CloudNativeCon + Open Source Summit China 2023 将在上海跨国采购会展中心隆重召开。作为全球顶级的开源和云原生盛会，本届大会以“云赋创新，无处不在”为主题，聚焦可观测、安全、平台工程、数据库、运维+性能等技术热点，邀请全球顶级技术专家、开源社区领袖和企业代表，共同探讨最新的开源云原生技术洞见、最佳实践以及来自全球的创新案例。
作为 7月份Istio从CNCF正式毕业后云原生领域的第一次全球顶级技术盛会，全球服务网格的爱好者们除了可以参加KubeCon + CloudNativeCon + Open Source Summit China上丰富的议题外，还可以参与同场活动IstioCon 2023，业界最受欢迎的服务网格的第三届社区会议。您将在会上找到在生产环境中运行 Istio 的经验教训、实践经验，以及来自整个 Istio 生态系统的维护人员。其中就包括华为云云原生团队的两位资深技术专家，他们同时也是Istio社区成员、Istio社区指导委员会成员（Istio Steering Committee Member）。
他们将在本期IstioCon和KubeCon上带来6场精彩的演讲。其中即包括《基于生产案例详细解析和重现Istio访问日志的各种应答标记（Response Flags）》、《cert-Manager 帮助增强 Istio 证书管理的安全性和灵活性》这种基于生产实践的技术干货，也包括《Istio数据平面的新选择：架构创新带来的全新性能体验》，《重新思考服务网格负载均衡》这样的深入技术研讨，还有《Istio毕业后的下一步发展》、《服务网格正在逐渐见证云计算更高的崛起》这些Istio和服务网格发展的讨论。
同时作为今年5月年上市图书《Istio权威指南（上）：原理与实践》和《Istio权威指南（下）：架构与源码》的核心作者，他们也期望在会议期间和广大读者就本次演讲的服务网格相关议题、《Istio权威指南》图书中的内容、服务网格领域社区、业界和生产实践的各类问题与广大读者听众近距离交流。
IstioCon议题分享 Istio数据平面的新选择：架构创新带来的全新性能体验 演讲嘉宾：Zhonghu Xu, Principal Engineer, Huawei Cloud
Songyang Xie, Senior Software Engineer, Huawei Cloud
时间：9月26号，周二 9:55-10:20
地点：3夹层 3M3会议室
议题简介：在像Istio这样的服务网格技术的部署中，减少数据平面代理架构引起的延迟开销已经成为网格提供者的关键问题。在本次会议中，徐中虎和谢颂杨将从操作系统的角度提出一种全新的服务网格数据平面解决方案。通过利用eBPF +内核增强，他们在操作系统中实现了原生的流量治理能力。与其他解决方案不同，这种方法显著简化了网格数据平面的转发路径，从而使数据平面转发延迟降低了60%以上。此外，它具有低资源开销和安全隔离的特点。该项目重新定义了网格数据平面，以Istiod作为控制平面，目前华为正在进行内部验证。此外，他们还将讨论服务网格的未来演变，并在不同部署场景中探索无Sidecar架构的潜力。
听众受益：
架构创新：从操作系统的角度引入一种新的方法来应对服务网格挑战，为基础架构之间的协作创新提供了一个很好的例子和灵感。 为 Istio 提供一个新的数据平面选项，以满足高性能应用场景的需求。 cert-Manager 帮助增强 Istio 证书管理的安全性和灵活性** 演讲嘉宾：Chaomeng Zhang, Architect, Huawei Cloud
          
          
        
      </description>
    </item>
    
    <item>
      <title>西湖会昌子</title>
      <link>https://idouba.com/meet-changzi-in-hangzhou/</link>
      <pubDate>Mon, 24 Jul 2023 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/meet-changzi-in-hangzhou/</guid>
      <description>
        
          
            中午开车接上老婆孩子，急急忙忙和二十多年的兄弟昌子见了一面，吃了个饭。
从高德上收到六和塔附近汇合点捞上昌子，到茅家埠附近的弄堂里吃饭，加一起也没有多长时间。傻叉非要说等下和等下要和在西湖边溜达的同事回合，都是从北京铁路系统来疗养的，晚上还要一起返回无锡去。
车上丫坐副驾驶位置总是嘚啵嘚的diss哥开车这不对哪不对的，靠。
饭桌上，我们聊起了咱们当年。中专入学刚认识的时候，你十五岁，我也十五岁。你好像都有剃须刀了，哥那会儿毛还没长出来呢。应该是你们北京发达地区吃得好，长得快。哥来自偏远地区还只吃面，长得慢。
那年你93斤，我88斤。四年后我们毕业了，你123斤，我也123斤。哪天我们约好去学校门口过称比体重，我灌了一大杯水，才比你多了几两赢了你。就因为这几两险胜，你才答应，我以后娶了媳妇你管叫嫂子。因为我生日只大你一个月，就冲你胡子出来早四年里总是嘚瑟地一直让我喊你哥。临到最后你哥我才扳回一局，那叫一个爽，虽然靠灌水作弊，但感觉就是正义的胜利。但现在我们对坐在饭桌上，我还是那会儿的123，你都搞到160了。行行行，还是你赢了。
毕业后，你回北京，在四道口厂子里焊钢轨，哥分配到了铁一局修铁路。我记得那时候兴毕业留言册，你给哥写的是盼着以后来北京修地铁，咱就可以常见面了。
哥修铁路干的第一个工程是秦沈客运专线，工地在沈阳附近。从东北回西安我总会在北京停下，来榆树庄找你玩几天。那会儿工地上有野外补助，加上哥参与修的那条线当时号称是中国第一条高铁，工地奖金高。哥钱包里掏出的票子让你这北京土著也喊叫“你这是来北京消费的啊”。对了，哥当时那个帆布钱包还是你在学校送我的，后面用了很多年。
记得当时班上自我介绍的时候你说你们村在卢沟桥边上。小时候总去卢沟桥上玩，把卢沟桥的石狮子都让你们摸的秃噜皮了。我好像讲了我们村附近埋着汉武帝，边上有个茂陵博物馆里还有卫青和霍去病的墓。后来我记得你拿着个破地图给我指说你们村离天安门可近了，比房山那些地方近多了。
二年级时候咱们班倒洛阳重机厂的车间实习。一个多月的实习时间里在车间干了啥我到现在一点印象都没有，只记得你带我和几个人在重机厂的龙门吊下面打扑克。印象更深的厂子里有个带假山的水池，水池里有些小鱼，你后来天天带着我在那个水池里捞鱼。不知从哪里搞来个破草帽，用根绳子系在一木棍上，每次中饭从食堂带了些米饭放在草帽里。最终一个鱼毛都没有捞到，却就这样干了一个月。想想咱们得同龄人那时候正在高二紧张地学习，我们天天在摸鱼也是很有意思。那时候咱十六岁了吧，我给我儿子说你幼儿园前也喜欢在小区的水池里捞鱼，也是鱼毛都捞不到，也是天天都要去。
饭桌上你兴奋地拿出手机里的照片，一个五毛的钢镚儿本人立在高铁的桌子上。你给哥吹牛说你们把100米一段的钢轨焊成500米，高铁才跑的这么稳。哥说哥参与修建了中国第一条高铁，只是后来大家说法变了，我们当时修的那个叫第一天客运专线，几年后修成的你们北京到天津那个被认定为第一条高铁。我们都曾经为为中国铁路事业做贡献，咱们同学很多人还在持续贡献，哥惭愧当了逃兵。
因为等会儿要开车，下午还要上班，不能陪你喝。给你自个儿要了啤酒。一手拿着酒杯，掏出的铁路职工乘车证给哥炫耀这次北京到无锡疗养全免票。你显摆优越感的时候是不是忘了你哥也从铁路上出来的，当年也是持证的，拿着这个证从沈阳工地到西安免费火车瞎溜达，中间在北京还歇歇脚找你玩了半个月。白天你去四道口焊钢轨，哥跟着大老吴坐公交车从榆树庄出来，到西单劝业场，大老吴去那里一个写字楼跟着一堆喊口号的人搞他那个5000一个东陵附近墓地的房地产买卖，哥就在上面的新华书店看一天书，然后晚上回到榆树庄在你家蹭饭睡觉。
有个夏天那是东北工地都结束了，我们在家里等通知，哪里有活接着去哪里。有个啥事来着，我这个免费乘车证还能用，就又来北京找你玩，好像就住在四道口你们职工宿舍里。天天中午跟着你们一帮人去附近馆子吃喝，你们还总撩骚人家上菜的姑娘，应该都是川菜馆子里的川妹子吧。
除了干铁路时候经常来北京，哥后来转了赛道去北京出差的次数也很多。基本上每次办完事，不管在大北京的那个角落，得一点空都会窜到丰台来找你。而你算上这次也才是哥第二次接待你。
第一次是在西安，比这次还要仓促。哥那会儿正在复习考研，记得在西电的阶梯教室里接到你的电话。你说你们在四川绵阳有个啥活干完了坐火车回北京，火车会路过西安。你们是铁路上的通票，不能随意下车停留。但是过兄弟跟前，就想着要怎么能见一面。于是我们就约定再西安站的站台上，你告诉我到站时间。哥撂下电话就跑到附近超市买了点小米柿饼这些看着像陕西特产又不太贵的东西搞了一包。准备考研的四个月里你哥完全没有收入，之前几年在西安边自学点东西，边打点零工，干的也是些跑腿的活，在铁路上挣得钱也霍霍的差不多了，日子比较拮据，大方给你买点东西也大方不到哪里去。结账时搞了几个易拉罐的啤酒和小瓶白酒塞了进去。
忘了当时靠站台票还是我的铁路职工乘车证，我好像给检票的说了我们有个铁路的兄弟要从这里过，他就告诉我站台让进去了，天下铁路人是一家啊。火车停下来，你穿着秋裤下了车。车在西安站就停车这几分钟，我们对着干了酒，没聊几句，真的都在酒里了。哥干了剩下的半瓶酒，目送你的火车继续开动。你继续北上回家的路，我也要回我的出租屋里继续复习。
咱那天见面后有一段糗事哥当时没给你说，后面几次北京见面我也从来没有给你说过。因为你的火车到西安的时间已经十一点多了，从火车站回我那个出租屋所在的村子的公交车停运了，哥只能从火车站打了个车回去。当时没有钱，吃饭都紧张，每月手里固定的一点现金抠着花。在超市买完东西加上咱的酒，口袋里好像只剩下十几块零五毛了。在出租车计价器跳到那个十几块的时候，摸摸口袋就提前下车了。走着回去走了多少里不知道，只是大半夜在当年号称贼城的街道一个人走路有点害怕，有一段还很偏，回到屋里躺到床上时估计你的那个慢车都至少开到华山了。
遗憾怎么也说不动你这个傻叉再留一晚，我家附近过了一桥下面酒店哥都给你看好了。你干了两瓶啤酒，哥只赔了两杯西瓜汁。如果能留下来，咱可以重复六七年前在北京牡丹园那一顿，牛二加土豆丝，无限续杯。搞得人家饭店打烊了，老板催了几次还不走，气的老板把电扇给关了。最终也没有赶走这俩光着膀子流着大汗吃喝的流氓。吃喝到一两点在酒店楼下又扯了一个多小时，我回到房间老婆孩子早睡着了，而你要赶回丰台估计就更晚了。第二天还是第三天我们刚起床，你又拿着小米粥和牛肉火烧过来了，这么远就为给哥和家人送个早点。
当年你比较时髦，哥比较土。四年级时候你开始练滑板，还领着我在学校后面找有没有哪个店能给你的T恤上印上“滑板梦之队”的字，现在你别说印“滑板梦之队”了，你就是让人给你印个“滑板屎之队”淘宝两天就能给你寄过来。那时候这东西好像不是很容易，忘了你最终装逼成功没。
最羡慕你搭飘逸的齐耳的碎发，对比哥入学时大家评价又矮又挫小黄毛没发育好的样子。现在哥摸摸渐秃的头顶，对你夹杂着大片白发的大叔平头也是满满的敬畏和羡慕。
我的好兄弟，这些个年，这些个十年。看着很多都变了，很多都没变。
多保重，希望咱都顺当平安，祝愿咱们的同学都顺顺当当。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio多集群关键技术 –《Istio权威指南》书摘</title>
      <link>https://idouba.com/multi-cluster-of-the-definitive-guide-istio/</link>
      <pubDate>Sun, 04 Jun 2023 15:22:57 +0000</pubDate>
      
      <guid>https://idouba.com/multi-cluster-of-the-definitive-guide-istio/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《Istio权威指南（上）：云原生服务网格Istio原理与实践》一书原理篇的第7章 异构基础设施，7.3节多集群的关键技术，更多内容请参照原书。
第7章 异构基础设施 对多云、混合云、虚拟机等异构基础设施的服务治理是Istio重点支持的场景之一。为了提高服务的可用性，避免厂商锁定，多云、混合云甚至虚拟机和容器混合部署都成为常态，因此Istio社区将多集群、混合服务治理作为了重点发展方向。根据Flexera 2022 State of the Cloud Report，89%的组织选择了多云，随着越来越多的组织寻求使用最佳解决方案，混合云和多云有望实现持续增长，跨云的服务通信、服务治理将成为困扰开发人员的主要问题。本章从Istio的角度，重点解读Istio针对多集群服务治理提供的能力及实现原理。
7.3 多集群的关键技术 多集群相对于单集群，其服务在跨集群互访时比较复杂，其中最棘手的问题有以下两个。
◎ 异构环境下的DNS解析：如何解析多集群的服务域名。
◎ 多网络环境下的服务跨网络访问：东西向网关如何转发跨网络的服务访问。
7.3.1 异构环境DNS 如图7-9所示为多集群、虚拟机异构服务网格典型的服务访问拓扑。
​ 图7-9 多集群、虚拟机异构服务网格典型的服务访问拓扑
在Kubernetes中，Kube-dns只负责集群内的服务域名解析，对其他集群或者传统虚拟机服务的域名解析束手无策。为此，我们必须借助其他技术方案，通过级联DNS的方式向集群内的应用提供服务域名DNS解析的能力。级联DNS一般通过级联上游中心式的DNS服务器实现，但是如何向级联DNS服务器注册服务的DNS记录（DNS SRV）依然比较困难。
另外，Istio依赖名为“istio-coredns”的CoreDns扩展插件，进行Remote集群服务的域名解析。这强制要求用户创建ServiceEntry以向istio-coredns注册服务，其中ServiceEntry中服务域名的表示形式被约定为..global，同时需要修改Kube-dns的配置，使其级联到istio-coredns。除此之外，还需要用户自己管理服务IP地址的分配。由此可见，在生产中使用这种方案非常困难。
为降低在多集群、虚拟机等异构环境下使用Istio的难度，Istio在1.8版本中实现了DNS代理的功能。DNS代理的用法更加简单，无须用户额外创建任何配置。因此，Istio彻底废除了istio-coredns插件，不再需要为其他Kubernetes集群里面的服务在本地集群中创建影子服务。
DNS代理完全是Istio内部实现的一个DNS服务器，负责解析所有应用程序发送的DNS解析请求。它的上游级联DNS默认为Kube-dns。DNS代理在提供服务时所需的DNS Records由Istiod通过NDS（NameTable Discovery Service）发送，其中NDS完全是基于xDS协议实现的。Istiod负责监听服务网格内部所有的服务（既包括Kubernetes服务，也包括ServiceEntry服务），然后根据服务的地址及域名等信息构建DNS记录。NDS配置的发送采用异步通知的机制，任何服务的更新都会及时触发NDS配置的发送。从功能上来讲，DNS代理完全分担了Kube-dns的压力，而且支持远端集群及ServiceEntry服务的域名解析。
总之，本地DNS代理有三种优势：①由于DNS代理是Pilot-Agent中的子模块，所以Sidecar自动包含此功能，无须单独部署；②它与应用被部署在同一Pod中，属于同一网络空间，因此可以大大降低应用的DNS解析时延；③DNS代理属于分布式部署，可以分担中心式Kube-dns服务器的压力，避免因为Kube-dns过载而导致整个集群的可用性下降。
DNS代理的基本工作原理如图7-10所示，流程如下。
（1）应用程序在访问目标服务时，首先发起DNS解析。Istio通过Iptables规则拦截应用的DNS解析请求，并将其转发到本地15053端口，15053端口正是DNS代理监听的端口。
（2）DNS代理在接收到DNS解析请求后，首先检索本地的DNS记录，如果本地存在，则直接返回DNS响应，否则继续向上游级联DNS服务器（Kube-dns）发起解析请求。
（3）本集群的Kube-dns首先在本地查找DNS记录，如果找到，则直接返回DNS响应，否则会遵循标准的DNS配置（/etc/resolv.conf），将DNS请求转发到上游级联DNS服务器。这里的上游级联DNS服务器可能是公有云厂商自有的DNS服务器。
​ 图7-10 DNS代理的基本工作原理
DNS域名与IP地址映射表
如图7-11所示，Istiod通过监听所有集群的Kube-apiserver，获取整个服务网格中的所有Service/ServiceEntry，并且为ServiceEntry自动分配IP地址。DNS代理通过NDS（Istio扩展的xDS协议）从Istiod中获取所有服务的DNS域名与IP地址的映射关系表，并将其缓存在本地。
​ 图7-11 DNS代理NDS的发现原理
对于Kubernetes原生的Service来说，DNS解析直接使用其ClusterIP。当然存在这么一种情况，Service B在集群1和集群2中均存在，但是具有不同的ClusterIP地址，这时应该选择哪个地址作为服务的地址呢？答案是：Istiod选择与DNS Proxy在同一集群服务中的ClusterIP作为Service B的IP地址。如果DNS Proxy在集群1中，则Istiod选择集群1的ClusterIP 10.96.0.10作为Service B的地址；如果DNS Proxy在集群2中，则Istiod选择集群2的ClusterIP 10.10.0.10作为Service B的地址。也就是说，在多集群场景中，同一个服务名在不同的集群中可能被解析成不同的IP地址，当然这里完全不影响服务的访问，因为Istiod在生成监听器及路由匹配条件时，也遵循优先选择代理所在集群的服务ClusterIP的原则。
ServiceEntry一般用来表示虚拟机上或者服务网格外部的服务，DNS或STATIC解析类型的ServiceEntry本身并没有IP地址，Istiod会从保留的E类地址（240.0.0.1～255.255.255.254）中为其随机分配一个假的IP地址，并发送给DNS代理。当应用访问如下ServiceEntry指定的mymongodb.somedomain域名时，实际上DNS代理会返回一个240.240.x.x的IP地址。STATIC类型的服务在Envoy中的Cluster类型为EDS，因此Envoy会将请求发往2.2.2.2或者3.3.3.3中的任意一个目标实例。
1apiVersion: networking.istio.io/v1beta1 2kind: ServiceEntry 3 metadata: 4 name: external-svc-mongocluster 5 spec: 6 hosts: 7 - mymongodb.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio服务授权策略AuthorizationPolicy详解 –《Istio权威指南》书摘</title>
      <link>https://idouba.com/authorization-policy-of-the-definitive-guide-istio/</link>
      <pubDate>Sat, 03 Jun 2023 15:22:57 +0000</pubDate>
      
      <guid>https://idouba.com/authorization-policy-of-the-definitive-guide-istio/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《Istio权威指南（上）：云原生服务网格Istio原理与实践》一书原理篇的第5章 服务安全的原理，5.4节AuthorizationPolicy（服务授权策略），更多内容请参照原书。
第5章 服务安全的原理 Istio以非侵入方式透明地提供面向应用的安全基础设施。在Istio中有两种不同的认证方式：①基于mTLS的对等身份认证；②基于JWT（JSON Web Token）令牌的服务请求认证。本章重点介绍这两种认证方式，以及基于这两种认证方式的细粒度的服务访问授权，会详细介绍其中认证、授权的通用原理、模型，以及Istio基于服务网格形态的实现原理和机制。本章还会详细介绍如何通过配置PeerAuthentication、RequestAuthentication和AuthorizationPolicy使用这些认证、授权能力。
5.4 AuthorizationPolicy（服务授权策略） 认证的大部分应用场景最终是基于授权的访问控制，以上两种认证策略也大多配套本节的授权策略使用。从Istio 1.4开始引入的AuthorizationPolicy替代了之前ClusterRbacConfig、ServiceRole和ServiceRoleBinding三个对象来进行授权配置，避免了配置多个API的麻烦，AuthorizationPolicy的自身功能也非常丰富。
5.4.1 入门示例 在如下示例中定义了作用于forecast负载v2版本的AuthorizationPolicy：来自cluster.local/ns/weather/sa/frontend的服务，当其携带的请求头域group是admin，并且通过PUT和POST方法访问目标服务才被允许时，其他条件的访问都会被拒绝：
1apiVersion: security.istio.io/v1beta1 2kind: AuthorizationPolicy 3metadata: 4 name: forecast 5 namespace: weather 6spec: 7 selector: 8 matchLabels: 9 app: forecast 10 version: v2 11 rules: 12 - from: 13 - source: 14 principals: [&amp;#34;cluster.local/ns/weather/sa/frontend&amp;#34;] 15 to: 16 - operation: 17 methods: [&amp;#34;PUT&amp;#34;,&amp;#34;POST&amp;#34;] 18 when: 19 - key: request.headers[group] 20 values: [&amp;#34;admin&amp;#34;] 5.4.2 配置模型 AuthorizationPolicy的配置模型如图5-16所示，主要包括以下三部分。
◎ selector：描述策略应用的目标对象。
◎ rules：描述详细的访问控制规则。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio重要对象ServiceEntry详解 –《Istio权威指南》书摘</title>
      <link>https://idouba.com/service-entry-of-the-definitive-guide-istio/</link>
      <pubDate>Fri, 02 Jun 2023 15:22:57 +0000</pubDate>
      
      <guid>https://idouba.com/service-entry-of-the-definitive-guide-istio/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《Istio权威指南（上）：云原生服务网格Istio原理与实践》一书原理篇的第3章 流量治理的原理，3.5节ServiceEntry（服务条目），更多内容请参照原书。
第3章 流量治理的原理 本章讲解Istio提供的流量治理相关内容，即Istio流量治理要解决的问题、实现原理、配置模型、配置定义和典型应用，包括负载均衡、服务熔断、故障注入、灰度发布、故障转移、入口流量和出口流量等流量管理能力的通用原理、模型，以及Istio基于服务网格形态实现的原理和机制；同时会详细解析如何通过Istio中的VirtualService、DestinationRule、Gateway、ServiceEntry、WorkloadEntry、WorkloadGroup、Sidecar、EnvoyFilter、WasmPlugin等重要的服务管理配置来实现流量治理能力。在内容安排上，每节在讲解治理能力前都会从一个最精简的入门示例入手，再详细解析配置模型和定义，并辅以典型的应用案例来呈现其使用方法和应用场景。
3.5 ServiceEntry（服务条目） 在第2章介绍架构和服务模型时提到，在Istio中管理的大部分服务都是自动注册的Kubernetes服务。但在实际应用中经常还有其他类型的服务并不能自动注册，这就需要一种服务注册机制。在Istio中提供了ServiceEntry对象进行服务注册，以这种方式注册的服务和Kubernetes服务一样被服务网格管理，可以对其配置各种流量规则。
早期的ServiceEntry主要用于服务网格外部服务注册，比如注册外部的SaaS API或中间件云服务等。当前ServiceEntry的应用范围更加广泛，包括一些非容器的内部服务，比如比较典型的虚拟机类型的服务，配合要在3.6节和3.7节介绍的WorkloadEntry和WorkloadGroup可以实现完整的服务定义和服务实例注册功能。
3.5.1 入门示例 下面通过一个入门示例了解ServiceEntry的基本用法，在该示例中通过ServiceEntry包装了一个对api.forecast.weather的服务网格外部服务的访问。通过如下配置即可把这个服务网格外部服务注册到服务网格中，并管理其访问流量：
1apiVersion: networking.istio.io/v1beta1 2kind: ServiceEntry 3metadata: 4 name: weather-external 5spec: 6 hosts: 7 - api.forecast.weather 8 ports: 9 - number: 80 10 name: http 11 protocol: HTTP 12 resolution: DNS 13 location: MESH_EXTERNAL 3.5.2 配置模型 如图3-68所示，ServiceEntry的配置模型主要由以下两部分组成。
◎ 服务自身定义：定义服务的访问信息，主要包括服务域名hosts和端口ports等，表示服务的访问入口；还包括服务位置（location）和解析方式（resolution）。服务自身的定义类似Kubernetes上Service的功能和定义。
◎ 服务实例关联：通过workloadSelector关联到服务对应的实例。类似Kubernetes中Service的后端实例选择机制。
​ 图3-68 ServiceEntry的配置模型
3.5.3 配置定义 1．hosts（服务域名） 在服务发现模型中，最重要的自然是服务名和服务访问地址。Istio在通过ServiceEntry定义服务时，通过hosts来表示这个访问入口。在使用上有以下几点需要说明。
◎ 对于HTTP流量，hosts匹配HTTP头域的Host或Authority。
◎ 对于HTTPS或TLS流量，hosts匹配SNI。
◎ 对于其他协议的流量，不匹配hosts，而是使用下面的addresses和port字段。
◎ 当resolution被设置为DNS类型并且没有指定endpoints时，这个字段用作后端的域名来解析后端地址。
在Istio的流量规则被应用时，VirtualService和DestinationRule也会匹配这个hosts，来决定生效的流量规则。
2．address（虚拟IP地址） address表示与服务关联的虚拟IP地址，可以是CIDR这种前缀表达式：
          
          
        
      </description>
    </item>
    
    <item>
      <title>《Istio权威指南-上》前言</title>
      <link>https://idouba.com/the-definitive-guide-istio-preface-1/</link>
      <pubDate>Thu, 01 Jun 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/the-definitive-guide-istio-preface-1/</guid>
      <description>
        
          
            Istio从2017年开源第1个版本到当前版本，已经走过了5年多的时间。在此期间，伴随着云原生技术在各个领域的飞速发展，服务网格的应用也越来越广泛和深入。作为服务网格领域最具影响力的项目，Istio快速发展和成熟，获得越来越多的技术人员关注和应用。我们希望通过《Istio权威指南》系统且深入地讲解Istio，帮助相关技术人员了解和熟悉Istio，满足其日常工作中的需求。《Istio权威指南（上）：云原生服务网格Istio原理与实践》是《Istio权威指南》的上册，重点讲解Istio的原理与实践；《Istio权威指南（下）：云原生服务网格Istio架构与源码》是《Istio权威指南》的下册，重点讲解Istio的架构与源码。
近年来，服务网格在各个行业中的生产落地越来越多。CNCF在2022年上半年公布的服务网格调查报告显示，服务网格的生产使用率已达到60%，有19%的公司计划在接下来的一年内使用服务网格。当然，服务网格作为云原生的重要技术之一，当前在Gartner的评定中仍处于技术发展的早期使用阶段，有很大的发展空间。
CNCF这几年的年度调查显示，Istio一直是生产环境下最受欢迎和使用最多的服务网格。其重要原因是，Istio是功能非常全面、扩展性非常好、与云原生技术结合得非常紧密、非常适用于云原生场景的服务网格。像早期Kubernetes在编排领域的设计和定位一样，Istio从2017年第1个版本开始规划项目的应用场景和架构时，就致力于构建一个云原生的基础设施平台，而不是解决某具体问题的简单工具。
作为基础设施平台，Istio向应用开发人员和应用运维人员提供了非常大的透明度。Istio自动在业务负载中注入服务网格数据面代理，自动拦截业务的访问流量，可方便地在多种环境下部署和应用，使得业务在使用Istio时无须做任何修改，甚至感知不到这个基础设施的存在。在实现上，Istio提供了统一的配置模型和执行机制来保证策略的一致性，其控制面和数据面在架构上都提供了高度的可扩展性，支持用户基于实际需要进行扩展。
2022年9月28日，Istio项目被正式批准加入CNCF。这必将推动Istio与Envoy项目的紧密协作，一起构建云原生应用流量管理的技术栈。正如Kubernetes已成为容器编排领域的行业标准，加入CNCF也将进一步促进Istio成为应用流量治理领域的事实标准。Istio和Kubernetes的紧密配合，也将有助于拉通规划和开发更有价值的功能。根据Istio官方的统计，Istio项目已有8800名个人贡献者，超过260个版本，并有来自15家公司的85名维护者，可见Istio在技术圈和产业圈都获得了极大的关注和认可。
本书作者所在的华为云作为云原生领域的早期实践者与社区领导者之一，在Istio项目发展初期就参与了社区工作，积极实践并推动项目的发展，贡献了大量大颗粒特性。本书作者之一徐中虎在2020年Istio社区进行的第一次治理委员会选举中作为亚洲唯一代表入选，参与Istio技术策略的制定和社区决策。
本书作者作为Istio早期的实践者，除了持续开发满足用户需求的服务网格产品并参与社区贡献，也积极促进服务网格等云原生技术在国内的推广，包括于2019年出版《云原生服务网格Istio：原理、实践、架构与源码解析》一书，并通过KubeCon、IstioCon、ServiceMeshCon等云原生和服务网格相关的技术峰会，推广服务网格和Istio相关的架构、生产实践和配套解决方案等。
写作目的 《Istio 权威指南》作为“华为云原生技术丛书”的一员，面向云计算领域的从业者及感兴趣的技术人员，普及与推广Istio。本书作者来自华为云云原生团队，本书基于作者在华为云及Istio社区的设计与开发实践，以及与服务网格强相关的Kubernetes容器、微服务和云原生领域的丰富经验，对Istio的原理、实践、架构与源码进行了系统化的深入剖析，由浅入深地讲解了Istio的概念、原理、架构、模型、用法、设计理念、典型实践和源码细节。
本书是《Istio权威指南》的上册，适合入门级读者从零开始了解Istio的概念、原理和用法，也适合有一定基础的读者深入理解Istio的设计理念。
《Istio权威指南》的组织架构 《Istio权威指南》分为原理篇、实践篇、架构篇和源码篇，总计26章，其组织架构如下。
◎ 原理篇：讲解Istio的相关概念、主要架构和工作原理。其中，第1章通过讲解Istio与微服务、服务网格、Kubernetes这几个云原生关键技术的联系，帮助读者立体地理解Istio的概念。第2章概述Istio的工作机制、服务模型、总体架构和主要组件。第3、4、5章通过较大篇幅讲解Istio提供的流量治理、可观测性和策略控制、服务安全这三大核心特性，包括其各自解决的问题、实现原理、配置模型、配置定义和典型应用，可以满足大多数读者在工作中的具体需求。第6章重点讲解自动注入和流量拦截的透明代理原理。第7章讲解Istio正在快速发展的多基础设施流量管理，包括对各种多集群模型、容器、虚拟机的统一管理等。
◎ 实践篇：通过贯穿全书的一个天气预报应用来实践Istio的非侵入能力。其中，第8章讲解如何从零开始搭建环境。第9章通过Istio的非侵入方式生成指标、拓扑、调用链和访问日志等。第10章讲解多种灰度发布方式，带读者了解Istio灵活的发布策略。第11章讲解负载均衡、会话保持、故障注入、超时、重试、HTTP重定向、HTTP重写、熔断与连接池、熔断异常点检测、限流等流量策略的实践。第12章讲解两种认证策略及其与授权的配合，以及Istio倡导的零信任网络的关键技术。第13章讲解入口网关和出口网关的流量管理，展示服务网格对东西向流量和南北向流量的管理。第14章则是对多集群和虚拟机环境下流量治理的实践。
◎ 架构篇：从架构的视角分别讲解Istio各组件的设计思想、数据模型和核心工作流程。在Istio 1.16中，Istiod以原有的Pilot为基础框架构建了包含Pilot、Citadel、Galley等组件的统一控制面，第15、16、17章分别讲解以上三个组件各自的架构、模型和流程机制。第18、19、20章依次讲解服务网格数据面上Pilot-agent、Envoy和Istio-proxy的架构和流程，包括三者的结合关系，配合Istio控制面组件完成流量管理，特别是Envoy的架构、模型和关键流程。
◎ 源码篇：包括第21～26章，与架构篇的6章对应，分别讲解Istio管理面组件Pilot、Citadel、Galley与数据面Pilot-agent、Envoy、Istio-proxy的主要代码结构、代码流程和关键代码片段。本篇配合架构篇中每个组件的架构和机制，对Istio重要组件的实现进行了更详细的讲解和剖析，为读者深入研读Istio相关代码，以及在生产环境下进行相应代码的调试和修改提供指导。
学习建议 对于有不同需求的读者，我们建议这样使用本书。
◎ 对云原生技术感兴趣的所有读者，都可通过阅读《Istio权威指南（上）：云原生服务网格Istio原理与实践》，了解服务网格和Istio的概念、技术背景、设计理念与功能原理，并全面掌握Istio流量治理、可观测性和安全等功能的使用方式。通过实践篇可以从零开始学习搭建Istio运行环境并完成多种场景的实践，逐渐熟悉Istio的功能、应用场景，以及需要解决的问题，并加深对Istio原理的理解。对于大多数架构师、开发者和其他从业人员，通过对原理篇和实践篇的学习，可以系统、全面地了解Istio的方方面面，满足日常工作需要。
◎ 对Istio架构和实现细节感兴趣的读者，可以阅读《Istio权威指南（下）：云原生服务网格Istio架构与源码》，了解Istio的整体架构、各个组件的详细架构、设计理念和关键的机制流程。若对Istio源码感兴趣，并且在实际工作中需要调试或基于源码进行二次开发，那么还可以通过阅读源码篇，了解Istio各个项目的代码结构、详细流程、主要数据结构及关键代码片段。在学习源码的基础上，读者可以根据自己的兴趣或工作需求，深入了解某一关键机制的完整实现，并作为贡献者参与Istio或Envoy项目的开发。
勘误和支持 您在阅读本书的过程中有任何问题或者建议时，都可以通过本书源码仓库提交Issue或者PR（源码仓库地址参见本书封底的读者服务），也可以关注华为云原生官方微信公众号并加入微信群与我们交流。我们十分感谢并重视您的反馈，会对您提出的问题、建议进行梳理与反馈，并在本书后续版本中及时做出勘误与更新。
本书还免费提供了Istio培训视频及Istio常见问题解答等资源，请通过本书封底的读者服务获取这些资源。
致谢 在本书的写作及成书过程中，本书作者团队得到了公司内外领导、同事及朋友的指导、鼓励和帮助。感谢华为云张平安、张宇昕、李帮清等业务主管对华为云原生技术丛书及本书写作的大力支持；感谢华为云容器团队张琦、王泽锋、张永明、吕赟等对本书的审阅与建议；感谢电子工业出版社博文视点张国霞编辑一丝不苟地制订出版计划及组织工作。感谢章鑫、徐飞等一起参与华为云原生技术丛书《云原生服务网格Istio：原理、实践、架构与源码解析》的创作，你们为国内服务网格技术的推广做出了很大贡献，也为本书的出版打下了良好的基础。感谢四位作者的家人，特别是豆豆、小核桃、毛毛小朋友的支持，本书创作的大部分时间源自陪伴你们的时间；也感谢CNCF及Istio、Kubernetes、Envoy社区众多开源爱好者辛勤、无私的工作，期待和你们一起基于云原生技术为产业创造更大价值。谢谢大家！
华为云容器服务域总监 黄 毽
华为云应用服务网格架构师 张超盟
          
          
        
      </description>
    </item>
    
    <item>
      <title>《Istio权威指南-上》目录</title>
      <link>https://idouba.com/2023-06-01-the-definitive-guide-istio-index-1/</link>
      <pubDate>Thu, 01 Jun 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/2023-06-01-the-definitive-guide-istio-index-1/</guid>
      <description>
        
          
            原 理 篇 第1章 你好，Istio. 2 1.1 Istio是什么... 2
1.2 Istio能做什么.. 3
1.3 Istio与服务治理... 5
1.3.1 关于微服务... 5
1.3.2 服务治理的形态.. 7
1.3.3 Istio不只解决微服务问题.. 9
1.4 Istio与服务网格... 11
1.4.1 云原生选择服务网格... 11
1.4.2 服务网格选择Istio. 14
1.5 Istio与Kubernetes 17
1.5.1 Istio，Kubernetes的好帮手... 18
1.5.2 Kubernetes，Istio的好基座... 20
1.6 本章小结... 23
第2章 Istio的架构概述.. 25 2.1 Istio的架构及原理... 25
2.2 Istio的服务模型... 28
2.2.1 Istio的服务.. 29
2.2.2 Istio的服务版本... 30
2.2.3 Istio的服务实例... 32
2.3 Istio的主要组件... 34
2.3.1 控制面的组件... 34
2.3.2 数据面的组件.
          
          
        
      </description>
    </item>
    
    <item>
      <title>《Istio权威指南-下》前言</title>
      <link>https://idouba.com/the-definitive-guide-istio-preface-2/</link>
      <pubDate>Thu, 01 Jun 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/the-definitive-guide-istio-preface-2/</guid>
      <description>
        
          
            Istio从2017年开源第1个版本到当前版本，已经走过了5年多的时间。在此期间，伴随着云原生技术在各个领域的飞速发展，服务网格的应用也越来越广泛和深入。作为服务网格领域最具影响力的项目，Istio快速发展和成熟，获得越来越多的技术人员关注和应用。我们希望通过《Istio权威指南》系统且深入地讲解Istio，帮助相关技术人员了解和熟悉Istio，满足其日常工作中的需求。《Istio权威指南（上）：云原生服务网格Istio原理与实践》是《Istio权威指南》的上册，重点讲解Istio的原理与实践；《Istio权威指南（下）：云原生服务网格Istio架构与源码》是《Istio权威指南》的下册，重点讲解Istio的架构与源码。
近年来，服务网格在各个行业中的生产落地越来越多。CNCF在2022年上半年公布的服务网格调查报告显示，服务网格的生产使用率已达到60%，有19%的公司计划在接下来的一年内使用服务网格。当然，服务网格作为云原生的重要技术之一，当前在Gartner的评定中仍处于技术发展的早期使用阶段，有很大的发展空间。
CNCF这几年的年度调查显示，Istio一直是生产环境下最受欢迎和使用最多的服务网格。其重要原因是，Istio是功能非常全面、扩展性非常好、与云原生技术结合得非常紧密、非常适用于云原生场景的服务网格。像早期Kubernetes在编排领域的设计和定位一样，Istio从2017年第1个版本开始规划项目的应用场景和架构时，就致力于构建一个云原生的基础设施平台，而不是解决某具体问题的简单工具。
作为基础设施平台，Istio向应用开发人员和应用运维人员提供了非常大的透明度。Istio自动在业务负载中注入服务网格数据面代理，自动拦截业务的访问流量，可方便地在多种环境下部署和应用，使得业务在使用Istio时无须做任何修改，甚至感知不到这个基础设施的存在。在实现上，Istio提供了统一的配置模型和执行机制来保证策略的一致性，其控制面和数据面在架构上都提供了高度的可扩展性，支持用户基于实际需要进行扩展。
2022年9月28日，Istio项目被正式批准加入CNCF。这必将推动Istio与Envoy项目的紧密协作，一起构建云原生应用流量管理的技术栈。正如Kubernetes已成为容器编排领域的行业标准，加入CNCF也将进一步促进Istio成为应用流量治理领域的事实标准。Istio和Kubernetes的紧密配合，也将有助于拉通规划和开发更有价值的功能。根据Istio官方的统计，Istio项目已有8800名个人贡献者，超过260个版本，并有来自15家公司的85名维护者，可见Istio在技术圈和产业圈都获得了极大的关注和认可。
本书作者所在的华为云作为云原生领域的早期实践者与社区领导者之一，在Istio项目发展初期就参与了社区工作，积极实践并推动项目的发展，贡献了大量大颗粒特性。本书作者之一徐中虎在2020年Istio社区进行的第一次治理委员会选举中作为亚洲唯一代表入选，参与Istio技术策略的制定和社区决策。
本书作者作为Istio早期的实践者，除了持续开发满足用户需求的服务网格产品并参与社区贡献，也积极促进服务网格等云原生技术在国内的推广，包括于2019年出版《云原生服务网格Istio：原理、实践、架构与源码解析》一书，并通过KubeCon、IstioCon、ServiceMeshCon等云原生和服务网格相关的技术峰会，推广服务网格和Istio相关的架构、生产实践和配套解决方案等。
写作目的 《Istio权威指南》作为“华为云原生技术丛书”的一员，面向云计算领域的从业者及感兴趣的技术人员，普及与推广Istio。本书作者来自华为云云原生团队，本书基于作者在华为云及Istio社区的设计与开发实践，以及与服务网格强相关的Kubernetes容器、微服务和云原生领域的丰富经验，对Istio的原理、实践、架构与源码进行了系统化的深入剖析，由浅入深地讲解了Istio的概念、原理、架构、模型、用法、设计理念、典型实践和源码细节。
本书是《Istio权威指南》的下册，适合入门级读者从零开始了解Istio的架构，也适合有一定基础的读者深入研究Istio的源码。
《Istio权威指南》的组织架构 《Istio权威指南》分为原理篇、实践篇、架构篇和源码篇，总计26章，其组织架构如下。
◎ 原理篇：讲解Istio的相关概念、主要架构和工作原理。其中，第1章通过讲解Istio与微服务、服务网格、Kubernetes这几个云原生关键技术的联系，帮助读者立体地理解Istio的概念。第2章概述Istio的工作机制、服务模型、总体架构和主要组件。第3、4、5章通过较大篇幅讲解Istio提供的流量治理、可观测性和策略控制、服务安全这三大核心特性，包括其各自解决的问题、实现原理、配置模型、配置定义和典型应用，可以满足大多数读者在工作中的具体需求。第6章重点讲解自动注入和流量拦截的透明代理原理。第7章讲解Istio正在快速发展的多基础设施流量管理，包括对各种多集群模型、容器、虚拟机的统一管理等。
◎ 实践篇：通过贯穿全书的一个天气预报应用来实践Istio的非侵入能力。其中，第8章讲解如何从零开始搭建环境。第9章通过Istio的非侵入方式生成指标、拓扑、调用链和访问日志等。第10章讲解多种灰度发布方式，带读者了解Istio灵活的发布策略。第11章讲解负载均衡、会话保持、故障注入、超时、重试、HTTP重定向、HTTP重写、熔断与连接池、熔断异常点检测、限流等流量策略的实践。第12章讲解两种认证策略及其与授权的配合，以及Istio倡导的零信任网络的关键技术。第13章讲解入口网关和出口网关的流量管理，展示服务网格对东西向流量和南北向流量的管理。第14章则是对多集群和虚拟机环境下流量治理的实践。
◎ 架构篇：从架构的视角分别讲解Istio各组件的设计思想、数据模型和核心工作流程。在Istio 1.16中，Istiod以原有的Pilot为基础框架构建了包含Pilot、Citadel、Galley等组件的统一控制面。第15、16、17章分别讲解以上三个组件各自的架构、模型和流程机制。第18、19、20章依次讲解服务网格数据面上Pilot-agent、Envoy和Istio-proxy的架构和流程，包括三者的结合关系，配合Istio控制面组件完成流量管理，特别是Envoy的架构、模型和关键流程。
◎ 源码篇：包括第21～26章，与架构篇的6章对应，分别讲解Istio管理面组件Pilot、Citadel、Galley与数据面Pilot-agent、Envoy、Istio-proxy的主要代码结构、代码流程和关键代码片段。本篇配合架构篇中每个组件的架构和机制，对Istio重要组件的实现进行了更详细的讲解和剖析，为读者深入研读Istio相关代码，以及在生产环境下进行相应代码的调试和修改提供指导。
学习建议 对于有不同需求的读者，我们建议这样使用本书。
◎ 对云原生技术感兴趣的所有读者，都可通过阅读《Istio权威指南（上）：云原生服务网格Istio原理与实践》，了解服务网格和Istio的概念、技术背景、设计理念与功能原理，并全面掌握Istio流量治理、可观测性和安全等功能的使用方式。通过实践篇可以从零开始学习搭建Istio运行环境并完成多种场景的实践，逐渐熟悉Istio的功能、应用场景，以及需要解决的问题，并加深对Istio原理的理解。对于大多数架构师、开发者和其他从业人员，通过对原理篇和实践篇的学习，可以系统、全面地了解Istio的方方面面，满足日常工作需要。
◎ 对Istio架构和实现细节感兴趣的读者，可以阅读《Istio权威指南（下）：云原生服务网格Istio架构与源码》，了解Istio的整体架构、各个组件的详细架构、设计理念和关键的机制流程。若对Istio源码感兴趣，并且在实际工作中需要调试或基于源码进行二次开发，那么还可以通过阅读源码篇，了解Istio各个项目的代码结构、详细流程、主要数据结构及关键代码片段。在学习源码的基础上，读者可以根据自己的兴趣或工作需求，深入了解某一关键机制的完整实现，并作为贡献者参与Istio或Envoy项目的开发。
勘误和支持 您在阅读本书的过程中有任何问题或者建议时，都可以通过本书源码仓库提交Issue或者PR（源码仓库地址参见本书封底的读者服务），也可以关注华为云原生官方微信公众号并加入微信群与我们交流。我们十分感谢并重视您的反馈，会对您提出的问题、建议进行梳理与反馈，并在本书后续版本中及时做出勘误与更新。
本书还免费提供了Istio培训视频及Istio常见问题解答等资源，请通过本书封底的读者服务获取这些资源。
致谢 ​
在本书的写作及成书过程中，本书作者团队得到了公司内外领导、同事及朋友的指导、鼓励和帮助。感谢华为云张平安、张宇昕、李帮清等业务主管对华为云原生技术丛书及本书写作的大力支持；感谢华为云容器团队张琦、王泽锋、张永明、吕赟等对本书的审阅与建议；感谢电子工业出版社博文视点张国霞编辑一丝不苟地制订出版计划及组织工作。感谢章鑫、徐飞等一起参与华为云原生技术丛书《云原生服务网格Istio：原理、实践、架构与源码解析》的创作，你们为国内服务网格技术的推广做出了很大贡献，也为本书的出版打下了良好的基础。感谢四位作者的家人，特别是豆豆、小核桃、毛毛小朋友的支持，本书创作的大部分时间源自陪伴你们的时间；也感谢CNCF及Istio、Kubernetes、Envoy社区众多开源爱好者辛勤、无私的工作，期待和你们一起基于云原生技术为产业创造更大价值。谢谢大家！
华为云容器服务域总监 黄 毽
华为云应用服务网格架构师 张超盟
          
          
        
      </description>
    </item>
    
    <item>
      <title>《Istio权威指南-下》目录</title>
      <link>https://idouba.com/2023-06-01-the-definitive-guide-istio-index-2/</link>
      <pubDate>Thu, 01 Jun 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/2023-06-01-the-definitive-guide-istio-index-2/</guid>
      <description>
        
          
            目 录
架 构 篇 第15章 Pilot的架构.. 2 15.1 Pilot的基本架构... 2
15.1.1 Istio的服务模型.. 4
15.1.2 xDS协议... 6
15.2 Pilot的原理.. 12
15.2.1 xDS服务器... 13
15.2.2 服务发现... 24
15.2.3 配置规则发现.. 29
15.2.4 xDS的生成和分发... 35
15.3 安全插件... 42
15.3.1 认证插件... 43
15.3.2 授权插件... 46
15.4 Pilot的关键设计... 48
15.4.1 三级缓存模型.. 48
15.4.2 去抖动分发... 50
15.4.3 防过度分发... 51
15.4.4 增量EDS. 51
15.4.5 资源隔离... 53
15.4.6 自动管理虚拟机工作负载... 54
15.5 本章小结... 55
第16章 Citadel的架构.. 56 16.1 Istio的证书和身份管理... 56
          
          
        
      </description>
    </item>
    
    <item>
      <title>《Istio权威指南》推荐序一</title>
      <link>https://idouba.com/the-definitive-guide-istio-ref1/</link>
      <pubDate>Thu, 01 Jun 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/the-definitive-guide-istio-ref1/</guid>
      <description>
        
          
            推荐序一
随着企业数字化转型的全面深入，企业在生产、运营、创新方面都对基础设施提出了全新要求。为了保障业务的极致性能，资源需要被随时随地按需获取；为了实现对成本的精细化运营，需要实现对资源的细粒度管理；新兴的智能业务则要求基础设施能提供海量的多样化算力。为了支撑企业的数智升级，企业的基础设施需要不断进化、创新。如今，企业逐步进入深度云化时代，由关注资源上云转向关注云上业务创新，同时需要通过安全、运维、IT治理、成本等精益运营手段来深度用云、高效管云。云原生解决了企业以高效协同模式创新的本质问题，让企业的软件架构可以去模块化、标准化部署，极大提高了企业应用生产力。
从技术发展的角度来看，我们可以把云原生理解为云计算的重心从“资源”逐渐转向“应用”的必然结果。以资源为中心的上一代云计算技术专注于物理设备如何虚拟化、池化、多租化，典型代表是计算、网络、存储三大基础设施的云化。以应用为中心的云原生技术则专注于应用如何更好地适应云环境。相对于传统应用通过迁移改造“上云”，云原生的目标是通过一系列的技术支撑，使用户在云环境下快速开发和运行、管理云原生应用，并更好地利用云资源和云技术。
服务网格是CNCF（Cloud-Native Computing Foundation，云原生计算基金会）定义的云原生技术栈中的关键技术之一，和容器、微服务、不可变基础设施、声明式API等技术一起，帮助用户在动态环境下以弹性和分布式的方式构建并运行可扩展的应用。服务网格在云原生技术栈中，向上连接用户应用，向下连接多种计算资源，发挥着关键作用。
◎ 向下，服务网格与底层资源、运行环境结合，构建了一个理解应用需求、对应用更友好的基础设施，而不只是提供一堆机器和资源。服务网格帮助用户打造“以应用为中心”的云原生基础设施，让基础设施能感知应用且更好地服务于应用，对应用进行细粒度管理，更有效地发挥资源的效能。服务网格向应用提供的这层基础设施也经常被称为“应用网络”。用户开发的应用程序像使用传统的网络协议栈一样使用服务网格提供的应用层协议。就像TCP/IP负责将字节码可靠地在网络节点间传递，服务网格负责将用户的应用层信息可靠地在服务间传递，并对服务间的访问进行管理。在实践中，包括华为云在内的越来越多的云厂商将七层应用流量管理能力和底层网络融合，在提供传统的底层连通性能力的同时，基于服务的语义模型，提供了应用层丰富的流量、安全和可观测性管理能力。
◎ 向上，服务网格以非侵入的方式提供面向应用的韧性、安全、动态路由、调用链、拓扑等应用管理和运维能力。这些能力在传统应用开发模式下，需要在开发阶段由开发人员开发并持续维护。而在云原生开发模式下，基于服务网格的非侵入性特点，这些能力被从业务中解耦，无须由开发人员开发，由运维人员配置即可。这些能力包括：灵活的灰度分流；超时、重试、限流、熔断等；动态地对服务访问进行重写、重定向、头域修改、故障注入；自动收集应用访问的指标、访问日志、调用链等可观测性数据，进行故障定界、定位和洞察；自动提供完整的面向应用的零信任安全，比如自动进行服务身份认证、通道加密和细粒度授权管理。使用这些能力时，无须改动用户的代码，也无须使用基于特定语言的开发框架。
作为服务网格技术中最具影响力的项目，Istio的平台化设计和良好扩展性使得其从诞生之初就获得了技术圈和产业界的极大关注。基于用户应用Istio时遇到的问题，Istio的版本在稳定迭代，功能在日益完善，易用性和运维能力在逐步增强，在大规模生产环境下的应用也越来越多。特别是，Istio于2022年9月被正式批准加入CNCF，作为在生产环境下使用最多的服务网格项目，Istio在加速成熟。
华为云在2018年率先发布全球首个Istio商用服务：ASM（Application Service Mesh，应用服务网格）。ASM是一个拥有高性能、高可靠性和易用性的全托管服务网格。作为分布式云场景中面向应用的网络基础，ASM对多云、混合云环境下的容器、虚拟机、Serverless、传统微服务、Proxyless服务提供了应用健康、韧性、弹性、安全性等统一的全方位管理。
作为最早一批投身云原生技术的厂商，华为云是CNCF在亚洲唯一的初创成员，社区代码贡献和Maintainer席位数均持续位居亚洲第一。华为云云原生团队从2018年开始积极参与Istio社区的活动，参与Istio社区的版本特性设计与开发，基于用户的共性需求开发了大量大颗粒特性，社区贡献位居全球第三、中国第一。华为云云原生团队成员入选了每届Istio社区指导委员会，参与了Istio社区的重大技术决策，持续引领了Istio项目和服务网格技术的发展。
2021年4月，华为云联合中国信通院正式发布云原生2.0白皮书，全面诠释了云原生2.0的核心理念，分享了云原生产业洞察，引领了云原生产业的繁荣。此外，华为云联合CNCF、中国信通院及业界云原生技术精英们成立全球云原生交流平台——创原会，创原会当前已经在中国、东南亚、拉美、欧洲陆续成立分会，探索前沿云原生技术、共享产业落地实践经验，让云原生为数字经济发展和企业数字化转型贡献更多的价值。
《Istio权威指南》来源于华为云云原生团队在云服务开发、客户解决方案构建、Istio社区特性开发、生产环境运维等日常工作中的实践、思考和总结，旨在帮助技术圈的更多朋友由浅入深且系统地理解Istio的原理、实践、架构与源码。书中内容在描述Istio的功能和机制的同时，运用了大量的图表总结，并深入解析其中的概念和技术点，可以帮助读者从多个维度理解云原生、服务网格等相关技术，掌握基于Istio实现应用流量管理、零信任安全、应用可观测性等能力的相关实践。无论是初学者，还是对服务网格有一定了解的用户，都可以通过本书获取自己需要的信息。
华为云CTO 张宇昕
          
          
        
      </description>
    </item>
    
    <item>
      <title>《Istio权威指南》推荐序二</title>
      <link>https://idouba.com/the-definitive-guide-istio-ref2/</link>
      <pubDate>Thu, 01 Jun 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/the-definitive-guide-istio-ref2/</guid>
      <description>
        
          
            推荐序二
我很高兴向大家介绍这本关于Istio服务网格技术的权威书籍。Istio是一种创新性的平台，在云原生计算领域迅速赢得人们的广泛关注。企业在向微服务和容器化架构转型的过程中，对强大且可扩展的服务发现、流量管理及安全平台的需求变得比以往更加迫切。Istio在2022年9月正式被CNCF接受为孵化项目，并成为一种领先的解决方案，为云原生应用提供了无缝连接、可观察性和控制等能力。
本书提供了全面且实用的Istio指南，涵盖了Istio的核心概念、特性和对xDS协议等主题的深入探讨，还包括对Envoy和Istio项目源码的深入解析，这对潜在贡献者非常有用。无论您是软件工程师、SRE还是云原生开发人员，本书都将为您提供利用Envoy和Istio构建可扩展和安全的云原生应用所需的知识和技能。
我要祝贺作者们完成了杰出的工作，并感谢他们在云原生社区分享自己的专业知识。我相信本书将成为对Envoy、Istio及现代云原生应用开发感兴趣的人不可或缺的资源。
CNCF CTO Chris Aniszczyk
（原文）
I am thrilled to introduce this definitive book on Istio service mesh technology, a revolutionary platform that has been rapidly gaining popularity in the world of cloud-native computing. As businesses shift towards microservices and containerized architectures, the need for a robust and scalable platform for service discovery, traffic management, and security has become more critical than ever before. Istio was officially accepted in the CNCF as an incubation project in September 2022 and has emerged as a leading solution that provides seamless connectivity, observability, and control for cloud native applications.
          
          
        
      </description>
    </item>
    
    <item>
      <title>《Istio权威指南》结语</title>
      <link>https://idouba.com/conclusion-of-the-definitive-guide-istio/</link>
      <pubDate>Thu, 01 Jun 2023 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/conclusion-of-the-definitive-guide-istio/</guid>
      <description>
        
          
            感谢各位读者阅读本书的全部内容！希望书中的内容能给您和您的日常工作带来帮助。下面谈谈笔者对服务网格技术的一些观点，以与各位读者共勉。
随着多年的发展，服务网格技术在用户场景中的应用及技术本身都进入了比较务实的阶段。以Istio为代表的服务网格项目通过自身的迭代和对用户应用场景的打磨变得逐渐稳定、成熟和易用。Istio已加入CNCF，这进一步增加了技术圈对服务网格技术的信心。通过这几年的发展，服务网格技术逐渐成熟，形态也逐步被用户接受，并越来越多地在生产环境下大规模应用。
在这个过程中，服务网格技术不断应对用户的实际应用问题，也与周边技术加速融合，更聚焦于解决用户的具体问题，在多个方面都呈现积极的变化。
除了Istio得到人们的广泛关注和大规模应用，其他多个服务网格项目也得到关注并实现了快速发展。除了开源的服务网格项目，多个云厂商也推出了自研的服务网格控制面，提供面向应用的全局的应用基础设施抽象，统一管理云上多种形态的服务（包括容器、虚拟机和多云混合云等），并与自有的监控、安全等服务结合，向最终用户提供完整的应用网络功能，解决服务流量、韧性、安全和可观测性等问题。
一个较大的潜在变化发生在网格API方面，Kubernetes Gateway API获得了长足的发展。原本设计用于升级Ingress管理入口流量的一组API在服务网格领域获得了意想不到的积极认可。除了一些厂商使用Kubernetes Gateway API配置入口流量，也有服务网格使用其来配置管理内部流量。社区专门设立了GAMMA（Gateway API for Mesh Management and Administration）来推动Kubernetes Gateway API在服务网格领域的应用。
较之控制面的设计和变化大多受厂商和生态等因素的影响，服务网格数据面的变化则更多来自最终用户的实际使用需求。在大规模的落地场景中，资源、性能、运维等挑战推动了服务网格数据面相应的变革尝试。
首先，服务网格数据面呈现多种形态，除了常规的Sidecar模式，Istio社区在2022年下半年推出了Ambient Mesh，在节点代理Ztunnel上处理四层流量，在拉远的集中式代理Waypoint上处理七层流量。Cilium项目基于eBPF和Envoy实现了高性能的网格数据面，四层流量由eBPF快路径处理，七层流量通过每节点部署的Envoy代理处理。华为云应用服务网格ASM上线节点级的网格代理Terrace，处理本节点上所有应用的流量，简化Sidecar维护并降低了总的资源开销。同时，华为云ASM推出完全基于内核处理四层和七层流量的数据面Kmesh，进一步降低了网格数据面代理带来的延迟和资源开销。
然后，在云厂商的网络产品中，七层的应用流量管理能力和底层网络融合的趋势越来越显著。即网络在解决传统的底层连通性的同时，开始提供以服务为中心的语义模型，并在面向服务的连通性基础上，提供了越来越丰富的应用层的流量管理能力，包括流量、安全和可观测性等方面。虽然当前提供的功能比一般意义上服务网格规划的功能要少，颗粒度要粗，但其模型、能力甚至场景与服务网格正逐步趋近。
其次，除了向基础设施进一步融合，网格数据面也出现了基于开发框架构建Proxyless模式的尝试。这种模式作为标准代理模式的补充，在厂商产品和用户解决方案中均获得了一定的认可，gRPC、Dubbo 3.0等开发框架均支持这种Proxyless模式。开发框架内置了服务网格数据面的能力，同时通过标准数据面协议xDS和控制面交互，进行服务发现、获取流量策略并执行相应的动作。这种模式比代理模式性能损耗少，也会相应地节省一部分代理的资源开销，但也存在开发框架固有的耦合性、语言绑定等问题。
再次，Proxyless模式从诞生时期开始就引发了较大的争论。一种观点认为其是服务网格的正常演进，是代理模式的有益补充；也有一种观点认为其是向开发框架模式的妥协，更有甚者批评其是技术倒车。笔者若干年前做过微服务框架的设计开发工作（项目后来开源并从Apache毕业），近些年一直聚焦于服务网格相关技术和产品，认为没必要太纠结技术形态细节。在为用户提供产品和解决方案的过程中，近距离深入了解各类用户的实际业务需求和痛点，我们认为几乎所有技术呈现的变化都是适应用户实际业务的自我调整。具体到网格数据面的这些变化，说明服务网格技术正进入了快速发展时期。在这个过程中，希望我们这些有幸参与其中的技术人员能够以更开放的心态接纳和参与这些变化，深刻洞察用户碰到的问题，并以更开阔的技术视野解决用户问题，避免各种无休止的技术形态空洞之争。我们认为技术唯一的价值就是解决用户问题，产生有用性。正是不断涌现的用户业务需求，推动了技术的进步和发展，也提供给我们参与其中的机会和发挥作用的空间。
最后，再次感谢各位读者阅读本书，也很期待将来有机会就其中的内容和您进行技术交流。假如您需要更深入地学习服务网格及云原生相关技术，欢迎关注我们的“容器魔方”公众号，一起学习并讨论服务网格及云原生领域内的最新技术进展。
​ 张超盟
          
          
        
      </description>
    </item>
    
    <item>
      <title>IstioCon2022：Istio 多集群流量管理加速汽车公司新业务开发、部署和运营</title>
      <link>https://idouba.com/istiocon2022-istio-multi-cluster-traffic-management-speed-up-automobile-company-new-business-dev-deploy-and-ops/</link>
      <pubDate>Thu, 28 Apr 2022 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/istiocon2022-istio-multi-cluster-traffic-management-speed-up-automobile-company-new-business-dev-deploy-and-ops/</guid>
      <description>
        
          
            记录在2022年4月28日在IstioCon上发表的技术演讲《Istio multi-cluster traffic management speed up automobile company new business dev,deploy and ops》，和Smart的研发总监Kexing一起介绍了Istio多集群在Smart的实践。希望为Smart新车的大卖贡献了一点力量。
议题： smart, a brand to fully transform from fuel vehicles to electric vehicles, is committed to exploring the best solutions for future urban transportation. On its IT infrastructure, cloud-native technologies such as Kubernetes and service mesh help simplify the technology stack, accelerate business innovation, and greatly improve the efficiency of new business development, deployment, operation and maintenance.
          
          
        
      </description>
    </item>
    
    <item>
      <title>KubeCon2021：服务网格替代 Hystrix 提升在线视频服务韧性的生产实践</title>
      <link>https://idouba.com/kubecon2021-online-video-upgrades-resilience-from-sc-circuit-breaker-to-service-mesh-kubecon2021/</link>
      <pubDate>Sun, 12 Dec 2021 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/kubecon2021-online-video-upgrades-resilience-from-sc-circuit-breaker-to-service-mesh-kubecon2021/</guid>
      <description>
        
          
            记录在KubeCon2021上发表的技术演讲《Online Video upgrades resilience from SC Circuit Breaker to Service Mesh》，和世宇做的一个技术实践分享，总结了下一起把网格在人人视频中落地的部分经验。。
议题： 作为中国领先的在线视频共享平台，人人视频业务的快速发展给其 IT 基础设施带来了巨大挑战。日益增长的复杂性、容量和韧性要求给当前基于 Spring Cloud 熔断器的微服务带来了新的问题。
在KubeCon2021上，华为云应用服务网格架构师张超盟和人人视频技术主管徐世宇介绍了大规模生产环境中的服务网格韧性实践，包括不健康实例的透明自动隔离、故障自动恢复和自我修复、连接池管理、重试、限流、超时和分布式跟踪等。通过分析熔断器模式和比较 Spring Cloud 熔断器与服务网格在各自生产实践中不同的实现方式，结果表明优化不只是改善了系统的可靠性和可用性，还使得开发和操作工作更简单便捷。
As one leading Online Video sharing platform in China, RR&#39;s rapid business development introduce great challenge on its IT infrastructure. The increasing complexity, capacity and resilience requirement brings new problems to current Spring Cloud circuit breaker based micro services.
In this presentation, Chaomeng and Shiyu will focus on service mesh resilience practice in large scale production environment, including transparent auto-isolation of the unhealthy instance, auto-recovery and self-healing, connection pool management, retry, fine gained rate limit and distributed tracing, latency metrics.
          
          
        
      </description>
    </item>
    
    <item>
      <title>ServiceMeshCon2021：Kubernetes 和 Service Mesh 升级汽车公司的 IT 基础设施</title>
      <link>https://idouba.com/servicemeshcon2021-kubernetes-and-service-mesh-upgrade-automobile-company%E2%80%99s-it-infrastructure/</link>
      <pubDate>Tue, 04 May 2021 12:40:08 +0000</pubDate>
      
      <guid>https://idouba.com/servicemeshcon2021-kubernetes-and-service-mesh-upgrade-automobile-company%E2%80%99s-it-infrastructure/</guid>
      <description>
        
          
            记录在2021年5月4日在欧洲ServiceMeshCon上发表的技术演讲《Kubernetes and Service Mesh Upgrade Automobile Company’s IT Infrastructure》，分享了一个服务网格在一个客户的实践案例。
议题： Rapid business development brings a great challenge to automobile manufacturing company’s IT platforms. In this presentation, Chaomeng will share a practice of upgrading the traditional IT built microservice platform to cloud native infrastructure. That is gradually transforming the self-developed inner DNS plus ELB for service discovery and load balance, per VM nginx for inbound traffic management, metric, and access log, to Kubernetes and service mesh.
          
          
        
      </description>
    </item>
    
    <item>
      <title>IstioCon2021：SpringClod到Istio最佳实践</title>
      <link>https://idouba.com/istiocon2021-best-practice-from-spring-cloud-to-istio/</link>
      <pubDate>Tue, 23 Feb 2021 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/istiocon2021-best-practice-from-spring-cloud-to-istio/</guid>
      <description>
        
          
            记录在北京时间2月23日，在全球首届社区峰会IstioCon 2021中，发表的《Best practice:from Spring Cloud to Istio》技术演讲。回答经常被客户和同事们问到的一个问题，SpringCloud和Istio的关系，如何演进。
议题： 正文: 大家好，我是来自华为云的工程师。很荣幸有机会和大家分享Istio在生产中使用的实际案例。
华为云应用服务网格从2018年在公有云上线， 作为全球最早的几个网格服务之一，经历和见证了从早期对网格的了解、尝试到当前大规模使用的过程。服务的客户越来越多，场景也越来越复杂。这其中的通用功能作为feature大都贡献到Istio社区，解决方案层面的实践也希望通过这样的机会和大家交流。
本次我选取的主题是Spring Cloud to Istio。来自我们客户的Spring cloud的项目和Istio的结合与迁移案例。
演讲主要包含四部分的内容： 1）背景介绍
2）使用Spring cloud微服务框架遇到的问题
3）解决方案
4）通过示例来描述方案的实践细节
背景介绍 还是以微服务为切入点，微服务的诸多优势非常明显，但相应给整个系统带来的复杂度也非常显著。单体的系统变成了分布式后，网络问题，服务如何找到并访问到对端的服务发现问题，网络访问的容错保护问题等。连当年最简单的通过日志中的调用栈就能实现的问题定位，微服务化后必须要通过分布式调用链才能支持。怎样解决微服务带来的这些挑战？
微服务SDK曾经是一个常用的解决方案。将微服务化后通用的能力封装在一个开发框架中，开发者使用这个框架开发写自己的业务代码，生成的微服务自然就内置了这些能力。在很长的一段时间内，这种形态是微服务治理的标配，以至于初学者以为只有这些SDK才是微服务。
服务网格则通过另一种形态提供治理能力。不同于SDK方式，服务治理的能力在一个独立的代理进程中提供，完全和开发解耦。虽然从图上看两者差异非常小，后面我们将会从架构和实际案例来分析两者在设计理念上的差异，来体会前者是一个开发框架，而后者是一个基础设施。
SDK形态中Spring cloud是最有影响力的代表项目。Spring cloud提供了构建分布式应用的开发工具集，如列表所示。其中被大部分开发者熟知的是微服务相关项目，如：服务注册发现eureka、配置管理 config、负载均衡ribbon、熔断容错Hystrix、调用链埋点sleuth、网关zuul或Spring cloud gateway等项目。在本次分享中提到的Spring cloud也特指Spring cloud的微服务开发套件。
而网格形态中，最有影响力的项目当属Istio。Istio的这张架构图在这次演讲中会高频出现。作为本次分享的背景，我们只要知道架构上由控制面和数据面组成，控制面管理网格里面的服务和对服务配置的各种规则。数据面上每个服务间的出流量和入流量都会被和服务同POD的数据面代理拦截和执行流量管理的动作。
除了架构外，作为背景的另外一个部分，我们挑两个基础功能稍微打开看下两者的设计和实现上的相同和不同。首先是服务发现和负载均衡。
左边是Spring cloud，所有的微服务都会先注册中心，一般是Eureka进行服务注册，然后在服务访问时，consumer去注册中心进行服务发现得到待访问的目标服务的实例列表，使用客户端负载均衡ribbon选择一个服务实例发起访问。
右边Istio不需要服务注册的过程，只需要从运行平台k8s中获取服务和实例的关系，在服务访问时，数据面代理Envoy拦截到流量，选择一个目标实例发送请求。可以看到都是基于服务发现数据进行客户端负载均衡，差别是服务发现数据来源不同，负载均衡的执行体不同。
下面比较下熔断：
左边为经典的Hystrix的状态迁移图。一段时间内实例连续的错误次数超过阈值则进入熔断开启状态，不接受请求；隔离一段时间后，会从熔断状态迁移到半熔断状态，如果正常则进入熔断关闭状态，可以接收请求；如果不正常则还是进入熔断开启状态。
Istio中虽然没有显示的提供这样一个状态图，但是大家熟悉Istio规则和行为应该会发现，Istio中OutlierDection的阈值规则也都是这样设计的。两者的不同是Spring cloud的熔断是在SDK中Hystrix执行，Istio中是数据面proxy执行。Hystrix因为在业务代码中，允许用户通过编程做一些控制。
以上分析可以看到服务发现、负载均衡和熔断，能力和机制都是类似的。如果忽略图上的某些细节，粗的看框图模型都是完全一样的，对比表格中也一般只有一项就是执行位置不同，这一点不同在实际应用中带来非常大的差异。
使用Spring cloud微服务框架遇到的问题 本次演讲的重点是实践。以下是我们客户找到我们TOP的几个的问题，剖析下用户使用传统微服务框架碰到了哪些问题，这些大部分也是他们选择网格的最大动力。
1）多语言问题 在企业应用开发下，一个业务使用统一的开发框架是非常合理常见的，很多开发团队为了提升效率，经常还会维护有自己公司或者团队的通用开发框架。当然因为大部分业务系统都是基于Java开发，所以Spring cloud开发框架，或者衍生于Spring cloud的各种开发框架使用的尤其广泛。
但是在云原生场景下，业务一般更加复杂多样，特别是涉及到很多即存的老系统。我们不能要求为了微服务化将在用的一组成熟服务用Spring cloud重写下。用户非常希望有一种方式不重写原来的系统也能对其进行应用层服务访问管理。
2）将Spring cloud的微服务运行在K8s上会有很大的概率出现服务发现不及时 前面介绍过Spring cloud服务发现是基于各个微服务先向注册中心进行服务注册的数据来实现的，在传统Spring cloud场景下，当微服务部署在VM上，服务动态变化要求没有那么高，顶多个别实例运行不正常，通过服务发现的健康检查就足够了。但是在k8s场景下，服务实例动态迁移是非常正常场景。如图示，producer的某个Pod已经从一个节点迁移到另外一个节点了，这时需要新的pod2的producer实例向eureka注册，老实例Pod1要去注册。
如果该情况频繁发生，会出现注册中心数据维护不及时，导致服务发现和负载均衡到旧的实例pod1上，从而引起访问失败的情况。
3）升级所有应用以应对服务管理需求变化 第三个问题是一个比较典型的问题。客户有一个公共团队专门维护了一套基于Spring cloud的自有开发框架，在每次升级开发框架时，不得不求着业务团队来升级自己的服务。经常会SDK自身修改测试工作量不大，但却要制定很长周期的升级计划，来对上千个基于这个SDK开发的服务分组重新编译，打包，升级，而且经常要陪着业务团队在夜间变更。业务团队因为自身没有什么改动，考虑到这个升级带来的工作量和线上风险，一般也没有什么动力。
4）从单体式架构向微服务架构迁移 这是一个比较普遍的问题，就是渐进的微服务化。马丁福勒在著名的文章单体到微服务的拆分中（https://martinfowler.com/articles/break-monolith-into-microservices.html ）也提到了对渐进微服务化的倡议，如何能从业务上将一个大的业务分割，解耦，然后逐步微服务化。马丁福勒强调 “解耦的是业务能力不是代码” ，大神将代码的解耦留给了开发者。
但是站在开发者的角度讲渐进的微服务不是一个容易的事情。以基于Spring cloud框架进行微服务开发为例，为了所有的微服务间进行统一的服务发现、负载均衡，消费和执行同样的治理策略，必须要求所有的微服务基于同样的，甚至是统一版本的SDK来开发。
          
          
        
      </description>
    </item>
    
    <item>
      <title>KubeCon2020：Kubernetes和服务网格在冠状病毒期间助力在线协作</title>
      <link>https://idouba.com/kubeco2020-kubernetes-and-service-mesh-helps-online-collaboration-during-coronavirus-time/</link>
      <pubDate>Sat, 01 Aug 2020 16:20:08 +0000</pubDate>
      
      <guid>https://idouba.com/kubeco2020-kubernetes-and-service-mesh-helps-online-collaboration-during-coronavirus-time/</guid>
      <description>
        
          
            记录在2020年8月1日在KubeCon上发表的技术演讲《Kubernetes &amp;amp; Service Mesh Helps Online Collaboration During Coronavirus Time》，和来自云会议的同事谢飞一起分享了2019年新冠疫情期间Istio在云会议的应用。
议题： During the period of coronavirus, lots of people required stay at home or different office, use Welink, an online collaboration platform, work together. The exponentially increased online users bring great performance and capacity challenges. In this Session, Chaomeng and Fei will share their technical experience of Kubernetes&amp;amp;Istio in Welink supporting large traffic from large amount of users’ meeting, mailing and other online collaborations.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio灰度发布实践 –《云原生服务网格Istio》书摘05</title>
      <link>https://idouba.com/istio-canary-release-pratice-of-cloudnativeistio-05/</link>
      <pubDate>Fri, 09 Aug 2019 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/istio-canary-release-pratice-of-cloudnativeistio-05/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《云原生服务网格Istio:原理,实践,架构与源码解析》一书实践篇的第10章灰度发布实践。更多内容参照原书，或者关注容器魔方公众号。作者：star
目前一些大型的互联网或金融行业的公司，都有自己的发布系统。但是对一些初创公司，从零开始构建这样一套系统并不简单，有一定的门槛。利用Istio提供的流量路由功能可以很方便地构建一个流量分配系统来做灰度发布和AB测试。
预先准备： 将所有流量都路由到各个服务的v1版本
在开始本章的实践前，先将frontend、advertisement和forecast服务的v1版本部署到集群中，命名空间是weather，执行如下命令确认Pod成功启动：
1$ kubectl get pods -n weather 2NAME READY STATUS RESTARTS AGE 3advertisement-v1-6f69c464b8-5xqjv 2/2 Running 0 1m 4forecast-v1-65599b68c7-sw6tx 2/2 Running 0 1m 5frontend-v1-67595b66b8-jxnzv 2/2 Running 0 1m 对每个服务都创建各自的VirtualService和DestinationRule资源，将访问请求路由到所有服务的v1版本：
1$ kubectl apply -f install/destination-rule-v1.yaml -n weather 2$ kubectl apply -f install/virtual-service-v1.yaml -n weather 查看配置的路由规则，以forecast服务为例：
1$ kubectl get vs -n weather forecast-route -o yaml 2apiVersion: networking.istio.io/v1alpha3 3kind: VirtualService 4…… 5 name: forecast-route 6 namespace: weather 7…… 8spec: 9 hosts: 10 - forecast 11 http: 12 - route: 13 - destination: 14 host: forecast 15 subset: v1 在浏览器中多次加载前台页面，并查询城市的天气信息，确认显示正常。各个服务之间的调用关系如图10-1所示。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Sidecar Injector自动注入的原理 –《云原生服务网格Istio》书摘04</title>
      <link>https://idouba.com/istio-sidecar-injection-of-cloudnativeistio-04/</link>
      <pubDate>Fri, 02 Aug 2019 15:22:57 +0000</pubDate>
      
      <guid>https://idouba.com/istio-sidecar-injection-of-cloudnativeistio-04/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《云原生服务网格Istio:原理,实践,架构与源码解析》一书原理篇的第6章透明的Sidecar机制，6.1.1小节Sidecar Injector自动注入的原理。更多内容参照原书，或者关注容器魔方公众号。
Sidecar注入 我们都知道，Istio的流量管理、策略、遥测等功能无须应用程序做任何改动，这种无侵入式的方式全部依赖于Sidecar。应用程序发送或者接收的流量都被Sidecar拦截，并由Sidecar进行认证、鉴权、策略执行及遥测数据上报等众多治理功能。
如图6-1所示，在Kubernetes中，Sidecar容器与应用容器共存于同一个Pod中，并且共享同一个Network Namespaces，因此Sidecar容器与应用容器共享同一个网络协议栈，这也是Sidecar能够通过iptables拦截应用进出口流量的根本原因。
图6-1 Istio的Sidecar模式
在Istio中进行Sidecar注入有两种方式：一种是通过istioctl命令行工具手动注入;另一种是通Istio Sidecar Injector自动注入。
这两种方式的最终目的都是在应用Pod中注入init容器及istio-proxy容器这两个Sidecar容器。如下所示，通过部署Istio的sleep应用，Sidecar是通过sidecar-injector自动注入的，查看注入的Sidecar容器：
（1）istio-proxy 容器： 1- args: # istio-proxy 容器命令行参数 2 - proxy 3- sidecar 4 - --domain 5- $(POD_NAMESPACE).svc.cluster.local 6 - --configPath 7- /etc/istio/proxy 8- --binaryPath 9 - /usr/local/bin/envoy 10 - --serviceCluster 11 - sleep.default 12 - --drainDuration 13- 45s 14 - --parentShutdownDuration 15- 1m0s 16 - --discoveryAddress 17 - istio-pilot.istio-system:15011 18 - --zipkinAddress 19 - zipkin.istio-system:9411 20 - --connectTimeout 21 - 10s 22 - --proxyAdminPort 23- &amp;#34;15000&amp;#34; 24 - --controlPlaneAuthPolicy 25 - MUTUAL_TLS 26 - --statusPort 27- &amp;#34;15020&amp;#34; 28 - --applicationPorts 29 - &amp;#34;&amp;#34; 30 env: # istio-proxy 容器环境变量 31 - name: POD_NAME 32 valueFrom: 33 fieldRef: 34 apiVersion: v1 35 fieldPath: metadata.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio灰度发布 –《云原生服务网格Istio》书摘03</title>
      <link>https://idouba.com/istio-canary-release-of-cloudnativeistio-03/</link>
      <pubDate>Thu, 25 Jul 2019 15:09:52 +0000</pubDate>
      
      <guid>https://idouba.com/istio-canary-release-of-cloudnativeistio-03/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《云原生服务网格Istio:原理,实践,架构与源码解析》一书原理篇的第3章非侵入的流量治理，第3.1.4小节灰度发布原理。更多内容参照原书，或者关注容器魔方公众号。
3.1.4 灰度发布 在新版本上线时，不管是在技术上考虑产品的稳定性等因素，还是在商业上考虑新版本被用户接受的程度，直接将老版本全部升级是非常有风险的。所以一般的做法是，新老版本同时在线，新版本只切分少量流量出来，在确认新版本没有问题后，再逐步加大流量比例。这正是灰度发布要解决的问题。其核心是能配置一定的流量策略，将用户在同一个访问入口的流量导到不同的版本上。有如下几种典型场景。
1．蓝绿发布 蓝绿发布的主要思路如图3-13所示，让新版本部署在另一套独立的资源上，在新版本可用后将所有流量都从老版本切到新版本上来。当新版本工作正常时，删除老版本；当新版本工作有问题时，快速切回到老版本，因此蓝绿发布看上去更像一种热部署方式。在新老版本都可用时，升级切换和回退的速度都可以非常快，但快速切换的代价是要配置冗余的资源，即有两倍的原有资源，分别部署新老版本。另外，由于流量是全量切换的，所以如果新版本有问题，则所有用户都受影响，但比蛮力发布在一套资源上重新安装新版本导致用户的访问全部中断，效果要好很多。
图3-13 蓝绿发布
2．AB测试 AB测试的场景比较明确，就是同时在线上部署A和B两个对等的版本来接收流量，如图3-14所示，按一定的目标选取策略让一部分用户使用A版本，让一部分用户使用B版本，收集这两部分用户的使用反馈，即对用户采样后做相关比较，通过分析数据来最终决定采用哪个版本。 图3-14 AB测试
对于有一定用户规模的产品，在上线新特性时都比较谨慎，一般都需要经过一轮AB测试。在AB测试里面比较重要的是对评价的规划：要规划什么样的用户访问，采集什么样的访问指标，尤其是，指标的选取是与业务强相关的复杂过程，所以一般都有一个平台在支撑，包括业务指标埋点、收集和评价。
3．金丝雀发布 金丝雀发布就比较直接，如图3-15所示，上线一个新版本，从老版本中切分一部分线上流量到新版本来判定新版本在生产环境中的实际表现。就像把一个金丝雀塞到瓦斯井里面一样，探测这个新版本在环境中是否可用。先让一小部分用户尝试新版本，在观察到新版本没有问题后再增加切换的比例，直到全部切换完成，是一个渐变、尝试的过程。
图3-15 金丝雀发布
蓝绿发布、AB测试和金丝雀发布的差别比较细微，有时只有金丝雀才被称为灰度发布，这里不用太纠缠这些划分，只需关注其共同的需求，就是要支持对流量的管理。能否提供灵活的流量策略是判断基础设施灰度发布支持能力的重要指标。
灰度发布技术上的核心要求是要提供一种机制满足多不版本同时在线，并能够灵活配置规则给不同的版本分配流量，可以采用以下几种方式。
1．基于负载均衡器的灰度发布 比较传统的灰度发布方式是在入口的负载均衡器上配置流量策略，这种方式要求负载均衡器必须支持相应的流量策略，并且只能对入口的服务做灰度发布，不支持对后端服务单独做灰度发布。如图3-16所示，可以在负载均衡器上配置流量规则对frontend服务进行灰度发布，但是没有地方给forecast服务配置分流策略，因此无法对forecast服务做灰度发布。
图3-16 基于负载均衡器的灰度发布
2．基于Kubernetes的灰度发布 在Kubernetes环境下可以基于Pod的数量比例分配流量。如图3-17所示，forecast服务的两个版本v2和v1分别有两个和3个实例，当流量被均衡地分发到每个实例上时，前者可以得到40%的流量，后者可以得到60%的流量，从而达到流量在两个版本间分配的效果。
图3-17 基于Pod数量的灰度发布
给v1和v2版本设置对应比例的Pod数量，依靠Kube-proxy把流量均衡地分发到目标后端，可以解决一个服务的多个版本分配流量的问题，但是限制非常明显：首先，要求分配的流量比例必须和Pod数量成比例，如图3-17所示，在当前的Pod比例下不支持得到3:7的流量比例，试想，基于这种方式支持3:97比例的流量基本上是不可能的；另外，这种方式不支持根据请求的内容来分配流量，比如要求Chrome浏览器发来的请求和IE浏览器发来的请求分别访问不同的版本。
有没有一种更细粒度的分流方式？答案当然是有，Istio就可以。Istio叠加在Kubernetes之上，从机制上可以提供比Kubernetes更细的服务控制粒度及更强的服务管理能力，该管理能力几乎包括本章的所有内容，对于灰度发布场景，和刚才Kubernetes的用法进行比较会体现得更明显。
3．基于Istio的灰度发布 不同于前面介绍的熔断、故障注入、负载均衡等功能，Istio本身并没有关于灰度发布的规则定义，灰度发布只是流量治理规则的一种典型应用，在进行灰度发布时，只要写个简单的流量规则配置即可。
Istio在每个Pod里都注入了一个Envoy，因而只要在控制面配置分流策略，对目标服务发起访问的每个Envoy便都可以执行流量策略，完成灰度发布功能。
如图3-18所示为对recommendation服务进行灰度发布，配置20%的流量到v2版本，保留80%的流量在v1版本。通过Istio控制面Pilot下发配置到数据面的各个Envoy，调用recommendation服务的两个服务frontend和forecast都会执行同样的策略，对recommendation服务发起的请求会被各自的Envoy拦截并执行同样的分流策略。
图3-18 Istio基于流量比例的灰度发布
在Istio中除了支持这种基于流量比例的策略，还支持非常灵活的基于请求内容的灰度策略。比如某个特性是专门为Mac操作系统开发的，则在该版本的流量策略中需要匹配请求方的操作系统。浏览器、请求的Headers等请求内容在Istio中都可以作为灰度发布的特征条件。如图3-19所示为根据Header的内容将请求分发到不同的版本上。
图3-19 Istio基于请求内容的灰度发布
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio通过Prometheus收集遥测数据--《云原生服务网格Istio》书摘06</title>
      <link>https://idouba.com/stio-prometheus-cloudnative-istio-06/</link>
      <pubDate>Sun, 21 Jul 2019 14:44:37 +0000</pubDate>
      
      <guid>https://idouba.com/stio-prometheus-cloudnative-istio-06/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《云原生服务网格Istio:原理,实践,架构与源码解析》一书原理篇的第4章可扩展的策略和遥测中1.4.1小节Prometheus适配器。更多内容参照原书，或者关注容器魔方公众号。
Prometheus适配器
Prometheus应该是当前应用最广的开源系统监控和报警平台了，随着以Kubernetes为核心的容器技术的发展，Prometheus强大的多维度数据模型、高效的数据采集能力、灵活的查询语法，以及可扩展性、方便集成的特点，尤其是和云原生生态的结合，使其获得了越来越广泛的应用。Prometheus于2015年正式发布，于2016年加入CNCF，并于2018年成为第2个从CNCF毕业的项目。
图4-10展示了Prometheus的工作原理。Prometheus的主要工作为抓取数据存储，并提供PromQL语法进行查询或者对接Grafana、Kiali等Dashboard进行显示，还可以根据配置的规则生成告警。
​ 图4-10 Prometheus的工作原理
这里重点关注Prometheus工作流程中与Mixer流程相关的数据采集部分，如图4-10所示。不同于常见的数据生成方向后端上报数据的这种Push方式，Prometheus在设计上基于Pull方式来获取数据，即向目标发送HTTP请求来获取数据，并存储获取的数据。这种使用标准格式主动拉取数据的方式使得Prometheus在和其他组件配合时更加主动，这也是其在云原生场景下得到广泛应用的一个重要原因。
1．Adapter的功能
我们一般可以使用Prometheus提供的各种语言的SDK在业务代码中添加Metric的生成逻辑，并通过HTTP发布满足格式的Metric接口。更通用的方式是提供Prometheus Exporter的代理，和应用一起部署，收集应用的Metric并将其转换成Prometheus的格式发布出来。
Exporter方式的最大优点不需要修改用户的代码，所以应用非常广泛。Prometheus社区提供了丰富的Exporter实现（https://prometheus.io/docs/instrumenting/exporters/），除了包括我们熟知的Redis、MySQL、TSDB、Elasticsearch、Kafka等数据库、消息中间件，还包括硬件、存储、HTTP服务器、日志监控系统等。
如图4-11所示，在Istio中通过Adapter收集服务生成的Metric供Prometheus采集，这个Adatper就是Prometheus Exporter的一个实现，把服务的Metric以Prometheus格式发布出来供Prometheus采集。
图4-11 Prometheus Adapter的工作机制
结合图4-11可以看到完整的流程，如下所述。
Envoy通过Report接口上报数据给Mixer。 Mixer根据配置将请求分发给Prometheus Adapter。 Prometheus Adapter通过HTTP接口发布Metric数据。 Prometheus服务作为Addon在集群中进行安装，并拉取、存储Metric数据，提供Query接口进行检索。 集群内的Dashboard如Grafana通过Prometheus的检索API访问Metric数据。 可以看到，关键步骤和关键角色是作为中介的Prometheus Adapter提供数据。观察“/prometheus/prometheus.yml”的如下配置，可以看到Prometheus数据采集的配置，包括采集目标、间隔、Metric Path等：
1- job_name: &amp;#39;istio-mesh&amp;#39; 2 # Override the global default and scrape targets from this job every 5 seconds. 3 scrape_interval: 5s 4 5 kubernetes_sd_configs: 6 - role: endpoints 7 namespaces: 8 names: 9 - istio-system 10 relabel_configs: 11 - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name] 12 action: keep 13 regex: istio-telemetry;prometheus 在Istio中，Prometheus除了默认可以配置istio-telemetry抓取任务从Prometheus的Adapter上采集业务数据，还可以通过其他多个采集任务分别采集istio-pilot、istio-galley、istio-policy、istio-telemetry对应的内置Metric接口。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Pilot的设计亮点–《云原生服务网格Istio》书摘02</title>
      <link>https://idouba.com/istio-pilot-design-of-cloudnativeistio-02/</link>
      <pubDate>Fri, 19 Jul 2019 14:44:37 +0000</pubDate>
      
      <guid>https://idouba.com/istio-pilot-design-of-cloudnativeistio-02/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《云原生服务网格Istio:原理,实践,架构与源码解析》一书架构篇的第14章司令官Pilot，第4节Pilot的设计亮点。更多内容参照原书，或者关注容器魔方公众号。作者：中虎
作为Istio数据面的司令官，Pilot控制中枢系统，它的性能好坏直接影响服务网格的大规模可扩展、配置时延等。如果Pilot的性能低，配置生成效率也低，那么它将难以管理大规模服务网格。比如，服务网格拥有成千上万服务及数十万服务实例，配置生成的效率很低，难以满足服务及Config更新带来的配置更新需要，将会造成Pilot负载很高，用户体验很差。Istio社区网络工作组很早就已经意识到这个问题，并在近期的版本中相继做了很多优化工作，本节选取具有代表性的4个优化点进行讲解。
14.4.1 三级缓存优化 缓存模型是软件系统中最常用的一种性能优化机制，通过缓存一定的资源，减少CPU利用率、网络I/O等，Pilot在设计之初就重复利用缓存来降低系统CPU及网络开销。目前在Pilot层面存在三级资源的缓存，如图14-28所示。
​ 图14-28 Pilot层面的三级资源的缓存
以Kubernetes平台为例，所有服务及配置规则的监听都通过Kubernetes Informer实现。我们知道，Informer的LIST-WATCH原理是通过在客户端本地维护资源的缓存实现的。此为Pilot平台适配层的一级缓存。
平台层的资源（Service、Endpoint、VirtualService、DestinationRule等）都是原始的API模型，对于具体的Sidecar、Gateway配置规则的生成涉及平台层原始资源的选择，以及从原始资源到Istio资源模型的转换。如果在xDS配置生成过程中重复执行原始资源的选择与转换，则非常影响性能。因此Istio在中间层做了Istio资源模型的缓存优化。
最上面的一层缓存则是xDS配置的缓存。具体来讲，目前在xDS层面有两种配置缓存：Cluster与Endpoint，这两种资源较为通用，很少被Envoy代理的设置所影响。因此在xDS层面对Cluster及Endpoint进行缓存，能极大提高Pilot的性能。
随着Istio的发展与成熟，越来越多的缓存优化逐渐成型。当然，任何事物都有两面性，缓存技术同样带来了巨大的内存开销，我们同样需要综合权衡利弊。
14.4.2 去抖动分发 随着集群规模的增大，Config及服务、服务实例的数量成倍增长，任何更新都可能会导致Envoy配置规则的改变，如果每一次的更新都引起Pilot重新计算及分发xDS配置，那么可能导致Pilot过载及Envoy的不稳定。这些都难以支撑大规模服务网格的需求，因此Pilot在内部以牺牲xDS配置的实时性为代价换取了稳定性。
具体的去抖动优化是通过EnvoyXdsServer的handleUpdates模块完成的，其主要根据最小静默时间及最大延迟时间两个参数控制分发事件的发送来实现。图14-29展示了利用最小静默时间进行去抖动的原理：tN表示在一个推送周期内第N次接收到更新事件的时间，如果从t0到tN不断有更新事件发生，并且在tN时刻之后的最小静默时间段内没有更新事件发生，那么根据最小静默时间原理，EnvoyXdsServer将会在tN+minQuiet时刻发送分发事件到pushChannel。
​ 图14-29 利用最小静默时间进行去抖动的原理
图14-30展示了最大延迟的去抖动原理：在很长的时间段内源源不断地产生更新事件，并且事件的出现频率很高，不能满足最小静默时间的要求，如果单纯依赖最小静默时间机制无法产生xDS分发事件，则会导致相当大的延迟，甚至可能影响Envoy的正常工作。根据最大延迟机制，如果当前时刻距离t0时刻超过最大延迟时间，则无论是否满足最小静默时间的要求，EnvoyXdsServer也会分发事件到pushChannel。
​ 图14-30 最大延迟的去抖动原理
最小静默时间机制及最大延迟时间机制的结合，充分平衡了Pilot配置生成与分发过程中的时延及Pilot自身的性能损耗，提供了个性化控制微服务网格控制面性能及稳定性的方案。无论如何，Envoy代理的配置具有最终一致性，这也是微服务通信的基本要求。
14.4.3 增量EDS 我们知道，在集群或者网格中，数量最多、变化最快的必然是服务实例，在Kubernetes平台上，服务实例就是Endpoint（Kubernetes平台的服务实例资源）。尤其是，在应用滚动升级或者故障迁移的过程中会产生非常多的服务实例的更新事件。而单纯的服务实例的变化并不会影响Listener、Route、Cluster等xDS配置，如果仅仅由于服务实例的变化触发全量的xDS配置生成与分发，则会浪费很多计算资源与网络带宽资源，同时影响Envoy代理的稳定性。
Istio在1.1版本中引入增量EDS特性，专门针对以上场景对Pilot进行优化。首先，服务实例的Event Handler不同于前面提到的通用的事件处理回调函数（直接发送全量更新事件到updateChannel）。增量EDS异步分发的主要流程如图14-31所示。
可以看到，Kubernetes的Endpoint资源在更新时，首先在平台适配层由updateEDS将其转换为Istio特有的IstioEndpoint模型；然后，EnvoyXdsServer通过对比其缓存的IstioEndpoint资源，检查是否需要全量下发配置，并更新缓存；当仅仅存在Endpoints更新事件时，Pilot只需要进行增量EDS分发；随后，EnvoyXdsServer将增量EDS分发事件发送到updateChannel，后续处理步骤详见14.2.4节。
​ 图14-31 增量EDS异步分发的主要流程
为了深入理解增量EDS的特性，这里讲解EnvoyXdsServer是如何判断是否可以进行增量EDS分发的。EnvoyXdsServer全局缓存所有服务的IstioEndpoint及在每个推送周期内发生变化的服务列表。前面已经讲过，EnvoyXdsServer是通过IstioEndpoint缓存判断是否需要全量配置下发的。在每个推送周期内，EnvoyXdsServer都维护了本周期内所有涉及Endpoint变化的服务列表，当增量EDS分发开始时，Pilot将在本次推送周期内更新的服务名称通过pushChannel发送到请求处理模块进行配置分发，这时只需生成与本推送周期变化的服务相关的EDS配置并下发即可。
14.4.4 资源隔离 随着用户对Istio服务网格的需求越来越旺盛，Istio社区充分认识到服务隔离或者说作用范围的必要性。通过有效定义访问范围及服务的有效作用范围，可以大大消除网格规模增加带来的配置规模几何级的增长，目前在理论上可支持无限大规模的服务网格。
Istio目前充分利用命名空间隔离的概念，在两方面做了可见范围的优化：用Sidecar API资源定义Envoy代理可以访问的服务；用服务及配置（VirtuslService、DestinationRule）资源定义其有效范围。
Sidecar API资源是Istio 1.1新增的特性，目前支持为同一命名空间下的所有Envoy或者通过标签选择为特定的Envoy定义其对外可访问的服务（支持具体的服务名称或者命名空间的基本服务）。 服务及配置规则的可见范围。目前可定义同一命名空间可见或者全局范围可见。Istio通过其实现服务访问层面的隔离，同Sidecar API资源一起减少xDS配置数量。 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio服务熔断 –《云原生服务网格Istio》书摘01</title>
      <link>https://idouba.com/istio-curcuit-break-of-cloudnativeistio/</link>
      <pubDate>Thu, 11 Jul 2019 10:17:31 +0000</pubDate>
      
      <guid>https://idouba.com/istio-curcuit-break-of-cloudnativeistio/</guid>
      <description>
        
          
            本节书摘来自华为云原生技术丛书《云原生服务网格Istio:原理,实践,架构与源码解析》一书中的第3章非侵入的流量治理，第3节Istio流量治理的原理3.1.2小节服务熔断。更多内容参照原书，或者关注容器魔方公众号。
熔断器在生活中一般指可以自动操作的电气开关，用来保护电路不会因为电流过载或者短路而受损，典型的动作是在检测到故障后马上中断电流。“熔断器”这个概念延伸到计算机世界中指的是故障检测和处理逻辑，防止临时故障或意外导致系统整体不可用，最典型的应用场景是防止网络和服务调用故障级联发生，限制故障的影响范围，防止故障蔓延导致系统整体性能下降或雪崩。
如图3-6所示为级联故障示例，可以看出在4个服务间有调用关系，如果后端服务recommendation由于各种原因导致不可用，则前端服务forecast和frontend都会受影响。在这个过程中，若单个服务的故障蔓延到其他服务，就会影响整个系统的运行，所以需要让故障服务快速失败，让调用方服务forecast和frontend知道后端服务recommendation出现问题，并立即进行故障处理。这时，非常小概率发生的事情对整个系统的影响都足够大
​ 图3-6 级联故障示例
在Hystrix官方曾经有这样一个推算：如果一个应用包含30个依赖的服务，每个服务都可以保证99.99%可靠性地正常运行，则从整个应用角度看，可以得到99.9930 =99.7%的正常运行时间，即有0.3%的失败率，在10亿次请求中就会有3 000 000多种失败，每个月就会有两个小时以上的宕机。即使其他服务都是运行良好的，只要其中一个服务有这样0.001%的故障几率，对整个系统就都会产生严重的影响。
关于熔断的设计，Martin Fowler有一个经典的文章，其中描述的熔断主要应用于微服务场景下的分布式调用中：在远程调用时，请求在超时前一直挂起，会导致请求链路上的级联故障和资源耗尽；熔断器封装了被保护的逻辑，监控调用是否失败，当连续调用失败的数量超过阈值时，熔断器就会跳闸，在跳闸后的一定时间段内，所有调用远程服务的尝试都将立即返回失败；同时，熔断器设置了一个计时器，当计时到期时，允许有限数量的测试请求通过；如果这些请求成功，则熔断器恢复正常操作；如果这些请求失败，则维持断路状态。Martin把这个简单的模型通过一个状态机来表达，我们简单理解下，如图3-7所示。
​ 图3-7 熔断器状态机
图3-7上的三个点表示熔断器的状态，下面分别进行解释。
熔断关闭：熔断器处于关闭状态，服务可以访问。熔断器维护了访问失败的计数器，若服务访问失败则加一。 熔断开启：熔断器处于开启状态，服务不可访问，若有服务访问则立即出错。 熔断半开启：熔断器处于半开启状态，允许对服务尝试请求，若服务访问成功则说明故障已经得到解决，否则说明故障依然存在。 图上状态机上的几条边表示几种状态流转，如表3-1所示。
​ 表3-1 熔断器的状态流转
Martin这个状态机成为后面很多系统实现的设计指导，包括最有名的Hystrix，当然，Istio的异常点检测也是按照类似语义工作的，后面会分别进行讲解。
1．Hystrix熔断
关于熔断，大家比较熟悉的一个落地产品就是Hystrix。Hystrix是Netflix提供的众多服务治理工具集中的一个，在形态上是一个Java库，在2011年出现，后来多在Spring Cloud中配合其他微服务治理工具集一起使用。
Hystrix的主要功能包括：
阻断级联失败，防止雪崩； 提供延迟和失败保护； 快速失败并即时恢复； 对每个服务调用都进行隔离； 对每个服务都维护一个连接池，在连接池满时直接拒绝访问； 配置熔断阈值，对服务访问直接走失败处理Fallback逻辑，可以定义失败处理逻辑； 在熔断生效后，在设定的时间后探测是否恢复，若恢复则关闭熔断； 提供实时监控、告警和操作控制。 Hystrix的熔断机制基本上与Martin的熔断机制一致。在实现上，如图3-8所示，Hystrix将要保护的过程封装在一个HystrixCommand中，将熔断功能应用到调用的方法上，并监视对该方法的失败调用，当失败次数达到阈值时，后续调用自动失败并被转到一个Fallback方法上。在HystrixCommand中封装的要保护的方法并不要求是一个对远端服务的请求，可以是任何需要保护的过程。每个HystrixCommand都可以被设置一个Fallback方法，用户可以写代码定义Fallback方法的处理逻辑。
​ 图3-8 HystrixCommand熔断处理
在Hystrix的资源隔离方式中除了提供了熔断，还提供了对线程池的管理，减少和限制了单个服务故障对整个系统的影响，提高了整个系统的弹性。在使用上，不管是直接使用Netflix的工具集还是Spring Cloud中的包装，都建议在代码中写熔断处理逻辑，有针对性地进行处理，但侵入了业务代码，这也是与Istio比较大的差别。
业界一直以Hystrix作为熔断的实现模板，尤其是基于Spring Cloud。但遗憾的是，Hystrix在1.5.18版本后就停止开发和代码合入，转为维护状态，其替代者是不太知名的Resilience4J。
2．Istio熔断
云原生场景下的服务调用关系更加复杂，前文提到的若干问题也更加严峻，Istio提供了一套非侵入的熔断能力来应对这种挑战。
与Hystrix类似，在Istio中也提供了连接池和故障实例隔离的能力，只是概念术语稍有不同：前者在Istio的配置中叫作连接池管理，后者叫作异常点检测，分别对应Envoy的熔断和异常点检测。
Istio在0.8版本之前使用V1alpha1接口，其中专门有个CircuitBreaker配置，包含对连接池和故障实例隔离的全部配置。在Istio 1.1的V1alpha3接口中，CircuitBreaker功能被拆分成连接池管理（ConnectionPoolSettings）和异常点检查（OutlierDetection）这两种配置，由用户选择搭配使用。
首先看看解决的问题，如下所述。
在Istio中通过限制某个客户端对目标服务的连接数、访问请求数等，避免对一个服务的过量访问，如果超过配置的阈值，则快速断路请求。还会限制重试次数，避免重试次数过多导致系统压力变大并加剧故障的传播； 如果某个服务实例频繁超时或者出错，则将该实例隔离，避免影响整个服务。 以上两个应用场景正好对应连接池管理和异常实例隔离功能。
Istio的连接池管理工作机制对TCP提供了最大连接数、连接超时时间等管理方式，对HTTP提供了最大请求数、最大等待请求数、最大重试次数、每连接最大请求数等管理方式，它控制客户端对目标服务的连接和访问，在超过配置时快速拒绝。
如图3-9所示，通过Istio的连接池管理可以控制frontend服务对目标服务forecast的请求：
当frontend服务对目标服务forecast的请求不超过配置的最大连接数时，放行； 当frontend服务对目标服务forecast的请求不超过配置的最大等待请求数时，进入连接池等待； 当frontend服务对目标服务forecast的请求超过配置的最大等待请求数时，直接拒绝。 ​ 图3-9 Istio的连接池管理
Istio提供的异常点检查机制动态地将异常实例从负载均衡池中移除，如图3-10所示，当连续的错误数超过配置的阈值时，后端实例会被移除。异常点检查在实现上对每个上游服务都进行跟踪，对于HTTP服务，如果有主机返回了连续的5xx，则会被踢出服务池；而对于TCP服务，如果到目标服务的连接超时和失败，则都会被记为出错。
​ 图3-10 Istio异常点检查
另外，被移除的实例在一段时间之后，还会被加回来再次尝试访问，如果可以访问成功，则认为实例正常；如果访问不成功，则实例不正常，重新被逐出，后面驱逐的时间等于一个基础时间乘以驱逐的次数。这样，如果一个实例经过以上过程的多次尝试访问一直不可用，则下次会被隔离更久的时间。可以看到，Istio的这个流程也是基于Martin的熔断模型设计和实现的，不同之处在于这里没有熔断半开状态，熔断器要打开多长时间取决于失败的次数。
另外，在Istio中可以控制驱逐比例，即有多少比例的服务实例在不满足要求时被驱逐。当有太多实例被移除时，就会进入恐慌模式，这时会忽略负载均衡池上实例的健康标记，仍然会向所有实例发送请求，从而保证一个服务的整体可用性。
下面对Istio与Hystrix的熔断进行简单对比，如表3-2所示。可以看到与Hystrix相比，Istio实现的熔断器其实是一个黑盒，和业务没有耦合，不涉及代码，只要是对服务访问的保护就可以用，配置比较简单、直接。
​ 表3-2 Istio和Hystrix熔断的简单对比
          
          
        
      </description>
    </item>
    
    <item>
      <title>2019年元旦忆我的咕咚队友</title>
      <link>https://idouba.com/the-first-day-of-2019/</link>
      <pubDate>Tue, 01 Jan 2019 15:10:06 +0000</pubDate>
      
      <guid>https://idouba.com/the-first-day-of-2019/</guid>
      <description>
        
          
            2018，我和我的咕咚队友的故事。2019，我和我的咕咚队友的故事，还将继续。整理手机里的文字，告别和纪念逝去的2018，迎来2019，多些勇气和力量。
一百天，老太太离开我们整整一百天了，可能是过去的几十年里最难过最漫长的一百天。又一次踏上回家路。大清早四点多起床，背了一个空包就钻进了往机场的出租车。再也不用琢磨包里塞点老太太没有吃过的东西。包里空的，心里更空，
这段时间一直就心里空空的，乱乱的。莫名的会发脾气，也莫名的会忘东西。考勤纪律很严格的我厂里居然一个月里有好几次忘了打卡。
有几次奇怪的梦里梦到老太太。。。各种有意思的梦，有次还会梦到爷爷。也梦到了又和我这个咕咚队友一起健走。
真的很巧，马上就是元旦了，眼看着2018就这样过去了。整理手机备忘录里那几天手指头敲进去的一点文字。整理下文字，整理下心情。纪念过去的2018，纪念在2018逝去的祖母。
您永远在家人的心里。就像从来没有离开过一样。
十一月份一次出差深圳，一个人爬了南山，感觉就像开着咕咚领着我的那个懒懒的队友一样。感觉非常好，很踏实。我的脚能走多远，我的心就能走多远，装在心里的我这个队友就能陪我走多远。
农历十月十五，晚上十点多加完班跑回家，8800米，天上的月也很圆，街上人不多，很静，江边上更安静，有些汗，有些泪，很畅快，不累。
农历十一月十五，早上比平时早起了二十分钟，8800米，比平时多跑了一半路程。但应该没那个一辈子的每一天里天不亮就起来前后屋子扫地的队友起的早。
农历腊月十五，离过年就剩下半个月了，非常期待的一次健跑。
2019年，加油！总能感受到队友给予的力量和勇气，教给我的包容、知足、感恩和坦然，当然还有不作恶的叮嘱。感谢2018帮过我的所有人，特别是那个在八月份出差西安给的我几天假的boss哥，得以最后一次陪祖母我的咕咚队友健走了最后的90米。2019，会记住祖母一直唠叨的话，不呵斥孩子，好好说话，每次要发脾气的时候会提醒自己。祝福在新的一年里，家人、朋友和身边所有的人健康顺利。
2018，8800，发发发，2019，8800，就发发，约起来。。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio 调用链埋点原理剖析—是否真的“零修改”？</title>
      <link>https://idouba.com/istio-tracing-is-not-zero-code-change/</link>
      <pubDate>Thu, 29 Nov 2018 15:23:04 +0000</pubDate>
      
      <guid>https://idouba.com/istio-tracing-is-not-zero-code-change/</guid>
      <description>
        
          
            发在Infoq上的一篇文章，答疑当前大家工作中碰到的Istio调用链的问题，最终澄清了观点，并推动社区修改了说法，避免误解。
前言 在 Istio 的实践中最近经常被问到一个问题，使用 Istio 做调用链用户的业务代码是不是完全 0 侵入，到底要不要修改业务代码？
看官方介绍：
Istio makes it easy to create a network of deployed services with load balancing, service-to-service authentication, monitoring, and more, without any changes in service code.
是不用修改任何代码即可做各种治理。实际使用中应用程序不做任何修改，使用 Istio 的调用链输出总是断开的，这到底是什么原因呢？
对以上问题关注的人比较多，但是貌似说的都不是特别清楚，在最近的 K8S 技术社区的 Meetup 上笔者专门做了主题分享，通过解析 Istio 的架构机制与 Istio 中调用链的工作原理来回答以上问题。在本文中将节选里面的重点内容，基于 Istio 官方典型的示例来展开其中的每个细节和原理。
Istio 本身的内容在这里不多介绍，作为 Google 继 Kubernetes 之后的又一重要项目，Istio 提供了 Service Mesh 方式服务治理的完整的解决方案。正如其首页介绍，通过非侵入的方式提供了服务的连接、控制、保护和观测能力。包括智能控制服务间的流量和 API 调用；提供授权、认证和通信加密机制自动保护服务安全；通过开放策略来控制调用者对服务的访问；另外提供了可扩展丰富的调用链、监控、日志等手段来对服务与性能进行观测。即用户不用修改代码，就可以实现各种服务治理能力。
较之其他系统和平台，Istio 比较明显的一个特点是服务运行的监控数据都可以动态获取和输出，提供了强大的调用链、监控和调用日志收集输出的能力。配合可视化工具，运维人员可以方便的看到系统的运行状况，并发现问题进而解决问题。而我们基本上不用在自己的代码里做任何修改来生成数据并对接各种监控、日志、调用链等后端。非常神奇的是只要我们的程序被部署 run 起来，其运行数据就自动收集并在一个面板上展现出来。
调用链概述 对于分布式系统的运维管理和故障定位来说，调用链当然是第一利器。
正如 Service Mesh 的诞生是为了解决大规模分布式服务访问的治理问题，调用链的出现也是为了对应于大规模的复杂的分布式系统运行中碰到的故障定位定界问题。大量的服务调用、跨进程、跨服务器，可能还会跨多个物理机房。无论是服务自身问题还是网络环境的问题导致调用上链路上出现问题都比较复杂，如何定位就比单进程的一个服务打印一个异常栈来找出某个方法要困难的多。需要有一个类似的调用链路的跟踪，经一次请求的逻辑规矩完整的表达出来，可以观察到每个阶段的调用关系，并能看到每个阶段的耗时和调用详细情况。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio调用链埋点原理剖析—是否真的“零修改”分享实录（下）</title>
      <link>https://idouba.com/istio-tracing-meetup-02/</link>
      <pubDate>Sat, 10 Nov 2018 15:36:10 +0000</pubDate>
      
      <guid>https://idouba.com/istio-tracing-meetup-02/</guid>
      <description>
        
          
            接上文Istio调用链埋点原理剖析—是否真的“零修改”分享实录（上）
Isito调用链 调用链原理和场景 正如Service Mesh的诞生是为了解决大规模分布式服务访问的治理问题，调用链的出现也是为了对应于大规模的复杂的分布式系统运行中碰到的故障定位定界问题。大量的服务调用、跨进程、跨服务器，可能还会跨多个物理机房。无论是服务自身问题还是网络环境的问题导致调用上链路上出现问题都比较复杂，如何定位就比单进程的一个服务打印一个异常栈来找出某个方法要困难的多。需要有一个类似的调用链路的跟踪，经一次请求的逻辑规矩完整的表达出来，可以观察到每个阶段的调用关系，并能看到每个阶段的耗时和调用详细情况。Dapper, a Large-Scale Distributed Systems Tracing Infrastructure 描述了其中的原理和一般性的机制。模型中包含的术语也很多，理解最主要的两个即可：
Trace：一次完整的分布式调用跟踪链路。 Span：跨服务的一次调用； 多个Span组合成一次Trace追踪记录。 上图是Dapper论文中的经典图示，左表示一个分布式调用关系。前端（A），两个中间层（B和C），以及两个后端（D和E）。用户发起一个请求时，先到达前端，再发送两个服务B和C。B直接应答，C服务调用后端D和E交互之后给A应答，A进而返回最终应答。要使用调用链跟踪，就是给每次调用添加TraceId、SpanId这样的跟踪标识和时间戳。
右表示对应Span的管理关系。每个节点是一个Span，表示一个调用。至少包含Span的名、父SpanId和SpanId。节点间的连线下表示Span和父Span的关系。所有的Span属于一个跟踪，共用一个TraceId。从图上可以看到对前端A的调用Span的两个子Span分别是对B和C调用的Span，D和E两个后端服务调用的Span则都是C的子Span。
调用链系统有很多实现，用的比较多的如zipkin，还有已经加入CNCF基金会并且的用的越来越多的Jaeger，满足Opentracing语义标准的就有这么多。
一个完整的调用链跟踪系统，包括调用链埋点，调用链数据收集，调用链数据存储和处理，调用链数据检索（除了提供检索的APIServer，一般还要包含一个非常酷炫的调用链前端）等若干重要组件。上图是Jaeger的一个完整实现。这里我们仅关注与应用相关的内容，即调用链埋点的部分，看下在Istio中是否能做到”无侵入“的调用链埋点。当然在最后也会看下Istio机制下提供的不同的调用链数据收集方式。
Istio标准BookInfo例子 简单期间，我们以Istio最经典的Bookinfo为例来说明。Bookinfo模拟在线书店的一个分类，显示一本书的信息。本身是一个异构应用，几个服务分别由不同的语言编写的。各个服务的模拟作用和调用关系是： productpage ：productpage 服务会调用 details 和 reviews 两个服务，用来生成页面。 details ：这个微服务包含了书籍的信息。 reviews ：这个微服务包含了书籍相关的评论。并调用 ratings 微服务。 ratings ：ratings 微服务中包含了由书籍评价组成的评级信息。 调用链输出 在Istio上运行这个典型例子，不用做任何的代码修改，自带的Zipkin上就能看到如下的调用链输出。可以看到展示给我们的调用链和Boookinfo这个场景设计的调用关系一致：productpage 服务会调用 details 和 reviews 两个服务，reviews调用了ratings 微服务。除了显示调用关系外，还显示了每个中间调用的耗时和调用详情。基于这个视图，服务的运维人员比较直观的定界到慢的或者有问题的服务，并钻取当时的调用细节，进而定位到问题。 我们就要关注下调用链埋点到底是在哪里做的，怎么做的？
在Istio中，所有的治理逻辑的执行体都是和业务容器一起部署的Envoy这个Sidecar，不管是负载均衡、熔断、流量路由还是安全、可观察性的数据生成都是在Envoy上。Sidecar拦截了所有的流入和流出业务程序的流量，根据收到的规则执行执行各种动作。实际使用中一般是基于K8S提供的InitContainer机制，用于在Pod中执行一些初始化任务. InitContainer中执行了一段iptables的脚本。正是通过这些Iptables规则拦截pod中流量，并发送到Envoy上。Envoy拦截到Inbound和Outbound的流量会分别作不同操作，执行上面配置的操作，另外再把请求往下发，对于Outbound就是根据服务发现找到对应的目标服务后端上；对于Inbound流量则直接发到本地的服务实例上。
我们今天的重点是看下拦截到流量后Sidecar在调用链埋点怎么做的。
Istio调用链埋点逻辑 Envoy的埋点规则和在其他服务调用方和被调用方的对应埋点逻辑没有太大差别。
Inbound流量：对于经过Sidecar流入应用程序的流量，如果经过Sidecar时Header中没有任何跟踪相关的信息，则会在创建一个根Span，TraceId就是这个SpanId，然后再将请求传递给业务容器的服务；如果请求中包含Trace相关的信息，则Sidecar从中提取Trace的上下文信息并发给应用程序。 Outbound流量：对于经过Sidecar流出的流量，如果经过Sidecar时Header中没有任何跟踪相关的信息，则会创建根Span，并将该跟Span相关上下文信息放在请求头中传递给下一个调用的服务；当存在Trace信息时，Sidecar从Header中提取Span相关信息，并基于这个Span创建子Span，并将新的Span信息加在请求头中传递。 特别是Outbound部分的调用链埋点逻辑，通过一段伪代码描述如图：
调用链详细解析 如图是对前面Zipkin上输出的一个Trace一个透视图，观察下每个调用的细节。可以看到每个阶段四个服务与部署在它旁边上的Sidecar是怎么配合的。在图上只标记了Sidecar生成的Span主要信息。因为Sidecar 处理 Inbound和Outbound的逻辑有所不同，在图上表也分开两个框图分开表达。如productpage，接收外部请求是一个处理，给details发出请求是一个处理，给reviews发出请求是另外一个处理，因此围绕productpage这个app有三个黑色的处理块，其实是一个Sidecar在做事。
同时，为了不使的图上箭头太多，最终的Response都没有表达出来，其实图上每个请求的箭头都有一个反方向的Response。在服务发起方的Sidecar会收到Response时，会记录一个CR(client Received)表示收到响应的时间并计算整个Span的持续时间。
**下面通过解析下具体数据来找出埋点逻辑： **
首先从调用入口的Gateway开始，Gateway作为一个独立部署在一个pod中的Envoy进程，当有请求过来时，它会将请求转给入口服务productpage。Gateway这个Envoy在发出请求时里面没有Trace信息，会生成一个根Span：SpanId和TraceId都是f79a31352fe7cae9，因为是第一个调用链上的第一个Span，也就是一般说的根Span，所有ParentId为空，在这个时候会记录CS（Client Send）； 请求从入口Gateway这个Envoy进入productpage的app业务进程其Inbound流量被productpage Pod内的Envoy拦截，Envoy处理请求头中带着Trace信息，记录SR(Server Received)，并将请求发送给productpage业务容器处理，productpage在处理请求的业务方法中在接受调用的参数时，除了接受一般的业务参数外，同时解析请求中的调用链Header信息，并把Header中的Trace信息传递给了调用的Details和Reviews的微服务。 从productpage出去的请求到达reviews服务前，其Oubtbound流量又一次通过同Pod的Envoy，Envoy埋点逻辑检查Header中包含了Trace相关信息，在将请求发出前会做客户端的调用链埋点，即以当前Span为parent Span，生成一个子Span：新的SpanId cb4c86fb667f3114，TraceId保持一致9a31352fe7cae9，ParentId就是上个Span的Id： f79a31352fe7cae9。 从prodcutepage到review的请求经过productpage的Sidecar走LB后，发给一个review的实例。请求在到达Review业务容器前，同样也被Review的Envoy拦截，Envoy检查从Header中解析出Trace信息存在，则发送Trace信息给reviews。reviews处理请求的服务端代码中同样接收和解析出这些包含Trace的Header信息，发送给下一个Ratings服务。 在这里我们只是理了一遍请求从入口Gateway，访问productpage服务，再访问reviews服务的流程。可以看到期间每个访问阶段，对服务的Inbound和Outbound流量都会被Envoy拦截并执行对应的调用链埋点逻辑。图示的Reviews访问Ratings和productpage访问Details逻辑与以上类似，这里不做复述。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio调用链埋点原理剖析—是否真的“零修改”分享实录（上）</title>
      <link>https://idouba.com/istio-tracing-meetup-01/</link>
      <pubDate>Sat, 10 Nov 2018 15:07:36 +0000</pubDate>
      
      <guid>https://idouba.com/istio-tracing-meetup-01/</guid>
      <description>
        
          
            整理自2018年在K8S技术社区在腾讯大厦关于Istio调用链的分享。
前言 大家好，我是zhangchaomeng，来自华为Cloud BU，当前在做华为云应用服务网格。今天跟大家分享的主题是Istio调用链相关内容。通过剖析Istio的架构机制与Istio中调用链的工作原理来解答一个大家经常问道的一个问题：Istio是否像其官方文档中宣传的一样，对业务代码完全的无侵入，无需用做任何修改就可以完成所有的治理能力，包括调用链的埋点？
关于这个问题，可以提前透漏下，答案是让人有点沮丧的，得改点。在Isito中你不用在自己的代码里使用各种埋点的SDK来做埋点的逻辑，但是必须要有适当的配合的修改。
为什么本来无侵入的Service Mesh形态的技术却要求我们开发者修改些代码，到底要做哪些修改？Istio中调用链到底是怎么工作的？在下面的内容中将逐个回答这些问题。
本次分享的主题包括两部分: 第一部分作为背景和基础，介绍Istio的架构和机制；第二部分将重点介绍Istio调用链的相关内容，解答前面提出的几个问题。
Isito的架构和机制 Service Mesh 如官方介绍，Istio是一个用于连接、控制、保护和观测服务的一个开放平台。即：智能控制服务间的流量和API调用；提供授权、认证和通信加密机制自动保护服务安全；并使用各种策略来控制调用者对服务的访问；另外可以扩展丰富的调用链、监控、日志等手段来对服务的与性能进行观测。
Istio是Google继Kubernetes之后的又一重要项目，提供了Service Mesh方式服务治理的完整的解决方案。2017年5月发布第一个版本 0.1， 2018年6月1日发布了0.8版本，第一个LTS版本，当前在使用的1.0版本是今年7.31发布，对外宣传可用于生产。最新的1.1版本将2018.11中旬最近发布(当时规划实际已延迟，作者注)。
Istio属于Service Mesh的一种实现。通过一张典型图来了解下Service Mesh。如图示深色是Proxy，浅色的是服务，所有流入流出服务的都通过Proxy。Service Mesh正是由这一组轻量代理组成，和应用程序部署在一起，但是应用程序感知不到他的存在。特别对于云原生应用，服务间的应用访问拓扑都比较复杂，可以通过Service Mesh来保证服务间的调用请求在可靠、安全的传递。在实现上一般会有一个统一的控制面，对这些代理有个统一的管理，所有的代理都接入一个控制面。对代理进行生命期管理和统一的治理规则的配置。 这里是对Service Mesh特点的一个一般性描述，后面结合Isito的架构和机制可以看下在Istio中对应的实现。
可以看到Service Mesh最核心的特点是在Proxy中实现治理逻辑，从而做到应用程序无感知。其实这个形态也是经过一个演变的过程的：
最早的治理逻辑直接由业务代码开发人员设计和实现，对服务间的访问进行管理，在代码里其实也不分治理和业务，治理本身就是业务的一部分。这种形态的缺点非常明显就是业务代码和治理的耦合，同时公共的治理逻辑有大量的重复。
很容易想到封装一个公共库，就是所谓的SDK，使用特定的SDK开发业务，则所有治理能力就内置了。Spring Cloud和Netflix都是此类的工具，使用比较广泛，除了治理能力外，SDK本身是个开发框架，基于一个语言统一、风格统一的开发框架开发新的项目非常好用。但这种形态语言相关，当前Java版本的SDK比较多。另外对于开发人员有一定的学习成本，必须熟悉这个SDK才能基于他开发。最重要的是推动已经在用的成熟的系统使用SDK重写下也不是个容易的事情。比如我们客户中就有用C开发的系统，运行稳定，基本不可能重写。对这类服务的治理就需要一个服务外面的治理方式。
于是考虑是否可以继续封装，将治理能力提到进程外面来，作为独立进程。即Sidecar方式，也就是广泛关注的Service Mesh 的。真正可以做到对业务代码和进程0侵入，这对于原来的系统完全不用改造，直接使用Sidecar进行治理。
用一段伪代码来表示以上形态的演变：
可以看到随着封装越来越加强，从公共库级别，到进程级别。对业务的侵入越来越少，SDK的公共库从业务代码中解耦，Sidecar方式直接从业务进程解耦了。对应的治理位置越来越低，即生效的位置更加基础了。尤其是Service Mesh方式下面访问通过 Proxy执行治理，所以Service Mesh的方式也已被称为一种应用的基础设施层，和TCP/IP的协议栈一样。TCP/IP负责将字节流可靠地在网络节点间传递；而应用基础设施则保证服务间的请求在安全、可靠、可被管控的传递。这也对应了前面Istio作为Service Mesh一种实现的定位。 Istio 关键能力 Istio官方介绍自己的关键能力如上所示，我把它分为两部分：一部分是功能，另有一部分提供的扩展能力。
功能上包括流量管理、策略执行、安全和可观察性。也正好应对了首页的连接、保护、控制和观测四大功能。
流量管理：是Istio中最常用的功能。可以通过配置规则和访问路由，来控制服务间的流量和API调用。从而实现负载均衡、熔断、故障注入、重试、重定向等服务治理功能，并且可以通过配置流量规则来对将流量切分到不同版本上从而实现灰度发布的流程。 策略执行：指Istio支持支持访问控制、速率限制、配额管理的能力。这些能力都是通过可动态插入的策略控制后端实现。 安全：Istio提供的底层的安全通道、管理服务通信的认证、授权，使得开发任务只用关注业务代码中的安全相关即可。 可观察性：较之其他系统和平台，Istio比较明显的一个特点是服务运行的监控数据都可以动态获取和输出，提供了强大的调用链、监控和调用日志收集输出的能力。配合可视化工具，运维人员可以方便的看到系统的运行状况，并发现问题进而解决问题。我们这次分享的主题调用链也正是Isito可观察性的一个核心能力。 后面分析可以看到以上四个特性从管理面看，正好对应Istio的三个重要组件。
扩展性：主要是指Istio从系统设计上对运行平台、交互的相关系统都尽可能的解耦，可扩展。这里列出的特性：
平台支持：指Istio可以部署在各种环境上，支持Kubernetes、Consul等上部署的服务，在之前版本上还支持注册到Eureka上的Service，新版本对Eureka的支持被干掉了；
集成和定制：指的Istio可以动态的对接各种如访问控制、配额管理等策略执行的后端和日志监控等客观性的后端。支持用户根据需要按照模板开发自己的后端方便的集成进来。
其实这两个扩展性的能力正好也对应了Istio的两个核心组件Pilot和Mixer，后面Isito架构时一起看下。
Istio 总体架构 以上是Isito的总体架构。上面是数据面，下半部分是控制面。 数据面Envoy是一个C++写的轻量代理，可以看到所有流入流出服务的流量都经过Proxy转发和处理，前面Istio中列出的所有的治理逻辑都是在Envoy上执行，正是拦截到服务访问间的流量才能进行各种治理；另外可以看到Sidecar都连到了一个统一的控制面。
Istio其实专指控制面的几个服务组件：
Pilot：Pilot干两个事情，一个是配置，就是前面功能介绍的智能路由和流量管理功能都是通过Pilot进行配置，并下发到Sidecar上去执行；另外一个是服务发现，可以对接不同的服务发现平台维护服务名和实例地址的关系并动态提供给Sidecar在服务请求时使用。Pilot的详细功能和机制见后面组件介绍。 Mixer：Mixer是Istio中比较特殊，当前甚至有点争议的组件。前面Isito核心功能中介绍的遥测和策略执行两个大特性均是Mixer提供。而Istio官方强调的集成和定制也是Mixer提供。即可以动态的配置和开发策略执行与遥测的后端，来实现对应的功能。Mixer的详细功能和机制见后面组件介绍。 Citadel：主要对应Istio核心功能中的安全部分。配合Pilot和Mixer实现秘钥和证书的管理、管理授权和审计，保证客户端和服务端的安全通信，通过内置的身份和凭证提供服务间的身份验证，并进而该通基于服务表示的策略执行。 Isito主要组件Pilot 如Istio架构中简介，Pilot实现服务发现和配置管理的功能。 作为服务发现，Pilot中定义了一个抽象的服务模型，包括服务、服务实例、版本等。并且只定义的服务发现的接口，并未实现服务发现的功能，而是通过Adapter机制以一种可扩展的方式来集成各种不同的服务发现，并转换成Istio通用的抽象模型。 如在Kubernetes中，Pilot中的Kubernetes适配器通过Kube-APIServer服务器得到Kubernetes中对应的资源信息。而对于像Eureka这种服务注册表，则是使用一个Eureka的HTTP Client去访问Eureka的名字服务的集群，获取服务实例的列表。不管哪种方式最终都转换成Pilot的标准服务发现定义，进而通过标准接口提供给Sidecar使用。
而配置管理，则是定义并维护各种的流量规则，来实现负载均衡、熔断、故障注入、流量拆分等功能。并转换成Envoy中标准格式推送给Envoy，从而实现治理功能。所有的这些功能用户均不用修改代码接口完成。详细的配置方式可以参照Istio Traffic Routing中的规则定义。重点关注：VirtualService、 DestinationRule、 Gateway等规则定义。如可以使用流量规则来配置各种灰度发布，也可以通过注入一个故障来测试故障场景；可以配置熔断来进行故障恢复；并且可以对HTTP请求根据我们的需要进行重定向、重写，重试等操作。
Istio主要组件Mixer Mixer是Isito特有的一个组件。主要做两个功能Check和Report，分别对应Istio官方宣传的两个重大特性策略执行和遥测功能。逻辑上理解每次服务间的请求都会通过proxy连接Mixer来进行处理，由Mixer来将请求派发到对应的后端上处理。通过扩展不同的后端来增强Mixer的能力。如可以做访问控制、配额等这样的控制，也可以对接不同的监控后端来做监控数据的收集，进而提供网格运行的可观察性能力。 Mixer通过使用通用插件模型实现的对接不同后端，避免了proxy为了完成不同的功能而去对接各种不同的后端。每个插件都被称为Adapter。对于每个请求Sidecar会从每一次请求中收集相关信息，如请求的路径，时间，源IP，目地服务，tracing头，日志等，并请这些属性上报给Mixer。Mixer和后端服务之间是通过适配器进行连接的，Mixer将Sidecar上报的内容通过适配器发送给后端服务。可以在不停止应用服务的情况下动态切换后台服务。
          
          
        
      </description>
    </item>
    
    <item>
      <title>月圆满，人圆满，中秋别祖母</title>
      <link>https://idouba.com/mid-autumn-and-my-grandmother/</link>
      <pubDate>Sun, 23 Sep 2018 16:38:08 +0000</pubDate>
      
      <guid>https://idouba.com/mid-autumn-and-my-grandmother/</guid>
      <description>
        
          
            2018中秋，十多年了第一次在这天回到家里。不是为团聚，而是为离别。
昨晚九点四十上接到的电话，祖母走了。当时没有难过，可能是因为还没想好接受。前天刚视频过，老太太脸色上看人还胖了点，和我说了许久
然后，然后人就不行了。实在忍不住捶胸，吓坏了客厅的孩子。
知道当前这种距离格局下这是迟早的，但没想到会来的这么快这么突然。真到来时还是没法接受。
悔恨，懊恼，有点扭曲的心里撕裂的疼。
前天中午视频的时候有点漫不经心，可能是上班中午困了吧。老太太来来回回就是这么几句：娃多大了，上学好好去的吧，不要呵斥娃，有话好好说，娃还小。来回几遍，偶尔会来一遍过年把娃领回来看看啊！
后悔最近变懒了，事情多了，原来隔天视频最近一周才一次，最近这次两周才打的。
老太太说她吃了两个菜合煎饼，妈妈说吃了三个。老太太一直胃口都还可以，每天晚上还会喝碗鲜奶。
但明显今年越来越懒了，不爱动了。坐下就不愿意起来，喜欢坐在那儿犯困发呆。今年回家几次拉着出去散步，走不了一百米就说“咱回，不走了”。而且明显一次比一次懒了。过年的时候能硬拽着走几百米，五月份就只能哄着绕着村子转了，七月份那次真的是从凳子上拉起来都费劲，太懒了。
七月份一起走路时还给我回忆了她当年当妇女队长的事，对一个已经老年痴呆有点老糊涂的老太太来说真是不容易。
有人算过在外地一辈子和一生中和家人见面的次数总共有非常可怜的几十次。对我和祖母，我早知道是和零非常接近的一个个位数，今天这个数字终于走到了那个零。
回想下见面的次数真的能数的过来：
十五岁去外地念书，才开学二十天，老太太就跟着爸爸和弟弟就坐了一夜的火车到我的学校。宿舍的同学国庆节都回家了，就住在我的宿舍里，半夜老太太又起来给我盖被子，和在家一样。四年中专回过九次家，四年寒暑假外有一次是在洛阳重机厂车间实习，国庆回了趟家。
后来十九岁毕业了，要去东北铁路工地上修铁路，从渭南铁一局桥梁处的机关培训完中午赶回家，晚上就要坐火车去沈阳工地，老太太下午给缝了一个新的棉花褥子。带着就上了晚上往东北的火车。在工地上第一次收到妈妈的来信，想起祖母，这条新到工地上也算是铁路汉子哭的停不下来，记得工友刘哥他们还以为家里出了什么事，一直过来安慰我。
再后来从工地回来，回到离家近的西安，干点不像样的工作挣点小钱，自个儿再去看点书学点东西，从修桥的转到了现在的所谓计算机行当，然后考研考到西工大。那几年虽然离家不远，但基本上也是三四个月半年回一次。家人管这个叫上进有事业心，老太太也跟着说好好学习不用惦记她，后来回想只想再多抽自己几个嘴巴子。
研究生毕业几个offer上选择时，留在西安还是去外地，最终还是被趋势的工作内容打动，选择了先出去工作两年再回西安。清楚记得和一个知心的师姐和他家大哥一起商量，在外地工作和老太太见面就不方便了，那会儿还没有微信，当时商量认为用电脑摄像头视频挺方便的，可以随时至少每天见到。但事实上两年后并没有回去，两年里也没有过一次视频过。反倒是回家的次数越来越少，停留的时间越来越短，和老人电话里的沟通也越来越机械，中午吃的什么，天气冷不冷这些。再后来老太太老年痴呆越来越糊涂了，连中午吃的什么都说开始瞎胡说了。
后来有了自己的家，老太太那就是一个老家，老家里的一个重要符号，但也只是个符号，有时会打开，有时候忙了就顾不上了，中间有几个过年都没有回去看她。每次从家回来会隔一天在中午吃饭后和老太太微信视频下，但后面忙起来懒起来就一周一次都不一定了。老太太还是重复那几句：娃多大了，上学好好去不？娃小不要呵斥娃，好好和娃说话。老太太后面还学会了一句“还有啥跟婆说不？没了挂了吧，回去歇着吧”，因为有时有点累或者懒我说话的音量和情绪让老太太也不自在，经常“你说啥”问个个不停，甚至答非所问得懒懒的说上一会儿。
老太太对孙子们的疼爱是出了名的。曾经有过一阵子小学上课搞两大晌，大家上学都是急急忙忙拿个馍装书包就走了，只有我家老太太很早起来做好孙子一人份稀饭，热腾腾的吃完才去，然后她再给家人做第二顿早饭。
小学初中时候每天中午吃完饭手里拿一个黄灿灿的灶塘里烤好的热腾腾又脆脆的干馍是小伙伴们最羡慕的，比起其他人的一处焦一处白的，手里这个黄干脆脆的东西老太太每天得花多少心思，多少感情在上面。
记得上小学还是初中时候有个邻居曾经开玩笑以后去外地念书上班把你奶奶带着，老太太就可以一直给你做饭了，老太太也不用整天在家里念叨孙子了。这是玩笑，却也是实情。从很小到长到成年，到现在为人父，还没有做好没有这个老太太的世界是什么样子。不是不够坚强，是真的没有习惯。
清楚记得初一第一次语文课，题目是那会儿很常见的《我的**》，很多人写《我的妈妈》或者《我的爸爸》，我的一篇《我的奶奶》被特别表扬了，不是这个从小就表现出理工男特质的小屁孩的文采能有多好，只是因为流水帐一样写下老太太的日常就足够感动那个姓史的语文老师。
从记事开始就和爷爷奶奶一起睡在老房子的土炕上，冬天里点火烧炕的，有时整个屋子都是烟熏的睁不开眼。到后来搬到这个新房子，每次回家也会睡奶奶的大炕上，大炕那头连着厨房的火塘，暖烘烘的，冬天里贴着腰特别舒服，踏实，去乏。当然不多的几次带着老婆孩子回家都会睡楼上的自己的房间。就在奶奶走前的一个月，西安出差周末回家了三天，还睡过奶奶的这个大坑。一般都是奶奶睡炕那头，我睡炕这头。经常半夜老太太又挪到大坑这头，给大孙子把被子角往上拽拽，尽管这个大孙子已经不是两三岁，而是近四十的孩子他爹。曾经非常想领着那个整天蹦哒停不下来的儿子来老祖母的大炕上感受一下，感受下开阔和暖烘烘大炕，感受下老祖母的开阔又有温度的爱，但终没来的及。想到这里，觉得对不起孩子，更对不起那个老太太。
这次回来，大炕还是同样的温度，但却空荡荡。老太太独自躺在前厅的玻璃柜子里，等待儿孙们送她到西边地里爷爷的身旁。妈妈说天渐变凉，奶奶走的前一天晚上刚从大炕上换下了夏天的薄床单，换上了秋冬的厚毛线床单。
晚上一个人去了老太太将要安息的地方。苹果园地头的这棵大白杨树下不远就是。通往这里家西边这条路是以前每次和老太太咕咚健走的地方。
一个人又走了遍队友一起走过的这段路，今天下着小雨静的吓人，一个人但一路走过来路边的核桃树、苹果树、空地的话题都在：“现在这杮子品种不行，没人要了；苹果现在太多了所以不值钱了；你看这家地里草多高，啥也没种，年轻娃都出去打工不种地了”
后来又领着姨奶奶在这条路上散步，奶奶的妹妹比奶奶小了十多岁，给我讲她们的母亲走的早，奶奶做为老大怎么照顾他们姊妹四个。后来她们成家后又挨个照看二姨奶奶的五个表叔叔，给做针线活，给做吃的养活他们。姨奶奶的外形和神态像极了奶奶，一起走回来就像之前领着奶奶一样，乱乱的心里有了些许慰藉。就像姨奶奶说的，奶奶用他的善良辛劳节俭养活了一大家的人，养活和影响了几辈人。
早上上楼，后院的核桃树上突然有一大群长尾的鸟飞过来，停下来，叽叽喳喳叫的很急，很快又都飞走了。在老太太眼里这棵核桃树上产的都是最宝贝的东西，每年收下来都在楼上一遍一遍的晾干，然后等孙子回来装成小袋子，塞到他的箱子里。但可恨的是，孙子有多孙子，一年一年的带去，发现去年的还没吃，已经放出虫子了。
今天家里人很多，过两天要按村里人的习俗有个仪式为老太太送行。人多说话声音很杂，但人群里总是冷不丁感觉到一个熟悉的声音，可能是一个大妈婶婶的声音和老太太很像，或者是我幻听了，一天一直在幻听。中午人少的时候，看看厨房、后院、大炕，总感觉她还在那里，揽柴火、烧锅，或者坐在炕边椅子上发呆。笤帚、水杯、椅子，家里的每个大小物件都是她的日常，总是感觉那个熟悉的身影又慢悠悠的走过来。
没什么精神，今天大多时间都是扎着脑袋坐在老太太常坐的小椅子上，总感觉有那种轻轻的鞋底在地上塔拉的声音在慢慢走近，然后有人站在前面，笑眯眯的，手里拿着个小吃的。
老太太自己不太吃饭以外的东西，但给我们很上心。记得之前家里前厅开着小卖部，夏天放假回家，老太太总隔会儿从冰柜里取出个雪糕，“尝尝，今儿很多娃买这种”。遗憾的是我对这些零食也一直不感兴趣，好像没吃过那些雪糕，老太太总是扫兴的自己又放回去了。再后来老太太就开始糊涂了，什么东西多少钱自己乱说开了，收的钱放那儿了自己也说不清了。然后小卖部就关门了。
每次回家带给她的吃的只有当时打开她才吃，自己从来想不起吃，其实是舍不得变成的一种习惯。今天老太太房间的桌子上，上个月西安出差回家买的那些吃的，几样还没开包装，有几样还是我那天打开两人分着吃剩下的。当时在前厅，吹着过道凉风，分着吃各种干果、水果的感觉和那次一百米的咕咚健步走是最后一次印象深刻的团队运动，遗憾的是，老太太吃几个就说“你吃你吃，婆不吃了”。
老太太太爱操心，操小家的心，操大家的心，直到湖涂了有些原来操心的事想不起来了，才慢慢消停了。但仍然每天晚上会检查家里大门有没有关好，检查了又忘了，有时回好几遍。祖母走的昨晚，就是自己跑到前屋检查了两遍大门后回去，睡觉前又跑出来，突然发病摔倒就再也没有醒过来。
老太太走的太急，一家人到现在还不能接受。大家族里一个上年纪的四婶专门过来安慰妈妈：“这都是一辈子积德积来的福份，八十八岁高龄，不影响吃喝，没躺炕上或医院受一天的罪，就这样安静利索的走了。自己不受罪，也不连累子女们。老太太临到最后都是不给人添麻烦。一辈子都是这样，只给人帮忙，从来不给人添麻烦。你看走的这个日子还是八月十五娃放假，都不让孙子们麻烦请假。”。四婶年龄比奶奶小不了几岁，说的是对的。以前这些老太太们的这些有点迷信的道理是不爱听的，但这回是听进去了。老太太真的是这个时候也不想给儿孙们添麻烦，连百日祭的日子都是后面的元旦假期了。
说德高望重是在整个村里人们对她的评价。后辈的眼里，祖母生活中传递给我们的的品质更值得铭记。勤俭、正直、善良是邻里们对老太太的评价，老太太唱给我们说的是行善不做恶。从来不做亏人的事情。对亲人，邻居，或者陌生人。以前门口要饭的到这家门口，都比较喜欢找这个老太太。
昨晚在杭州家里从接到电话到四点多赶第一班飞机，基本没睡。今晚到从九点一觉睡到早上，睡的很踏实。心里不平静，一阵一阵的疼，还是那种手机备忘录纪录下思绪。
今天是中秋节，中秋月满，祖母也在这天圆满的走完了这一生。村里人说连倒下这天也是考虑了儿孙们这两天有假期。因为都说她一辈子只为亲人操心，唯独自己总是凑合。老太太不知道自己的生日，中秋节对于全家人会有另外一种意义。
之前从来没有想过来世的说法，也第一次自己提起这个词。但此刻真的希望有来世，再当您的孙子，我真的没当够。您养我长大，我陪您健走。如果有来世，不孝孙子一定不会跑的离您这么远了。
和我的咕咚队友来个约定，每月的月圆的那天会是特别的一天，8800米，纪念我88岁的咕咚队友，让我静静地想您，流着汗，流着泪，我相信您会在我身边一起跟着我慢慢的跑，我会一直跑，一直跑到我跑不动的那一天。
2018，农历八月十五前夜，月圆满，人圆满。八十八岁，送别我的祖母，送别我的咕咚队友。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio技术与实践02：源码解析之Istio on Kubernetes 统一服务发现</title>
      <link>https://idouba.com/istio-01-code-pilot-service-discovery-upon-k8s/</link>
      <pubDate>Mon, 23 Jul 2018 14:35:50 +0000</pubDate>
      
      <guid>https://idouba.com/istio-01-code-pilot-service-discovery-upon-k8s/</guid>
      <description>
        
          
            【摘要】 本文基于Pilot服务发现Kubernetes部分源码重点介绍在Istio on Kubernetes环境下，如何基于Pilot的Adapter机制实现Istio管理的服务直接使用Kubernetes service来做统一服务发现，避免了其他微服务框架运行在Kubernetes环境时上下两套服务目录的局面。并以此为入口从架构、场景等方面总结下Istio和Kubernetes的结合关系。
前言 文章Istio技术与实践01： 源码解析之Pilot多云平台服务发现机制结合Pilot的代码实现介绍了Istio的抽象服务模型和基于该模型的数据结构定义，了解到Istio上只是定义的服务发现的接口，并未实现服务发现的功能，而是通过Adapter机制以一种可扩展的方式来集成各种不同的服务发现。本文重点讲解Adapter机制在Kubernetes平台上的使用。即Istio on Kubernetes如何实现服务发现。
Kubernetes和Istio的结合Kubernetes和Istio的结合 从场景和架构上看Istio和Kubernetes都是非常契合的一种搭配。从场景和架构上看Istio和Kubernetes都是非常契合的一种搭配。
首先从场景上看Kuberntes为应用负载的部署、运维、扩缩容等提供了强大的支持。通过Service机制提供了负载间访问机制，通过域名结合Kubeproxy提供的转发机制可以方便的访问到对端的服务实例。因此如上图可以认为Kubernetes提供了一定的服务发现和负载均衡能力，但是较深入细致的流量治理能力，因为Kubnernetes所处的基础位置并未提供，而Istio正是补齐了这部分能力，两者的结合提供了一个端到端的容器服务运行和治理的解决方案。
从架构看Istio和Kubernetes更是深度的结合。 得益于Kuberntes Pod的设计，数据面的Sidecar作为一种高性能轻量的代理自动注入到Pod中和业务容器部署在一起，接管业务容器的inbound和outbound的流量，从而实现对业务容器中服务访问的治理。在控制面上Istio基于其Adapter机制集成Kubernetes的域名，从而避免了两套名字服务的尴尬场景。
在本文中将结合Pilot的代码实现来重点描述图中上半部分的实现，下半部分的内容Pilot提供的通用的API给Envoy使用可参照上一篇文章的DiscoverServer部分的描述。
基于Kubernetes的服务发现 理解了Pilot的ServiceDiscovery的Adapter的主流程后，了解这部分内容比较容易。Pilot-discovery在initServiceControllers时，根据服务注册配置的方式，如果是Kubernetes，则会走到这个分支来构造K8sServiceController。
1case serviceregistry.KubernetesRegistry: 2s.createK8sServiceControllers(serviceControllers, args); err != nil { 3return err 4} 创建controller其实就是创建了一个Kubenernetes的controller，可以看到List/Watch了Service、Endpoints、Node、Pod几个资源对象。
1// NewController creates a new Kubernetes controller 2func NewController(client kubernetes.Interface, options ControllerOptions) *Controller { 3 out := &amp;amp;Controller{ 4 domainSuffix: options.DomainSuffix, 5 client: client, 6 queue: NewQueue(1 * time.Second), 7 } 8 out.services = out.createInformer(&amp;amp;v1.Service{}, &amp;#34;Service&amp;#34;, options.ResyncPeriod, 9 func(opts meta_v1.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio技术与实践01： 源码解析之Pilot多云平台服务发现机制</title>
      <link>https://idouba.com/istio-01-code-pilot-service-discovery-adapter/</link>
      <pubDate>Sat, 21 Jul 2018 16:12:44 +0000</pubDate>
      
      <guid>https://idouba.com/istio-01-code-pilot-service-discovery-adapter/</guid>
      <description>
        
          
            前言 本文结合Pilot中的关键代码来说明下Istio的服务发现的机制、原理和流程。并以Eureka为例看下Adapter的机制如何支持多云环境下的服务发现。可以了解到： 1. Istio的服务模型; 2. Istio发现的机制和原理; 3. Istio服务发现的adpater机制。 基于以上了解可以根据需开发集成自有的服务注册表，完成服务发现的功能。
服务模型 首先，Istio作为一个（微）服务治理的平台，和其他的微服务模型一样也提供了Service，ServiceInstance这样抽象服务模型。如Service的定义中所表达的，一个服务有一个全域名，可以有一个或多个侦听端口。
1type Service struct { 2 // Hostname of the service, e.g. &amp;#34;catalog.mystore.com&amp;#34; 3 Hostname Hostname `json:&amp;#34;hostname&amp;#34;` 4 Address string `json:&amp;#34;address,omitempty&amp;#34;` 5 Addresses map[string]string `json:&amp;#34;addresses,omitempty&amp;#34;` 6 // Ports is the set of network ports where the service is listening for connections 7 Ports PortList `json:&amp;#34;ports,omitempty&amp;#34;` 8 ExternalName Hostname `json:&amp;#34;external&amp;#34;` 9 ... 10 } 当然这里的Service不只是mesh里定义的service，还可以是通过serviceEntry接入的外部服务。每个port的定义在这里：
1type Port struct { 2 Name string `json:&amp;#34;name,omitempty&amp;#34;` 3 Port int `json:&amp;#34;port&amp;#34;` 4 Protocol Protocol `json:&amp;#34;protocol,omitempty&amp;#34;` 5 } 除了port外，还有 一个name和protocol。可以看到支持如下几个Protocol ：
          
          
        
      </description>
    </item>
    
    <item>
      <title>论CAS在幼儿园点名中的应用</title>
      <link>https://idouba.com/cas-in-kids-garden/</link>
      <pubDate>Mon, 30 Oct 2017 15:51:14 +0000</pubDate>
      
      <guid>https://idouba.com/cas-in-kids-garden/</guid>
      <description>
        
          
            宝贝的幼儿园老师都是漂亮活泼又富有爱心的小天使一样的人物，非常神奇的教会了宝贝们很多我们家长们都搞不定的事情，非常有办法的完全不用发火的将这些淘气的小家伙们修理的服服贴贴，在小宝贝们眼里简直就是神一般的存在，当然在家长眼里也是。
如果你以为这就是全部，那就大错特错了。就在这两天发现了，她们居然也是深谙各种计算机中的算法。不得不偷着怀疑这些白天在学校里的陪孩子们玩的小姑娘们下班后是不是在菊厂或者其他公司写代码。
这不这两天在家长群里发了消息，就小露了一手。这个案例的背景是要收集到每个宝贝的家长对一个重要通知的确认。上级的重要通知，每个家的家长都要确认。如果你说请在群里回复“收到”那简直弱爆了。最终怎么确认每个都收到了。
看看我们美女老师设计的算法。如右图所示，每个家长的回复一个序号+宝贝名+收到，序号是根据前面的回复次序i++上来，并且每个回复要求追加在前面一个回复的后面。
这样：
第一个回复是：1 苹果收到； 第二个回复是：1 苹果收到 2 桃子收到； 最后一个回复是：1 苹果收到 2 桃子收到……32 橘子收到。 同一个时间段内家长回复非常密集（我们都非常积极的支持我们老师们的工作的），那发之前就要检查下是否符合这个规则。比如douba发之前，先拷贝前面的串，发现doudou轮到10号了，那我们该回复的串就是：1苹果收到 2 桃子收到……10豆豆收到。如果在发出去前发现有个家长先于我们发到群里了：1 苹果收到 2 桃子收到……10香蕉收到，那么douba这个提交就和香蕉冲突了，需要发：1 苹果收到 2 桃子收到……10香蕉收到收到 11 豆豆收到。
并发场景下，在更新同一个变量，先比较你读过来的值和当前值是否一致，一致表示在更新前这个值未被别人（其他线程）更新过，则允许替换；否则不一致说明别人（其他线程）已经更新过了，则不允许更新。是不是非常眼熟，不就是大名鼎鼎的的Compare and Swap的应用。
1public boolean cas(StringBuffer targetValue, String mySegment, String myOldValue) { 2if(targetValue.equals(myOldValue)){ 3targetValue.append(mySegment); 4return true;} 5else 6{ 7return false} 8} 9} 当然这个伪代码中的set操作不是机器指令上的原子操作，但也demo了CAS的思路。算法执行读-修改-写操作，而无需害怕其他线程同时修改变量，因为如果其他线程修改变量， 会检测它并失败，算法可以对该操作重新计算，因此是一种无锁的并发算法。
用在这个微信点名没法加锁的场景下，简单高效。设想后面老师要收集最终数据，只要检查最后的那个串上，所有的她所有的宝贝按顺序排列在上面，就像每天早上老师当队头排成长队去教室外面活动一样，保证一个都不会少。
          
          
        
      </description>
    </item>
    
    <item>
      <title>kubernetes liveness probe 流程</title>
      <link>https://idouba.com/kubernetes-liveness-probe/</link>
      <pubDate>Fri, 01 Sep 2017 15:39:48 +0000</pubDate>
      
      <guid>https://idouba.com/kubernetes-liveness-probe/</guid>
      <description>
        
          
            1 概述 kubernetes提供了的Probe可以进行健康检查。
https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
对pod中的每个容器通过配置liveness或者readiness。
当liveness probe failed后，该container会杀掉，并重新创建；而readinessProbe失败，则该pod ip 会从service的endpoints列表中删除，即隔离到该后端的请求。
如liveness 配置如下：
1livenessProbe: 2 httpGet: 3 port: 10252 4 path: “/healthz” 5 initialDelaySeconds: 15 6 timeoutSeconds: 15 文中尝试端到端的看下整个过程有哪些组件参与进来，怎么配合工作的。
2 配置 pkg/api/types.go#Probe结构描述了Probe的一个定义。其中Handler是执行的动作，initialDelaySeconds表示容器启动后延迟多少秒初始化probe，考虑一般应用启动需要一定时间。periodSeconds 表示周期检查的间隔，默认10秒，最小1秒。timeoutSeconds会告诉健康检查等待多长时间，默认1秒，最小1秒。successThreshold表示连续探测多少次成功才算成功。failureThreshold表示连续探测多少次失败才算失败。默认是3.
1type Probe struct { 2Handler json:&amp;#34;,inline&amp;#34; 3InitialDelaySeconds int32 json:&amp;#34;initialDelaySeconds,omitempty&amp;#34; 4TimeoutSeconds int32 json:&amp;#34;timeoutSeconds,omitempty&amp;#34; 5PeriodSeconds int32 json:&amp;#34;periodSeconds,omitempty&amp;#34; 6SuccessThreshold int32 json:&amp;#34;successThreshold,omitempty&amp;#34; 7FailureThreshold int32 json:&amp;#34;failureThreshold,omitempty&amp;#34; 8} 探测动作Handler支持httpget tcd 和exec三种动作。
httpGet对应一个http请求，主要是配置http端口和path；TCPSocket对应一个TCP请求，主要是配置一个TCP端口，EXEC表示执行一个命令。各个handler详细的定义不看了。
1type Handler struct { 2Exec *ExecAction json:&amp;#34;exec,omitempty&amp;#34; 3// HTTPGet specifies the http request to perform.
          
          
        
      </description>
    </item>
    
    <item>
      <title>kubernetes federation 工作机制之资源对象同步</title>
      <link>https://idouba.com/kubernetes-federation-sync-accross-cluster/</link>
      <pubDate>Tue, 15 Aug 2017 15:51:34 +0000</pubDate>
      
      <guid>https://idouba.com/kubernetes-federation-sync-accross-cluster/</guid>
      <description>
        
          
            1 前言 希望通过本文最简单的方式向熟悉k8s的人说明白其上的federation是干什么的，如何工作的。
关于federation，比较官方的说法是：集群联邦可以让租户/企业根据需要扩展或伸缩所需要的集群；可以让租户/企业在跨地区甚至跨地域的多个集群上部署、调度、监测管理应用。通过集群联邦，租户/企业可以在指定集群上部署应用，可以拉通私有云和公有云建立混合云(hybrid cloud)。
如在design-proposal 中描述的federation提供了cross-cluster scheduling, cross-cluster service discovery, cross-cluster migration, cross-cluster**ing and auditing, cross-cluster load balancing。
简单讲就一句话。能调用一个api，向操作一个k8s集群一样操作多个k8s集群。主要是拉通其下的k8s集群在上部署应用，发布服务，并且可以让其互相访问。
那么是怎么做到的呢？熟悉了kubernetes代码和主要的工作逻辑会发现非常简单。简单看下这部分代码会就会发现federation有如下特点：
复用了kubernets的机制 复用kubernetes的代码 扩展了kubernetes的对象（的定义和功能） 2. 架构 Federation 层的主要组件包括Federation-API Server，Controller-Manager和ETCD。根据Decoupled 的设计的目标和kubernetes 共用类库，而不是共用一个紧密的结构结构。在结构上解耦可以保证，Federation层故障，其下的每个个kubernetes集群不受影响。另外FederationAPI接口和kube-api接口完全兼容，用户可以像之前操作单个kubernetes集群一样操作联邦。
和Kubernetes类似，用户通过kubectl或者API调用向FederationAPI server的接口创建和维护各种对象，数据对象被持久化存储在Federation的ETCD中。联邦只是维护了规划，真正干活还是在其下的各个Cluster上（现实生活中其实也总是这样，你见过在联邦的川普干过什么正经事情）。真正关键的联邦如何通过一个统一的入口来接收请求，在各个cluster上调度。具体到（代码）功能就是联邦中指令如何在cluster上被落实执行。
联邦和其下k8s 集群的调用关系。调用细节下面描述。
3. 主要流程 关键就在于Federation的组件Controller-manager。和K8s其他的controller作用和工作机制类似，通过watch api-server 执行动作来维护集群状态。Federation的Controller-manager的处理逻辑和kubernetes略有不同，在于它一般都要连两个API server，watch 3个API 对象
对于每种Resource对象，都对应一个Controller，在Federation的Controller-manager启动时，启动这些Controller。
以ConfigMap为例，ConfigMapController启动后会watch如下三类接口：
Federation API server的Cluster接口federation/v1beta1/cluster； Federation API server的ConfigMap接口v1/configmap； Federation 管理的 N 个kubernetes cluster的Kube-API server 的ConfigMap的接口：v1/ configmap 当ConfigMapController watch到有户通过Federation API 创建（或者更新删除）一个ConfigMap，则会调用对应的每个cluster 的kube-apiserver创建（或者更新删除）对应的ConfigMap。
当ConfigMapController Watch到有新的Cluster加入进来时，调用新的Cluster的kube-api接口创建ConfigMap。Configmap、Secret等对象都是依照以上逻辑，从上向下Sync。
以ConfigMap 的controller为例，其他的都是遵从同一个模板流程。在NewConfigMapController场景controller时对watch 3个api。
Federation API server的ConfigMap接口v1/configmap；
          
          
        
      </description>
    </item>
    
    <item>
      <title>古城贼文化</title>
      <link>https://idouba.com/thief-culture-of-the-city/</link>
      <pubDate>Sat, 31 Dec 2016 10:56:34 +0000</pubDate>
      
      <guid>https://idouba.com/thief-culture-of-the-city/</guid>
      <description>
        
          
            吃完晚饭与淋波&amp;amp;宝强在园区周边溜达一圈，不知怎么的扯到了小偷和被盗这个悲催的话题。三个人各自讲了自己经历的这方面的糗事，居然洋洋洒洒的扯了咕咚3000步。发现无论是数量还是质量还是精彩指数都完爆那两位，而这些素材都得益于在家乡古城的那几年经历，然后晚上回来虽然很晚了还是把这些归纳整理了下。
记忆最深刻的是在解放路上图书大厦的那次遭遇。那会儿刚从东北的铁路工地上回到家乡的这个城市，好久找不到工作，最后在和平门里一个老民居的公司里跑业务送东西。无意中撞到附近解放路上图书大厦里，后来就每天上午在这里看半天书，下午接着去跑业务。到现在能从搞工地的工程跨界到另外一个工程，也是这阵子开的头。
和那位君子（后文中都君子，是简称，不是尊称。灵感于小时候小人书里有梁上君子的说法）的偶遇也就发生在书城下面的存包处。那天正在存包时突的感觉裤兜里有点动静，伸手一看，一个大镊子正夹手机玩外拽。有点惊慌，这可是当时唯一的家用电器啊，有点愤怒，想大喊小偷，说实话还有点害怕，对面那个肥头大耳留着板寸的君子哥面相有点凶，而且高我半头。总之，几秒钟里气氛有点奇怪。没想对面的板寸哥却却异常镇定，像个大哥哥一样的非常和蔼的的拍拍我的肩膀说“小兄弟，不好意思，搞错了，搞错了。。。”，然后就消失在大街上。留下一个原地里发愣的傻逼青年在想“搞错了”是啥意思，当时要是顺利被偷走了，就没搞错这茬了吧。后面好几年里多次坐车经过这里，往这边瞄下，总能看到那个平头哥在这里晃悠。
另外一次是虽然没有直接交互，但却非常有意思的来了个亲密接触。这次遭遇的不是一个君子哥，而是一群。故事发生在古城隔壁的渭城。和我一样，同事刘哥在东北工地完事后，也不去后面的青藏工地上班了，在家乡开了个卖小工艺品的小店。那年考完研入学前要转档案到NPU，就到修桥的原单位处机关里办手续，被拖了好几天。机关在刘哥店所在的渭城，那几天没事就在刘哥店里帮忙，有时还拿着老俞的红宝书准备GRE翻翻。每到晚上七八点吃完晚饭的时候，是店里生意最好的时候，几平米的小店里就挤满了人，主要都是些小姑娘。店里实在太挤了，有时候就蹲在店门口的台阶上打发时间，偶尔还好翻两下红宝书。一天傍晚正蹲着，不知什么时候身边整整齐齐的又蹲了仨哥们儿，一字儿排开蹲在我的隔壁抽烟，每人手里拿着一个硬纸板撑着的一套秋衣。刘哥之前早就说过这边有股这种神秘的势力，这帮人都是拿着一个秋衣盒子做拆挡，然后还另外一只手用镊子夹手机。于是就比较好奇的偷偷瞄一眼蹲在边上的这三位仁兄，碰巧三个人也整整齐齐的从上打量我，目光尤其落在我手上的这本书上。当时心里就乐了“人家一定当我是这片新来的吧，装备不太本地化啊”。难怪人家看我是那种同行冤家的那种感觉，《天下无贼》里葛优碰上刘德华啦。我也挑衅的瞪了他们一眼，这几个哥哥会了下眼神就离开了。
除了直接近距离直接交手这么两次，坐车骑车目击的就更多了。在南大街见过一直跟着行人走手伸到人家挎包里的；上班骑车路过含光路见过几个小朋友跟着前面的自行车跑，去伸手到骑车人斜跨的包里；在火车站还看到过一个一条腿的君子头目拄着拐杖指挥者兄弟们一起挤起点站的14路公交车的。
当然更近距离经历的是和宿舍的两个舍友三个男人第一次逛东大街，结果那个小名华华的东北三好小伙，手机上插着耳机正听着歌时被人拿走了。真为那个下手的君子哥的手法和胆识所折服。想这个动作是多么需要技巧和胆量，从裤兜里轻轻的掏出手机，快速拔掉耳机，然后离开现场或者伪装成路人。总之这一行还真是像葛优演的梨叔说的讲究技术含量的，也是业务素质要求很高的一个行业。
因为地理或者一些其他什么原因，在这个古城的这种行业尤其发达。在这个城市生活的人们估计很少有人能幸免不遭遇一点。除了上面热闹的几个场景，本人几轮交手下来的负向战利品是一个电脑台式机和4+辆自行车。在这里丢自行车电瓶车几乎是每个人都经历过的。印象最深刻的是最后一辆，不对，是最后两辆。这段经历在当时项目组里被广为流传：因为这个倒霉蛋连着两天丢了两辆。也就是今天丢了，重新买一辆，第二天早上又没了。汗！
如果说在古城方几十里圆范围内随处可以碰到这些君子们不算啥的话，在他乡遇故人的感觉就非常特别了。事情那发生在南方一个城市火车站。那是一个下午，正走着路，就听到前面两个人用熟悉的乡音在交流。虽然这么远的地方碰到老乡不至于激动上去搭腔，但是多听几声乡音的冲动还是有的。但是多听了几声，发现味道就不对了。一个用带着脏字的土话教育另外一个，“咋这么笨，那个背包在后面背着还下不了手”。妈呀，您们这是千里之外拓展业务来了，一种滑稽的自豪感油然而生。真是应了牛群给冯巩说的那句“tou出亚洲，tou向世界”。还真保不齐人家是这边办事处编制的。老家竞争太激烈了，南下开拓市场了。
当然，谁也不会抹黑自己的家乡。咱更是时时以家乡古城悠久的历史和文化而自豪。戏虐的写下这些文字也只是archive一个很有意思的主题记忆。没想到拎起来居然能扯这么多。
很多年了，也没有那种丢了东西的伤感，也没有当时的愤怒和对这个群体的仇恨。本来想取名“古城贼影”，觉得有几分惊悚和，又有点武侠的庸俗，联系下古城的特色，觉得“古城贼文化”似乎更契合这个城市的气质和闷骚的底蕴。只是不小心又揭了我们华华伤疤。那天回到宿舍大家都很愤怒，都忙着安慰你，没好意思问个问题“到底当时发生了什么，耳机在耳朵里插着手机也能被拿走了？”
          
          
        
      </description>
    </item>
    
    <item>
      <title>稀松！对不住杭州，对不住G20</title>
      <link>https://idouba.com/weekly-xisong-g20/</link>
      <pubDate>Sun, 04 Sep 2016 11:23:27 +0000</pubDate>
      
      <guid>https://idouba.com/weekly-xisong-g20/</guid>
      <description>
        
          
            注：这是第一篇用手机敲出来的文字，每天下午五点半开始在医院挂那瓶红色肺炎专用药的那四个小时。
熟悉的时间又来到这个最近开始熟悉的地方。这两天杭州g20，今天周末，临出门看了眼电视里习主席G20开幕布上的演讲。
右手上扎的针眼太有点多，今天换左手。腾出右手来闲着想记点东西。
这周过得和平时很不同。和很多生活在这个城市的人感觉一样，路上很空，街道人很少。连输液这边的护士都说这里现在的人都比平日少了好几成。与现实周围形成反差的是朋友圈里很热闹，名种晒图，大江南北。
对不住大家，对不住这个盛世的气氛。这周一个小人物过得异常的。。。稀松！
低烧了几乎整个八月，在月底了没扛住还是来到了这个地方。
有多稀松！
开始一天，单位里，翘班跑医院抽血拍片，幸亏和咱单位在一条街上，打车几分钟就过来了，抽血～回单位～拍片～回单位～取结果。稀松，折腾，狼狈。然后一个多礼拜里每天下班后要来这里挂水至少四个小时。
回家睡觉早早就被隔离在小房间，虽然窃喜过终于逃脱家务了，看到那娘俩忙乱的样子，心里也着急上火还有点惭愧。因为只能戴着口罩面对儿子，他妈问儿子：“是不是都不记得你爹长啥样了？”
当然最明显的稀和松是咱这点小身板。月底十天，减了5公斤。十天减十斤，对此良方有意者可留言咨询。
一只病手在另一只手还在滴滴答答的时候，手机敲这么多字进来，应该不是自己玩悲情，而是想记录下感受，只有在这种地方这种感受才会有稍微饱满那么一点。能想起拍片那下被机器把人送进去的那种紧张，那会儿就想娃和娃他妈。咱这个阶段确实很微妙，已经不是咱一个人的事儿了，倒不是咱自己怕啥。
所以立帖为证（除了欧洲杯那会儿赛前装逼的发个帖子预测下结果很少干这种事）：
等这阵过去后，每天一奶一水果，和娃他妈坚持过半个月。每周最少在楼下的塑胶跑道上跑三次，两次吧先尝尝，这么好的设备在家门口。搞俩二手自行车，骑车上班。每天步行15000+。
临座那个尿结石的小伙正电话给家人汇报自己的健身计划呢。这个时候都是这种心态吧，但大部分人应该是好了伤疤忘了疼。但不影响咱继续表态。
还有，吃饭排队不看手机，关注的每场比赛只看一篇报道，被一群没有足球底蕴只会炒作卖弄粗糙文字的小编骗流量和时间早就证明是一件极其傻逼的事情。回到家里尽量少想工作上的事情，三十多岁的老码农在几天里老纠结看到的那点代码长的难看总想着怎么重写下还是挺装逼的。
算不上死里逃生的大场面的人生感悟，天天坐在这个输液室里三四个小时还是难得大片空闲。记点东西下来总比意思贝斯和唐老师的扯淡有点意思。
顺便记几个三八事：那个过去几天一直值班的男护士 今天没来，他总是非常细心的摸胳膊上吊水打出的红疹问痒不痒，今天的女护士扎针有点疼，应该是新人，边上那个被她扎了好几次才扎上。医院里的G20绿色通道不是摆设，今天碰到了一群执勤的女警察通过G20专用通道把她们一个同伴用轮骑推进来。G20也是保障也真辛苦了一大群人！好长时间都是晴空万里的，偏偏今天G20开幕天有点灰蒙蒙的。朋友圈里有人说是奥黑的那几辆大排量的车闹的，我觉得有道理。
快滴完了，护士要来拔针了，好了好了。。。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Sort源码实现比较Go&amp;Java语言风格(3)</title>
      <link>https://idouba.com/compare-go-and-java-style-by-sort-implement-3/</link>
      <pubDate>Tue, 01 Dec 2015 15:20:55 +0000</pubDate>
      
      <guid>https://idouba.com/compare-go-and-java-style-by-sort-implement-3/</guid>
      <description>
        
          
            前面两部分分别描述了Go和java两种语言对sort的使用方式和源码实现。作为go初学者，最想做的是通过例子和源码来对新的语言有个理解。这部分就结合自己的理解整理下，可以看到，是非常主观。
4 语言语法比较
可以看到，两种语言的思路基本上是一样的，用户必须定义比较规则。在排序过程中都要考察集合长度，使用用户定义的比较规则，然后调整元素位置来达到排序的效果，对应go的interface要求的三个方法。但是还是有挺多不同。
首先从使用方式上看，go的规则（通过方法来体现）定义在集合上，并且定义了三个方法，分别获取集合的状况，元素比较的规则，元素位置操作的方法；而java的规则定义在元素上，用户只用一个元素比较的规则compareTo就够了。看起来java要求用户定义少，因为其封装的多，这也是其一贯的风格。对用户要似乎更友好一点。比较而言go更直接，简单。留给程序员能干预的更多一点。但还是觉得Len和Swap方法留给用户定义的意义不是很大，就像源码中自带的好几个例子，Len除了返回集合长度， Swap(i,j)除了{ a[i], a[j] = a[j], a[i] }，真想不好我们还能赋予它其他的使用方法。
从package的组织，能看到Go中更面向功能（或者说行为），功能更简单直接，而java更是面向对象组织的，封装更多。看到go sort的package下面的内容如图，而java一个Collections下面这么多功能方法，而看所在的的uitl包下上内容（只能截一屏还有一大半显示不全）。
看到了java的uitl包，下面除了Collections和Arrays这样几个工具类外更多的是List、Map、Set这样的数据结构定义（通过接口），以及常用的ArrayList，LinedList，HashMap，HashTable，TreeSet这样的实现。同样的这样键值对的容器，即有HashMap这样非同步的，又有Hashtable这样同步的，同步个容器上嫌Hashtable上加一把锁影响并发性能，后来大师Doug Lea，又发明了ConcurrentMap接口，以及现在已成经典的实现ConcurrentHashMap，在一个容器上分开加多把锁。
而比较而言，go的结构就简单很多，语言内置容器数组和map提供了几乎所有我们要的功能，并且其操作非常简单，在源码中费劲的想找其他基于其上的结构居然没有找见。Go的简的风格在此体现的真是明显，只提供基础的数据结构，和对这些结构的好用的操作。稍微用了下切片操作真的非常赞，非要对照下和java的ArrayList挺像，但是[:]这样操作起来真的很简单直接。另外看sort源码时发现两个语言在各自package中，和sort 相伴的也都是search之类的操作。
当然，看例子中还有源码中两个语言的语法差别那就更多了。尤其要称赞下go的几个非常酷的语法。如快排中找中间点的方法
1func doPivot(data Interface, lo, hi int) (midlo, midhi int){.. 2return lo + b - a, hi - (d - c) 3} 居然可以返回多个返回值，不用再像原来那样，要么一个返回值作为参数传进来，另外一个从return上取，要么就不得不构造一个结构来做组织多个返回值，费劲又别扭。真是解决程序员的真正问题。
还有，这个swap的方法实现，
1func (a ByAge) Swap(i, j int) { a[i], a[j] = a[j], a[i] } 这样一句就解决问题。而不是java这样费劲。
一下就把我大java比下去了。有没有想到很多年前，我们用c来数据结构的时候，老师反复强调，这时候要声明一个局部变量temp类做数据交换，非常神秘非常高级的知识点哈。在go这里居然真的可以直接交换。看上去有点像SQL这样的非过程语言了，又有点像我们描述代码功能的伪代码，只要告诉我你想干啥描述清楚，过程的能省就省了。非常非常简单，就这一小点，让咱这个新人产生了无数好感。
1private static void swap(Object[] x, int a, int b) { 2Object t = x[a]; 3x[a] = x[b]; 4x[b] = t; 5} 当然还有左大括号的使用，声明未使用的变量编译报错等新语法，看着蛮横，但却是简单。有一点点不习惯的是居然用方法名首字母的大小写来区分方法的访问权限，不像java中public protected private这样关键字来修饰，但说实话，写大写字母大头的方法还是有点瞅着怪怪的，老想给改成小写，虽然都是所谓的驼峰式的命名。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Sort源码实现比较Go&amp;Java语言风格(2)</title>
      <link>https://idouba.com/compare-go-and-java-style-by-sort-implement-2/</link>
      <pubDate>Tue, 01 Dec 2015 15:18:12 +0000</pubDate>
      
      <guid>https://idouba.com/compare-go-and-java-style-by-sort-implement-2/</guid>
      <description>
        
          
            接上篇博文，工作中用到了go排序的功能，作为go新手，在参照着例子，并读了go的sort.go部分涉及的源码，了解了go中排序的细节和实现算法，这些在上篇博文中有介绍。作为一个java ZHONGDU*2的用户，不由自主的想到了java中对应实现的样子，在这里也非常简要的贴出来，描述下java中排序的用法，和java源码中对应部分的实现，比较好奇java是和go一样，也用的时候快速排序吗？
3 Java 排序源码解析 主要代码Looks like this： 3.1 使用例子
1public class Person implements Comparable&amp;amp;lt;Person&amp;amp;gt; { 2private String name; 3private int age; 4 5 6@Override 7public int compareTo(Person o) { 8return this.age - o.age; 9} 10 11public static void main(String args[]) 12{ 13List&amp;amp;lt;Person&amp;amp;gt; persons = new ArrayList&amp;amp;lt;Person&amp;amp;gt;(); 14Collections.sort(persons); 15} 16} 和go中不同，必须要在class的第一行implements Comparable这个接口，然后在实现这个接口中定义的compareTo方法，告诉接口到底元素是怎么比较大小的。于是这也追踪下Collections.sort()方法中是如何使用这个compareTo规则来进行排序的。
3.2 源码解析 Collections是一个工具类，调用的是另外一个工具类Arrays中提供的静态方法。java中很少有class名用复数的，和Collection这也一个单数表达的是interface不同，这两个有悠久历史的类下面提供了很多static的工具方法。
1public static &amp;amp;lt;T extends Comparable&amp;amp;lt;? super T&amp;amp;gt;&amp;amp;gt; void sort(List&amp;amp;lt;T&amp;amp;gt; list) { 2Object[] a = list.toArray(); 3Arrays.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Sort源码实现比较Go&amp;Java语言风格(1)</title>
      <link>https://idouba.com/compare-go-and-java-style-by-sort-implement-1/</link>
      <pubDate>Tue, 01 Dec 2015 05:11:15 +0000</pubDate>
      
      <guid>https://idouba.com/compare-go-and-java-style-by-sort-implement-1/</guid>
      <description>
        
          
            1 前言 刚开始拥抱go，非常新鲜！才使用没多久，属于没有经验，有一点感受的那种。具体也说不了特别清楚，就是觉得：简单，直接，灵活，方便。作为一个 java 重度中毒（ZHANGDU*2）用户，过程中还是习惯对照着思考，至少在这个阶段。也好，发现对照着想，似乎更容易融会贯通。 对资深的go程序员来说，应该都是非常基础基本的问题，但也挡不住咱这个小白要发表下感想。
第一篇文章首先结合最近做一个小feature时用到go中元素排序的功能，顺便了解下两种语言中排序功能的使用方式，各自源码中对排序功能的实现。当然最主要的是在这个过程中，作为go初学者对语言的体会和理解。
2 Go排序源码解析 现在一般不太会自己写排序算法的实现了，就去搜go的package， 如愿找到了package sort?，和猜想的接口差不多，有一个func Sort(data Interface) 。只要把待排序的对象传到一个sort方法中就可以了。
只是对这个Interface?对象还有点疑惑，这个Interface是个啥东西呀？带着这个疑问，瞄见了package前面这个这个example（裁剪了部分非关键代码）。
2.1 go排序例子 1type Person struct { 2Name string 3Age int 4} 5// ByAge implements sort.Interface for []Person based on the Age field. 6type ByAge []Person 7func (a ByAge) Len() int { return len(a) } 8func (a ByAge) Swap(i, j int) { a[i], a[j] = a[j], a[i] } 9func (a ByAge) Less(i, j int) bool { return a[i].
          
          
        
      </description>
    </item>
    
    <item>
      <title>戏（细）说Executor框架线程池任务执行全过程（下）</title>
      <link>https://idouba.com/executor-framework-thread-pool-task-execution-part-02/</link>
      <pubDate>Fri, 05 Jun 2015 16:02:43 +0000</pubDate>
      
      <guid>https://idouba.com/executor-framework-thread-pool-task-execution-part-02/</guid>
      <description>
        
          
            归档下发表于infoq.com 2015年6月的两篇文章。本来是一篇文章，经过Infoq编辑Alice Ding建议，拆分为&amp;lt;上&amp;gt;和&amp;lt;下&amp;gt;两部分。谢谢Alice对文章的细心校对，帮我发下了其中的很多问题。添加下infoq要求的声明：本文为InfoQ中文站特供稿件，首发地址为：http://www.infoq.com/cn/articles/executor-framework-thread-pool-task-execution-part-02 。如需转载，请与InfoQ中文站联系。
内容综述 基于Executor接口中将任务提交和任务执行解耦的设计，ExecutorService和其各种功能强大的实现类提供了非常简便方式来提交任务并获取任务执行结果，封装了任务执行的全部过程。本文尝试通过对j.u.c.下该部分源码的解析以ThreadPoolExecutor为例来追踪任务提交、执行、获取执行结果的整个过程。为了避免陷入枯燥的源码解释，将该过程和过程中涉及的角色与我们工作中的场景和场景中涉及的角色进行映射，力图生动和深入浅出。
上一篇文章中通过引入的一个例子介绍了在Executor框架下，提交一个任务的过程，这个过程就像我们老大的老大要找个老大来执行一个任务那样简单。并通过剖析ExecutorService的一种经典实现ThreadPoolExecutor来分析接收任务的主要逻辑，发现ThreadPoolExecutor的工作思路和我们带项目的老大的工作思路完全一致。在本文中我们将继续后面的步骤，着重描述下任务执行的过程和任务执行结果获取的过程。会很容易发现，这个过程我们更加熟悉，因为正是每天我们工作的过程。除了ThreadPoolExecutor的内部类Worker外，对执行内容和执行结果封装的FutureTask的表现是这部分着重需要了解的。
为了连贯期间，内容的编号延续上篇。
2. 任务执行 其实应该说是任务被执行，任务是宾语。动宾结构：execute the task，执行任务，无论写成英文还是中文似乎都是这样。那么主语是是who呢？明显不是调用submit的那位（线程），那是哪位呢？上篇介绍ThreadPoolExecutor主要属性时提到其中有一个HashSet workers的集合，我们有说明这里存储的就是线程池的工作队列的集合，队列的对象是Worker类型的工作线程，是ThreadPoolExecutor的一个内部类，实现了Runnable接口：
1private final class Worker implements Runnable 8)看作业线程干什么当然是看它的run方法在干什么。如我们所料，作业线程就是在一直调用getTask方法获取任务，然后调用 runTask(task)方法执行任务。看到没有，是在while循环里面，就是不干完不罢休的意思！在加班干活的苦逼的朋友们，有没有遇见战友的亲切感觉？
1public void run() { 2 try { 3 Runnable task = firstTask; 4 //循环从线程池的任务队列获取任务 5 while (task != null || (task = getTask()) != null) { 6 //执行任务 7 runTask(task); 8 task = null; 9 } 10 } finally { 11 workerDone(this); 12 } 13 } 然后简单看下getTask和runTask(task)方法的内容。
getTask方法是ThreadPoolExecutor提供给其内部类Worker的的方法。作用就是一个，从任务队列中取任务，源源不断地输出任务。有没有想到老大手里拿的总是满满当当的project，也是源源不断的。 1Runnable getTask() { 2 for (;;) { 3 //从任务队列的头部取任务 4 r = workQueue.
          
          
        
      </description>
    </item>
    
    <item>
      <title>戏（细）说Executor框架线程池任务执行全过程（上）</title>
      <link>https://idouba.com/executor-framework-thread-pool-task-execution-part-01/</link>
      <pubDate>Fri, 05 Jun 2015 15:41:44 +0000</pubDate>
      
      <guid>https://idouba.com/executor-framework-thread-pool-task-execution-part-01/</guid>
      <description>
        
          
            归档下发表于infoq.com 2015年6月的两篇文章。本来是一篇文章，经过Infoq编辑Alice Ding建议，拆分为&amp;lt;上&amp;gt;和&amp;lt;下&amp;gt;两部分。谢谢Alice对文章的细心校对，帮我发下了其中的很多问题。添加下infoq要求的声明：本文为InfoQ中文站特供稿件，首发地址为：http://www.infoq.com/cn/articles/executor-framework-thread-pool-task-execution-part-01。如需转载，请与InfoQ中文站联系。
内容综述 基于Executor接口中将任务提交和任务执行解耦的设计，ExecutorService和其各种功能强大的实现类提供了非常简便方式来提交任务并获取任务执行结果，封装了任务执行的全部过程。本文尝试通过对j.u.c.下该部分源码的解析以ThreadPoolExecutor为例来追踪任务提交、执行、获取执行结果的整个过程。为了避免陷入枯燥的源码解释，将该过程和过程中涉及的角色与我们工作中的场景和场景中涉及的角色进行映射，力图生动和深入浅出。
一、前言 1.5后引入的Executor框架的最大优点是把任务的提交和执行解耦。要执行任务的人只需把Task描述清楚，然后提交即可。这个Task是怎么被执行的，被谁执行的，什么时候执行的，提交的人就不用关心了。具体点讲，提交一个Callable对象给ExecutorService（如最常用的线程池ThreadPoolExecutor），将得到一个Future对象，调用Future对象的get方法等待执行结果就好了。
经过这样的封装，对于使用者来说，提交任务获取结果的过程大大简化，调用者直接从提交的地方就可以等待获取执行结果。而封装最大的效果是使得真正执行任务的线程们变得不为人知。有没有觉得这个场景似曾相识？我们工作中当老大的老大（且称作LD^2）把一个任务交给我们老大（LD）的时候，到底是LD自己干，还是转过身来拉来一帮苦逼的兄弟加班加点干，那LD^2是不管的。LD^2只用把人描述清楚提及给LD，然后喝着咖啡等着收LD的report即可。等LD一封邮件非常优雅地报告LD^2report结果时，实际操作中是码农A和码农B干了一个月，还是码农ABCDE加班干了一个礼拜，大多是不用体现的。这套机制的优点就是LD^2找个合适的LD出来提交任务即可，接口友好有效，不用为具体怎么干费神费力。
二、 一个最简单的例子 看上去这个执行过程是这个样子。调用这段代码的是老大的老大了，他所需要干的所有事情就是找到一个合适的老大（如下面例子中laodaA就荣幸地被选中了），提交任务就好了。
1	// 一个有7个作业线程的线程池，老大的老大找到一个管7个人的小团队的老大 2 ExecutorService laodaA = Executors.newFixedThreadPool(7); 3	//提交作业给老大，作业内容封装在Callable中，约定好了输出的类型是String。 4	String outputs = laoda.submit( 5	new Callable&amp;amp;lt;String&amp;amp;gt;() { 6	public String call() throws Exception 7	{	8	return &amp;#34;I am a task, which submited by the so called laoda, and run by those anonymous workers&amp;#34;; 9	} 10	//提交后就等着结果吧，到底是手下7个作业中谁领到任务了，老大是不关心的。 11	}).get(); 12	System.out.println(outputs); 使用上非常简单，其实只有两行语句来完成所有功能：创建一个线程池，提交任务并等待获取执行结果。
例子中生成线程池采用了工具类Executors的静态方法。除了newFixedThreadPool可以生成固定大小的线程池，newCachedThreadPool可以生成一个无界、可以自动回收的线程池，newSingleThreadScheduledExecutor可以生成一个单个线程的线程池。newScheduledThreadPool还可以生成支持周期任务的线程池。一般用户场景下各种不同设置要求的线程池都可以这样生成，不用自己new一个线程池出来。
三、代码剖析 这套机制怎么用，上面两句语句就做到了，非常方便和友好。但是submit的task是怎么被执行的？是谁执行的？如何做到在调用的时候只有等待执行结束才能get到结果。这些都是1.5之后Executor接口下的线程池、Future接口下的可获得执行结果的的任务，配合AQS和原有的Runnable来做到的。在下文中我们尝试通过剖析每部分的代码来了解Task提交，Task执行，获取Task执行结果等几个主要步骤。为了控制篇幅，突出主要逻辑，文章中引用的代码片段去掉了异常捕获、非主要条件判断、非主要操作。文中只是以最常用的ThreadPoolExecutor线程池举例，其实ExecutorService接口下定义了很多功能丰富的其他类型，有各自的特点，但风格类似。本文重点是介绍任务提交的过程，过程中涉及的ExecutorService、ThreadPoolExecutor、AQS、Future、FutureTask等只会介绍该过程中用到的内容，不会对每个类都详细展开。
1、 任务提交 从类图上可以看到，接口ExecutorService继承自Executor。不像Executor中只定义了一个方法来执行任务，在ExecutorService中，正如其名字暗示的一样，定义了一个服务，定义了完整的线程池的行为，可以接受提交任务、执行任务、关闭服务。抽象类AbstractExecutorService类实现了ExecutorService接口，也实现了接口定义的默认行为。
          
          
        
      </description>
    </item>
    
    <item>
      <title>从Search Sort到Join</title>
      <link>https://idouba.com/learn_table_join_from_search_and_sort/</link>
      <pubDate>Thu, 07 May 2015 07:11:32 +0000</pubDate>
      
      <guid>https://idouba.com/learn_table_join_from_search_and_sort/</guid>
      <description>
        
          
            发表于《程序员》2015年4月B的一篇文章，在博客归档下。根据杂志社要求，在自己博客发表该文章亦须注明：本文为CSDN编译整理，未经允许不得转载，如需转载请联系market#csdn.net(#换成@)
想通过原理来说明一些技术白皮书上“什么时候应该使用什么”这个“应该”后面的原因。通过数据结构中经典的排序查找算法来推倒解释数据库中几种经典的表连接背后的算法原理，和原理决定的在各种数据库中不同的应用和限制。以简单的算法来讲出数据库系统中看着核心强大功能的本质的算法设计。较之白皮书中不同数据库的不同描述，尽量去除差异，通过原理来描述功能，做到深入浅出。
一、前言 Join的语义是把两张表的通过属性的关联条件值组合在一起，一般意义上数据库范式越高，表被拆分的越多，应用中要被Join的表可能会越多。在我们日常开发中几乎找不到不涉及Join的SQL语句，哪怕未显示包含Join这个关键字。在数据库系统执行时，都会选用一种明确最优的Join方式来执行。通过对Join原理的理解能帮助理解数据库的Join选择，进而更深刻的理解查询计划，理解同样的表结构数据行数变化、索引的变化为什么会影响数据库Join方式的选择，从而更针对性的做好性能优化。
如下图分别是oracle和mssql的执行计划，是涉及四个表的内连接。在查询计划中显示每一个步骤的表连接方式，从图中可以看到共有三个表连接操作(有意思的是，对于相似的数据集，两个数据库选择的连接方式不同)。
​ 图表 1 Oracle执行计划
Join原理在数据库厂商的文档中和经典的《数据库系统概念》中分别从应用和理论的角度上描述的足够详细。本文尝试从另外一个视角，通过数据结构中最基础的查找排序算法(Search&amp;amp;Sort)来类推和归纳最常用的三种Join方式的原理：嵌套循环连接(Nested Loop Join)、排序归并连接 (Sorted Merge Join)、 哈希连接(Hash Join)。进而了解三种方式之间的联系、演变以及原理决定的其应用上的细微差别。说明这几种表连接方式是数据库的技术，但和数据库索引等其他数据库技术一样，也是是典型的数据结构的延伸。
​ 图表 2 Mssql执行计划
二、实例数据 为了示意清楚，本文中用到的示例中的两个数据集比较简单。为如下两个表。
T_FC Fc_id Fc_name OfficialSite CityId 1 Inter www.inter.it 2 2 Barcelona http://www.fcbarcelona.com/ 8 3 Manchester united http://www.manutd.com 12 4 Liverpool http://www.liverpoolfc.com/ 11 5 Arsenal http://www.arsenal.com/ 36 6 ACM http://www.acmilan.com/ 2 7 Chelsea http://www.chelseafc.com/ 36 8 Manchester city http://www.mcfc.co.uk/ 12 ​ 图表 3 测试数据T_FC
T_City Fc_id*CityId* Fc_name Country Desc 36 Landon Britain ?
          
          
        
      </description>
    </item>
    
    <item>
      <title>跨界看项目那些事儿</title>
      <link>https://idouba.com/about-projects/</link>
      <pubDate>Fri, 10 Apr 2015 10:19:09 +0000</pubDate>
      
      <guid>https://idouba.com/about-projects/</guid>
      <description>
        
          
            年底了，该总结了。例行的招呼几个项目负责人对几个项目执行情况进行总结，项目上中实践比较成功的，记录细节，评估其他项目借鉴的可能性；项目上存在的问题，重点一起剖析下。由表面现象，到深层次的原因，力图通过讨论或争论都能有一致的认识，形成改进。但希望是理解了改进，而不是被要求改进。为了更生动的说明自己的观点，作为主持人的笔者准备了一个大家都比较熟悉的例子，公司附近的一个工地上项目。居然发现效果很好，新鲜，生动，容易被大家理解和引起共鸣。也是，在批判自己的过程中，肆无忌惮的给第三方挑毛病的确是很爽的一件事情！笔者在进入软件这个行当之前干的就是在[铁路工地上干活][1]的，经常不自觉的把这两种项目拿来比较。虽然看上去是有点跨界，其实也差别不大，项目那些事儿无非就如何把一组人组织起来有效的完成一件事情，达到规划的目标，做出一个有用的东西。因此，存在的问题和问题产生的原因也差不多。
例子中的这个项目是公司附近大家吃饭下班都会路过的一个工地，位于某某高新开发区区政府广场附近。项目一部分是图中B处一个过街地下通道，另外一个是不远C处的一个地铁站。从位置上就能看出其地位来，算是这个核心片区的重点项目。这么一个形象工程、利民项目被拿来作为一个反面案例，自认有点惶恐，有点忐忑。
先看B处这个过街地下通道，严格意义上讲不上一个新项目，因为原来就有，这次虽然项目规模很大，工程持续时间很长，给周边大家的生活带来了挺大影响，但其实工程的性质就是对原有项目的完善。即做了个2.0版本，只是对1.0版本的升级。
2.0版本的最主要的需求当然就是1.0版本存在的问题。那1.0版本最主要的问题是什么呢？就是没人用。在附近生活了四年了，几乎没有见过几个个人使用过。那么2.0版本的主要功能是什么呢？
地下通道的地面和墙壁都进行了粉刷和重新整修，尽管原来那个版本因为几乎未被使用，也没有什么损耗。即对1.0版本的UI进行了全面改善。 在西北、西南两个出口的台阶楼梯边上增加了两部手扶电梯，用户体验更好了。 在四个出口处都增加了玻璃的顶棚，下雨这种异常情况也处理的更得体了。 四个出口周边增加了绿化和石凳，整个产品风格一下就小清新了。 在西北出口处增加了保安，现场对产品进行技术支持和运维。 那2.0版本做的这么多看着很漂亮的功能是否解决了1.0的问题呢？本山大叔说过“看疗效！”。遗憾的是，在完工的近半年里，笔者没观察到什么变化，每天早晚上下班时间最大的人流还是选择从图示的A处，鲜有人会绕道这边来。非要说带来的变化，这个落寂的爱民工程倒是使得这个新区的政府广场看上去一下子高档了很多。
费了很大劲做了一个没人用的产品，这个项目难被评价为一个成功的项目。为什么花了这么大的代价，大半年时间，做出的产品用户却不买账呢？这是我们总结中让大家来分析的，因为我们的项目中也曾经发上过至少两次同样的事情，虽然规模和时间没有这么夸张。原因无一例外就是需求没有搞清楚，详细说分两种，一种是没有搞清楚产品的目标用户是谁，另外一种是没有搞清楚目标用户需要什么。
这个项目的目标用户是谁呢？在该项目往西一百多米的A处。马路南面和北面正对着是本区域最大的公交站，北面是该新区最繁华的商业步行街Star Road，是商场和写字楼聚集地。在1.0的时代，每天早晚上下班的时候总有那么一批人一大拨一大拨的从马路这边匆匆的冲到马路对面，先是穿过车流，然后来到中间绿化带，跨过环卫大妈们一遍一遍重铺过的草地，拉起的栏杆等各种障碍，再穿过另外一边的车流，艰难上岸，再冲进一个个大楼里。2.0后，可能随着新区的发展，人流量更多了，可怜的环卫大妈仍绞尽脑汁在和这些写字楼中的白领们斗争着，草坪踩了又种，种了又踩；隔离带由绳索升级为铁栏杆，再由铁栏杆升级为“过街走地道行路讲文明”的告示牌依然不能阻止上班族们在上下班时从写字楼和马路对面的公交站之间之间穿行。看上去项目的目标用户正是这些从城市的各个角落赶到这个公交站，为了掐着点赶着去写字楼打卡考勤，早点都要路上边走边吃，舍不得绕半个街区的时间来使用这个便民项目，冒着风险两次穿过车流，顶着巨大的道德压力跨过“过街走地道行路讲文明”的可怜的小白领们。他们是这个项目的目标用户，但却在项目立项的时候被无情的忽视了，不管是1.0版本和2.0版本。
再来看下提供的是不是用户期望的功能。我们来看看该项目中完成的五大feature，前四个无一例外都是用户体验上的改善。UI更干净了，操作方式做的更智能便利了，异常处理做的更完善了，整个产品风格都变得更清新了。那么用户的实际需求是不是对体验不满呢？是不愿意走楼梯而愿意选电梯，是因为下雨天漏雨而不愿意使用吗？是嫌这边没有花花草草才去马路中间的绿化带里寻找去了？显然都不是，观察到用户的基本需求仅仅是能便利、节省时间的安全的通行，比让穿过马路方便安全就行。如果这个基本需求不能满足，体验上的改善很难打动他们改变主意。
在一个个分析2.0的功能时候，有人提出了不同认识，那就是功能5中提到的不是技术支持，因为通过观察这些人从事的不是引导搀扶小老弱病残这样的支持类工作，也不是配合维护电梯通道等的维护类工作，而是把B处行人拉到楼梯口通行，这应该算是产品推广性质的工作吧。配合A处各种生物、物理、精神路障，B处活人路障是铁了心要用大禹前辈的治水方式来把人“堵”到通道中去。为了产品推广还真是蛮拼的！但直到今天只有B处零星的行人是被堵成功了，A处的真正目标用户一点变化也没有。
上面两个问题在我们软件项目中也是很容易碰到的，分析我们曾经出问题的两个项目底层的原因正是这样。项目立项的时候要先明确目标用户，搞清楚谁对这个产品有需求，这个产品做好了给谁用，这看似是个基本原则。但实践中经常这个最基本的原则却经常被忽视。很多营销上噱头的东西经常压倒了对目标用户的分析成为我们考虑的重点。没有明确目标用户，就开始做需求开发，然后功能分解后就开工干了。最终做出的东西找不到人用也就不足为奇了。例子中这个项目很可能在1.0立项的时候根本没有考虑目标用户，只是要建成区政府广场一角的一个形象工程。天安门广场有个过街通道，咱也要搞一个，这是标配。至于给谁用谁来用先不考虑了。
另外一个问题存在的就更普遍，有一个在开发的产品中正不同程度的还存在着。就是当产品推广不力的时候，我们最容易想到的就是用户体验上改善，什么图表不漂亮了，页面色彩不美观了，UI风格不舒服了这些，而忽视了用户对产品功能最基本的诉求。做出这样的决策也不难理解，第一用户体验的问题较之产品功能更容易被发现，更容易被提出；第二，从开发人员角度来说，用户体验的修改较之底层功能调整代价和影响要小；第三，虽然不好意思说，但实际中却经常发生，提出用户体验的要求对项目组外的领导们技术和业务能力要求最低，最容易发挥影响力来指点。没有冒犯权贵的意思，但真的不排除 例子中这个2.0改造项目是某某大领导亲自批示的，除了这个项目外，整个区政府周边整体UI在浩浩荡荡的也在被翻新。我们经常嘲笑那个地方刚栽好的花毁了种草，刚种好了的草铲了铺路这样瞎折腾。却忘了我们项目中花了多少力气反复干把一个网页横的变成竖的，蓝色的变成绿色的这样的事情。
挑了毛病，那能建议个方案吗？其实也不难想，用户怎么用，就怎么提供产品呗。A处 是主要人流的地方，那在A处建一个过街通道即可。在讨论中有人在此基础上提出了另外一个方案获得了大家的积极响应。
看图上最右边标识C处是一个地铁站，是新区最大的地铁枢纽，一号线已投入使用，规划有其他线路在这里换乘。从现阶段的使用情况来看，从地下上到地面上出站的主要人流方向也是涌向左边的区政府和这个商业街区。有没有可能把地铁的出站口延伸到A处，则那个期待的过街通道就被复用为地铁出口。本来距离也不是很远，而且在Start Road步行街地下一层原本就是另一个步行街。那事情就变得非常简单，把地铁站和Start Road 的地下一条街打通，孤立的两个项目就被整合为一个项目了。
整合的优点是很明显的，这种设计其实是很成熟并且在大量被使用。延伸的通道可以增加很多商业，作为Start Road地下商业街的一个延伸，不评估购买力，单人流量延伸的这段就比原来的那段要多很多。项目B这样的原来就存在的小过街通道转型为地铁出口，可以直接出站到区政府。当然在A处公交站和Start Road马路两侧的增加的地铁出口，不仅可以解决此处大量人流的过街需求，还可以方便的完成此处公交和地铁的换乘，可以一路引导地铁出站的人很方便的到达商业街。最重要的是可以更方便的让大量来商业街和区政府这两处的外来人找到地铁口。
说到找地铁口，笔者在地铁开通的这一年里，不下十次的在区政府和Start Road周边被问到“请问地铁站在哪儿”，开始也非常好奇，不是有地铁标识了吗？老头老太太就算了，怎么看着大学生模样的也不认识标识。于是乘地铁时留意了下周边的标识，被这些工程师同行的杰作给雷到了。150M这个较实际距离偏大暂不说，你把它放在出口处的边上就有点疑问了。就因为我手里有一个150M的牌子和一个100M的牌子，我就分别两个方向目测下距离装好就行。我们做这样设计的时候有没有想过，在商业街、区政府主要人流量的地方需要引导用户的地方没有标识，而用户一路询问都看见地铁口的广告牌了，发现此处你杵着一个标识告诉我需继续往前再走若干米米。感慨我们这些工程师们做项目时候，“用户观点”总是挂在嘴边，但实施的时候工程师的思维还是根深蒂固。
回到两个项目整合的问题，这种整合方案其实不难想到。就这这个例子，我们这种干另外类型项目的人根据自己的背景都能指手画脚，施工的同行们一定也应该是考虑过的。这种方案在地铁站规划的时候一定作为一种方案被提出过。和我们软件项目一样，两个功能模块在设计初期，根据规划，先分开设计和开发，留好扩展的接口，在适当的时机进行整合。即使设计初期没有考虑到，两个功能完全不相干，分开设计和开发。在产品演变过程中，表现出了相关性，整合的必要出现了，也会在适当的时机进行整合。但实际中我们都有这样的经验，大多数时候这不是一个设计问题，而是一个执行的问题。
一般经验来说，当基于整体需求的评估，要做整体考虑方案，则越早越好。但实际执行中，单个模块工期的压力，整合带来的实施上的不确定性和潜在的风险，甚至两个项目原本不同项目组开发引起人员上的困难，都使得下决心“整”变得困难。一般会被冠以“时机不成熟，待下个版本解决”这样一次一次的拖下去。这个时候，考验的不是大局观，设计能力，而是执行能力。考验的不是智慧，而是的是勇气、魄力。拖下去的好处是当时安生，但把麻烦留给了以后。经常在上一个版本多一点努力可以完成的，在下一个版本需要费很大气力。尤其是接口部分，要么是丑陋、别扭的适配，要么就是大量推翻重写。就像这个项目一样，如果在地铁站规划中能扩展考虑到延伸方案，则一下解决了多个问题，而像现在这样独立的来做，只解决了部分问题，待到下期整合时，结合处上上下下的台阶斜坡，通道处拐弯转交这样的接口硬伤是避免不了。
夹生饭再下锅蒸熟了品质当然不如一贯的好，这是结果上看，从过程上看，这样工程执行需要付出更多的代价。付出的人力和时间成本虽然在当前版本中不会考虑，在下个版本中也会以正当的理由冠冕堂皇的被贴上 重构这样高大上的标签，项目方案洋洋洒洒，项目计划宏伟庞大，但实际上从整个项目来看是做了无用功，其实就是出现了返工。就像例子中这个项目一样，在一两年后如果要打通的时候，我们又会看到和今年上半年这里一样忙碌的工作场景，重新圈起来的工地上轰隆隆的的电锤杂碎的每个石子儿都是两年前同伴们的辛苦劳作。工程上这样修了又拆，拆了又修的案例最近几年经常见诸报端，我们这些在屋子里面做项目的人经常对这些工地项目的粗鲁做法嗤之以鼻，好像那些做项目的人是野蛮人，骂其瞎折腾。但却忘了其实很多时候我们更野蛮，这样的例子在我们自己项目中其实也不也一直在发生，从上层被折腾的UI，到底层被折腾的实现，从某个独立模块的实现方式，到两个模块间的接口方案，当然大部分我们可以理直气壮的讲这是经过充分的评估和讨论的，是改进，不是瞎折腾，但是其中有多少是真折腾，过程中参与其中的人有时候恐怕自己也判别不清楚，在我们这种总结会议上大家跳出来争论后才可能形成结论。只是我们这种折腾进行的比较隐蔽罢了，但其带来的浪费真的不见得比看到的我们的同行们在工地上砸的几块地砖，扒掉些混凝土影响小，代价少。
洋洋洒洒会议持续了两个小时，扯了很多。平时不允许这样浪费时间来开会，既然讨论的这么热烈，感觉讨论通了，尽兴了当然就也就理解了，达到目的了。很快会议纪要邮件就发出来了。一级标题如下：
搞清目标用户 理解用户根本需求 UI好可增加颜值，但是功能好才是真的好。 做项目的要会想，但更多时候要会just do it。 项目规划和下棋一样，走着瞧，但尽量要多看几步，否则悔棋不易。 满满当当的项目规划和执行计划有时候是蒙老板的，有料没料要看是否厚道。 用户观点，挂在嘴边不够，应刻在脑门上，最好深一点，刻到骨头上。 当然每个抽象的观点下面都有详细展开，包括实际例子来说明，这个跨界的工程只是其中很小的一部分花絮素材，大部分还是说我们自己项目中实际的问题。比较散，有点乱，但都是有联系的。虽然纪要中是按照观点来展开的，但是如果按照涉及的项目来索引发现很少有一个项目仅存在一个问题。通过讨论，大家问题想通了想透了，最终改进也就有了前提了。做好明年的项目，争取少犯这些错误。
有心者在会议纪要上回复如下：“对例子中项目的诸多评价仅是一帮屌丝工程师学术讨论，个人观点，纯属YY，特此声明。”也作为本文的一个声明。
          
          
        
      </description>
    </item>
    
    <item>
      <title>源码剖析AQS在几个同步工具类中的使用</title>
      <link>https://idouba.com/sync-implementation-by-aqs/</link>
      <pubDate>Mon, 06 Apr 2015 15:30:31 +0000</pubDate>
      
      <guid>https://idouba.com/sync-implementation-by-aqs/</guid>
      <description>
        
          
            1. 前言 AQS(AbstractQueuedSynchronizer)是 java.util.concurrent的基础。J.U.C中宣传的封装良好的好用的同步工具类Semaphore、CountDownLatch、ReentrantLock、ReentrantReadWriteLock、FutureTask等虽然各自都有不同特征，但是简单看一下源码，每个类内部都包含一个如下的内部类定义：
abstract static class Sync extends AbstractQueuedSynchronizer 同时每个类内部都包含有这样一个属性，连属性名都一样！注释已经暗示了，该类的同步机制正是通过这个AQS的子类来完成的。不得不感叹：“每个强大的同步工具类，内心都有一把同样的锁！”
1/** All mechanics via AbstractQueuedSynchronizer subclass */ 2 private final Sync sync; 几种同步类提供的功能其实都是委托sync来完成。有些是部分功能，有些则是全部功能。 本文中就是想尝试比较分析下在几个同步工具类下面定义的AQS的子类如何来实现工具类要求的功能。当然包括两部分，一部分是这些工具类如何使用其Sync这种类型的同步器，也就是工具类向外提供的方法中，如何使用sync这个句柄；第二部分，就是工具类中自己定义的内部类Sync继承自AQS，那到底override了哪些方法来做到以父类AQS为基础，提供受委托工具类的功能要求。
关于第一部分，sync如何被其工具类使用，请允许我无耻的在一个文章中把一个类所有代码贴出来。
所幸方法很多，总的代码行不多，因为每个方法都是一个风格，就是换个名直接调用sync的对应方法。这是Semaphore中对sync的使用。是不是觉得写这个代码的作者比写这个文章的作者还要无耻？在其他几个工具类中，没有这么夸张，b但基本上也是这个风格，即以一个helper的方式向外面的封装类提供功能支持。所以第一个问题，在文章中说到这里，后面涉及到也只会简单描述。 主要是求索第二个问题，即每个工具类中自己定义的Sync到底是什么样子，有哪些不同的特征，其实也就是代码上看这些Sync类对父类AQS做了哪些修改。
2. AQS简介 要介绍子类的特征，父类总得大致介绍下。AQS的原理、设计等比较系统的东西，在这里就不想涉及了。可以参照《深入浅出 Java Concurrency》{#viewpost1_TitleUrl}系列的深入浅出 Java Concurrency (7): 锁机制 part 2 AQS{#viewpost1_TitleUrl}一节，谢谢这个系列，作者讲的确实非常的深入浅出！要想了解更多，可以参考Doug Lea大师的原著The java.util.concurrent Synchronizer Framework。最简单的办法其实就是的耐心把AbstractQueuedSynchronizer源码前面注释的javadoc完整的读一遍就可以了。笔者反正有这样的习惯。扎着脑袋看代码，看注释，然后自己看看是否能把一个package有个系统的视图，如果需要再看相关的参考文档来确认这个系统的视图。
看一个对象有什么本事，看他的构成是什么样，远比看他由哪些行为来的要深远。其实在OOP这种以class方式承载功能的编程中，即看一个类包含的属性，比他的方法也更容易理解对象的作用。看AQS类，暂时抛开outline视图下需要两屏才能看完的重要方法（还未展开ConditionObject和Node两个重要的内部类），只看该类包含的三个重要属性的定义就能看出端倪。
1private transient volatile Node head; 2 private transient volatile Node tail; 3 private volatile int state; 注释其实已经告诉我们了，Node类型的head和tail是一个FIFO的wait queue；一个int类型的状态位state。到这里也能猜到AQS对外呈现（或者说声明）的主要行为就是由一个状态位和一个有序队列来配合完成。 最简单的读一下主要的四个方法：
1//获取排他锁 2 public final void acquire(int arg) { 3 if (!
          
          
        
      </description>
    </item>
    
    <item>
      <title>实际抢票体验描述和分析“猎豹抢票跨站推荐功能有票刷不到”的疑似bug</title>
      <link>https://idouba.com/one-new-bug-report-of-liebao-huochepiao/</link>
      <pubDate>Tue, 23 Dec 2014 00:03:04 +0000</pubDate>
      
      <guid>https://idouba.com/one-new-bug-report-of-liebao-huochepiao/</guid>
      <description>
        
          
            前言 快过年了，又到了一年抢票时。今年douba和douma计划要带着doudou回姥姥家。昨天在家用抢票软件居然发现了一个bug，那就是在猎豹抢票中跨站推荐的车票几天里一直是没有，但是在12306手动尝试不同的跨站可以买到票，怀疑是猎豹在处理车次信息的时候对于变化的车次没有考虑到所致。在文中以实际操作尝试对这个bug做个比较详细的描述，并加上一点定位和分析，希望可以帮助这款神器的使用者和开发者提供些有用信息。按照douma的指示，今天上班来中午吃完饭不休息了，匆匆写下发表出来，供其他焦急的抢票战友们借鉴。不要只是懒懒的用工具刷，过于依赖神器，该动手时候要动动手才有可能抢到票。祝大家都能抢到心仪的车票。
正文 在本次战役中，除了360三代外，douma推荐了另外一款抢票神器猎豹。并用自己的成功经验诠释了下该神器的与其他工具的比较优势，那就是除了普通工具都有的自动刷票功能外，还提供了一款推荐功能。可以提示用户购买超出区间的余票，并很nice很体贴的提示出票价超了多少（类似信息检索技术中的查询扩展，都是为了提高查全率）。比如douma本来要买两张hangzhou’到yangzhou的软卧，没有买到，就通过该功能成功的抢了两张wenzhou发车的票，尽管多付了66%的票款（这个败家媳妇！），但是能抢到就是很了不起了！尤其据douma的消息，今年除了起点站很多过路的票都很难抢，因此这个跨站抢票的功能就显得尤为重要了。可是就是这个重要功能，在后续使用中被发现存在问题。
&amp;nbsp;
本来douma的两张超出常规票价66%的两张软卧（败家媳妇，说到这儿就得再骂一遍）可以把doudou和douba带到姥姥家。可是偏偏doudou的姥姥家住的就是这么偏僻，下了火车还要再倒一班3个半小时的短途火车。就是这两张车票让douma和douba抢了三四天都没有抢到。怎么想这个短途车也不至于这么热吧？打了电话12306，声音甜美的美眉客服也是说票都被秒杀啦。但是昨天在家里打开笔记本打算继续扫之前，douba无意做了个操作，却发现了个神奇的现象。
360和猎豹显示“本次车票已经卖完了”。12306其他地方也是显示yanzhou这个过站没有票。说明确实过站的票是没有了。
然后当然是尝试跨站的起点站购票了。douma天天都盯着猎豹的跨站推荐的地方。但是三天里推荐功能一直显示：“订票助手正在为您监控以下跨站票”。让douma望眼欲穿！看来douma比较拿手的始发站下手的策略也没有办法实施。难道这个票从“zaozhuangxi”就卖完啦？douma一个本地人非常不解，这个车以前好像都是没人坐吧，又慢又不好的，要不是带着doudou等大巴麻烦，我才不选这个破车呢。douma领着douba和doudou回家从yanzhou到juxian就这一班火车的哦。急死了！
就这样焦急了三天，天天上班douba和douma都是到座位开机后不忘把两个神器开起来，然后才忙别的，期间还会QQ、电话互通下进展。晚上下班回家，第一件事情也是把doudou先放一边，打开神器再忙别的。一天一天，douma都要放弃了，也就商量着直接打个车得了。
直到周末，准确说是周日昨天（周六都懒得搞了），吃完饭开机搞别的，居然被douba轻松手动的从12306的官方售票处买到了这趟车的车票。你能想到在douba支付宝支付的时候，douma和doudou那敬仰的神态吗？家长就应该是这个样子滴！截至到douba这会儿在写这个小文章，去12306上截个图，发现这趟车依然有票在买，从放票开始已经过去整整5天了，票还没卖完。也验证了douma的了解，这趟车确实没有那么热，问题就是为什么猎豹推荐的zaozhuangxi始发的车就是没有呢？结论当然是抢票神器出了问题。
为什么好几天了直到现在12306一直说有票，抢票神器却说没票呢？“应该是这个软件有bug”，CS工学硕士douma第一时间给出了结论，非常镇定，当时的神态都非常认真和专业，尽管不是在公司，而是穿着拖鞋在家里客厅。
douma说的对，但是分析是什么bug呢？就需要一定的业务知识的支持，这个就要请教在读研搞CS前曾经修过铁路的douba了。应该是一个非常tricky的问题，抢票神器可能没有考虑到。那就是车次的问题，细心的朋友应该看到，尽管douma没有选车次，但是神器推荐的是5037?，而douba在12306上买到的是5036。不是Yanzhou到juxian只有一趟车吗？怎么有两个车次?
随即douba打开12306的列车信息演示给douma看，原来这是一趟车。
我们都是有文化的人，但是看到车次这一列，想必大部分人都会“蛋疼了”。有这么折腾人的吗？一趟车走早上七点到八点半叫5036，走到九点就叫5037，再走到中午12点又叫5036，走了三个多小时后，到了下午三点多又叫5037。能不能不要这么任性啊！你都不怕列车广播车次的时候把刚上车的大叔大妈吓得认为坐错车了。反正douma看见这张表是晕菜了。
再听douba啰嗦下《铁路概论》课本上学到的规定的我国的火车车次的编排规则：
我国火车车次的编制和上行下行有关。铁路规定进京方向或是从支线到干线被称为上行，反之离京方向或是从干线到支线被称为下行。上行的列车车次为偶数（双数），下行的列车车次为奇数（单数）。在铁路调度中，调度员能一看车次就知道行驶方向,十分方便。因此就会出现有的车在运行途中会因为线路上下行的改变而改变车次。例如：1392/1393 到天津前是往北京方向，天津站后是远离北京方向。所以这趟火车有两个车次编号。
同样的5036/5037也是。看看这个地图中这趟车的行进线路上和我们伟大祖国的首都的相对位置变化就不难理解其为什么走俩小时变个车次，走俩小时又变一下了。
说到这里，douma大概理解了抢票神器中的问题。“猎豹应该就是只是按照5037进行查询了”。然后douma完整了描述了下bug：“当用户在神器中推荐功能其实是神器自己列举了若干个站到站查询，但是进行这步站到站查询的时候，带上了车次的的信息，不巧这个车次在后面站是存在的，在这个延伸的站是不存在的。即使用的车次不是这趟车的真正的唯一标识，而只是一个看上去的唯一标识。”
说白了用户查yanzhou到juxian的列车，神器先得到车次信息是5037，然后跨站推荐中把查询的起始和终点站向前后延伸，尝试做二次查询。如尝试起点站zaozhuangxi到juxian，但是这个时候却错误的带上了前面的车次信息。两个条件与在一起就查不出来了。在douma的例子中，按照5037去跨站搜，发现zaozhuangxi根本就没有该趟车，不是卖完了，是从来就没有过！以为这趟车在zaozhuangxi人家叫5036。所以就会出现例子中douba在12306上输入zaozhuangxi到juxiain一直有票，而猎豹刷票推荐了好几条，跨站的地方总是zaozhuangxi到juxian没票。
试想如果该趟车在铁路管理系统中的一条记录如下:
Id 车次 起点站 终点站 运行时间 里程 硬卧下 … 889 5036/5037 枣庄西 烟台 11.小时 710 170 890 K112 贵阳 上海南 25小时 1982 416 … 891 … 如果我们用889来标识这趟车是没有问题，如果我们用5036/5037这九个字符来标识这趟车也没有问题，但是如果我们只是用5036或5037这其中四个字符来标识这趟车就有问题了。这样的全称来表达一辆连续的列车是合适的，看好多网站上上车票信息的查询中对车次的标示用的就是用5036/5037这样的标示，而不是一个车次来标示来查。
铁路上是通过运行区间来管理的（以前一个抬杠的熟语是说“铁路警察是管长不管宽”说的就是这个道理），狭长的铁路必须分而治之，因而就有了北京段、济南段这样的分段，但是把运行（现在应该讲是飞驰）在其上的火车也分段命名仅仅是为了调度上好区分而搞单双号，douba一个从铁路系统上跑出来的程序员认为是有点过时了。
但是对于开发神器这个系统的开发者来说这个明显是用户现状了，我们开发者不大能指望客户做多大调整，更何况当你的客户是中国铁路这么一个有深远历史和影响的庞然大物了，所以只能是系统来适应。
前面报bug，包括bug描述以及截图都应该是完整、精确、并且尽可能做到可以reproduct的。但是后面的分析，是douba为了博得doudou和douma再次的敬仰当场发挥的，也就老婆孩子面前装13的，完全是基于自己的理解和分析。可能是跑偏了，只能算是对发现的bug做了个简单的外围的分析和定位吧。但求开发神器的伟大攻城狮们了解到，快点改好。douma还惦记着用神器买返程票呢。作为同行，代表doudou和douma对你们的工作表示由衷的感谢，这才是有用的东西，为我们这些屌丝大众造福的好产品。
另外对于大多数和douma一样的急着抢票的神器用户，douba想说，人家 12306官方都说了大家不要使用刷票软件，也就悠着点用吧，千万不要太迷信刷票软件，该动手时实施自己动手尝试下，说不定会有惊喜哦。
完。
          
          
        
      </description>
    </item>
    
    <item>
      <title>oracle分页技术性能比较</title>
      <link>https://idouba.com/performance-comparison-of-oracle-paging/</link>
      <pubDate>Tue, 14 Oct 2014 08:53:14 +0000</pubDate>
      
      <guid>https://idouba.com/performance-comparison-of-oracle-paging/</guid>
      <description>
        
          
            一、前言 在一个有30亿条数据的大表上分页，为了对方案进行性能测试，先忽略其他条件查询的影响，单看下分页部分的性能，顺便考察说明下oracle中rownum使用中一些比较tricky的地方。 实验条件： 表结构如下，内有2千万条实验数据。
二、实验 提供7种不同方式（其实是5种，二和四是一种、三和五是一种）方式的 。第一种只是为了demo一下假设的一种错误逻辑方式，第二种和第四种是一种逻辑正确，但是性能极差的方式。筛选下来看上去性能可行的方式是第五、第六、第七方式。 这里仅仅记录没中方式的执行结果和计划。
方式1 笨笨的想想。Oracle里面不是有个变量叫rownum，顾名思义，就是行号的意思，我要获取第十行到第二十行的数据，sql写起来很精练！比myslq的limit和mssql的top折腾看着还要优雅！
1select * from idouba.APP_CLUSTEREDAUDITLOG where rownum between 10 and 20 喔！十条记录执行了十分钟还么有结果，一定是哪儿有问题了，shut了重试。那就来个简单的：
1select * from idouba.APP_CLUSTEREDAUDITLOG where rownum =10 也没有记录，再尝试rownum=2都不会有记录。 分析rownum的原理就不难理解。rownum是查询到的结果集中的一个伪列，可以理解成在我们查询到的结果上加序号。按照这个逻辑，写rownum=1是能得到结果集的第一行。执行rownum=2时，先比较第一行，其rownum是1，则扔掉，考察下一行，rownum又是1，直到扫描完整个表，没有满足条件的结果集。 查询计划如下。
已用时间: 00: 04: 01.81
1执行计划 2---------------------------------------------------------- 3Plan hash value: 2858290634 4-------------------------------------------------------------------------------- 5| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | 6-------------------------------------------------------------------------------- 7| 0 | SELECT STATEMENT | | 20M| 146G| 102K (1)| 00:20:29 | 8| 1 | COUNT | | | | | | 9|* 2 | FILTER | | | | | | 10| 3 | INDEX FAST FULL SCAN| PK_ID | 20M| 146G| 102K (1)| 00:20:29 | 11-------------------------------------------------------------------------------- 12Predicate Information (identified by operation id): 13--------------------------------------------------- 14 2 - filter(ROWNUM=2) 15Note 16----- 17 - dynamic sampling used for this statement 18 19统计信息 20---------------------------------------------------------- 21 0 recursive calls 22 0 db block gets 23 461958 consistent gets 24 221499 physical reads 25 0 redo size 26 1956 bytes sent via SQL*Net to client 27 374 bytes received via SQL*Net from client 28 1 SQL*Net roundtrips to/from client 29 0 sorts (memory) 30 0 sorts (disk) 31 0 rows processed&amp;lt;/pre&amp;gt; 执行了4分钟，没有得到一条记录。尝试下面的方法。
          
          
        
      </description>
    </item>
    
    <item>
      <title>最简单例子图解JVM内存分配和回收</title>
      <link>https://idouba.com/a-simple-example-demo-jvm-allocation-and-gc/</link>
      <pubDate>Tue, 15 Jul 2014 05:49:37 +0000</pubDate>
      
      <guid>https://idouba.com/a-simple-example-demo-jvm-allocation-and-gc/</guid>
      <description>
        
          
            一、简介 JVM采用分代垃圾回收。在JVM的内存空间中把堆空间分为年老代和年轻代。将大量（据说是90%以上）创建了没多久就会消亡的对象存储在年轻代，而年老代中存放生命周期长久的实例对象。年轻代中又被分为Eden区(圣经中的伊甸园)、和两个Survivor区。新的对象分配是首先放在Eden区，Survivor区作为Eden区和Old区的缓冲，在Survivor区的对象经历若干次收集仍然存活的，就会被转移到年老区。
简单讲，就是生命期短的对象放在一起，将少数生命期长的对象放在一起，分别采用不同的回收策略。生命期短的对象回收频率比较高，生命期长的对象采用比较低回收频率，生命期短的对象被尝试回收几次发现还存活，则被移到另外一个地方去存起来。就像现在夏天了，勤劳的douma把doudou和douba常穿的衣服放在顺手的地方，把冬天的衣服打包放在柜子
另一个地方。虽然把doudou的小衣服类比成虚拟机里的对象有点不合适，大致意思应该就是这样。
本文中通过最简单的一个例子来demo下这个过程，代码很短，很简单，希望剖析的细一点，包括每一步操作后对象的分配和回收对内存堆产生的影响。设定上包括对堆中年轻代（年轻代中eden区和survivor区）、年老代大小的设定，以及设置阈值控制年轻代到年老代的晋升。
二、示例代码 下面是最简单的代码，通过代码的每一步的执行来剖析其中的规则。
1package com.idouba.jvm.demo; 2/** 3 * @author idouba 4 * Use shortest code demo jvm allocation, gc, and someting in gc. 5 * 6 * In details 7 * 1) sizing of young generation (eden space，survivor space),old generation. 8 * 2) allocation in eden space, gc in young generation, 9 * 3) working with survivor space and with old generation. 10 * 11 */ 12 public class SimpleJVMArg { 13 /** 14 * @param args 15 */ 16 public static void main(String[] args) 17 { 18 demo(); 19 } 20 21 /** 22 * VM arg：-verbose:gc -Xms200M -Xmx200M -Xmn100M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 -XX:+PrintTenuringDistribution 23 * */ 24 @SuppressWarnings(&amp;#34;unused&amp;#34;) 25 public static void demo() { 26 27 final int tenMB = 10* 1024 * 1024; 28 29 byte[] alloc1, alloc2, alloc3; 30 31 alloc1 = new byte[tenMB / 5]; 32 alloc2 = new byte[5 * tenMB]; 33 alloc3 = new byte[4 * tenMB]; 34 alloc3 = null; 35 alloc3 = new byte[6 * tenMB]; 36 } 37 } package com.
          
          
        
      </description>
    </item>
    
    <item>
      <title>B树在数据库索引中的应用剖析(发表版本)</title>
      <link>https://idouba.com/about-btrees-application-in-database-index-in-programmer/</link>
      <pubDate>Wed, 18 Jun 2014 09:27:23 +0000</pubDate>
      
      <guid>https://idouba.com/about-btrees-application-in-database-index-in-programmer/</guid>
      <description>
        
          
            最近一篇发表于《程序员》2014年6月刊上的文章。有点遗憾发现，有些部分被编辑修改过了，读起来有点怪怪的。最典型的是习惯于对某些比较经典的定义引用wikipedia或者原始白皮书中原始的E文，在文中发现都被硬译过了，表达的意思自己都有点看不懂了！
最终修改后提交的版本归档下：
引言 关于数据库索引，随便Google一个Oracle index，Mysql index总能得到“某某索引之n条经典建议”之类大量结果。笔者认为，较之直接借鉴，在搞清实际需求的基础上，对备选方案的原理尽可能深入全面的了解会更有利于我们的决策。因为某种方案或者技术呈现出某种优势（包括可能没有被介绍到但一定存在的限制），不是厂商的白皮书这样规定，是由实现机制决定的或者说本身的结构决定的。
本文重点介绍数据结构中经典的树（B树）结构在数据库索引中的经典应用，也会涉及到几种数据库中对此支持的细微不同，以期比较完整的描述实现原理。最终会发现这几种被不同数据库厂商冠以不同名字的东西原理上其实差不多，理论上其实是一个东西。文中只是略微空洞的介绍其实现原理，不涉及应用上具体的使用建议。
关键字：B树 数据库索引 索引组织表（Index-Organized Tables） 聚集索引 非聚集索引 Oracle Mysql Mssql
一、关于数据库索引 数据库索引在维基中的定义：A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and the use of more storage space to maintain the extra copy of data. Indexes are used to quickly locate data without having to search every row in a database table every time a database table is accessed.
          
          
        
      </description>
    </item>
    
    <item>
      <title>豆豆棒球记</title>
      <link>https://idouba.com/doudou-baseball/</link>
      <pubDate>Wed, 02 Apr 2014 14:00:11 +0000</pubDate>
      
      <guid>https://idouba.com/doudou-baseball/</guid>
      <description>
        
          
            豆豆小朋友真的长大了！会调皮了。
今天晚上，doudou指挥着和豆爸配合了一把棒球的游戏。doudou用的是乒乓球，douba用的是笤帚做球杆（棒球是不是叫球棒？）。工具都是 doudou提供和设计。总共进行了六轮，以姥姥指挥douba耍赖藏球结束比赛。哦，忘了补充一句，整个过程，doudou是在尿湿了裤子，外面裤子被 扒下来在膝盖位置，湿漉漉的秋裤贴着屁股的艰难环境下完成的。
这个家伙怎么这么没有出息呀，就喜欢笤帚，在家里面扫地可起劲了。
1for i in 0..6 2	doudou: 3	step1: 高高的撅着屁股往床下扔乒乓球 4	step2：结实的趴在地上瞄着床下确认球的位置 5	step3：扶着床沿爬起来，把笤帚递给douba 6	step4：用手和眼睛指挥douba把球捞出来 7	douba： 8	按照doudou的指示用笤帚击球 9	pingpang： 10	滚出来（滚蛋） 11	doudou： 12	step1：大笑，傻笑 13	step2：晃晃悠悠跑到乒乓跟前 14	step2：猫腰撅起屁股做棒球投球状。。。出手！ 完。
          
          
        
      </description>
    </item>
    
    <item>
      <title>从Count看Oracle执行计划的选择</title>
      <link>https://idouba.com/analysis-oracle-execute-plan-from-count/</link>
      <pubDate>Mon, 24 Mar 2014 12:53:50 +0000</pubDate>
      
      <guid>https://idouba.com/analysis-oracle-execute-plan-from-count/</guid>
      <description>
        
          
            一、 前言 在调查一个性能问题的时候，一个同事问道，为什么数据库有些时候这么不聪明，明明表上有索引，但是在执行一个简单的count的时候居然全表扫描了！难道不知道走索引更快么？
试图从最简单的count来重新了解oracle查询计划的选择，以及最终产生的结果。虽然有些结果会让人觉得有些意外，并且可能会鄙视，这个查询计划选择真的不够聪明。但稍微用心点的去了解，做的已经足够细致了。大多数情况下，根据我们输入的信息，来自输入的SQL、表结构、索引状况、统计信息，会得出一个比较优的计划。所以和前面一直试图讲到索引和join方式一样，所有这样的选择不是因为数据库厂商这样规定的，而是基于存储的数据的实际情况，就**应该(甚至说不得不)**这么去选择。
1-- Create table 2create table IDOUBA.APP_APPLICATIONAUDIT 3( 4 ID NUMBER, 5 UNIQUEID NUMBER, 6 POLICYID NUMBER, 7 IP VARCHAR2(200) not null, 8 IPNUM NUMBER not null, 9 MAC VARCHAR2(200), 10 USERVISIT VARCHAR2(100), 11 PHONE VARCHAR2(200), 12 GROUPNAME VARCHAR2(100), 13 PORT NUMBER, 14 APP_URL VARCHAR2(200), 15 TITLE VARCHAR2(200), 16 REQUESTS VARCHAR2(1000), 17 REQIDENTITYCARD VARCHAR2(1000), 18 REQKEY VARCHAR2(1000), 19 RESPONSEEKEY VARCHAR2(3000), 20 UPDATETIME DATE, 21 AUDITTYPE NUMBER, 22 TITLEID NUMBER, 23 SUBTITLEID NUMBER, 24 SERVERIP VARCHAR2(200), 25 DOMAINNAME VARCHAR2(200) 26) 27tablespace USERS 28 pctfree 10 29 initrans 1 30 maxtrans 255 31 storage 32 ( 33 initial 64K 34 minextents 1 35 maxextents unlimited 36 ); 37-- Create/Recreate indexes 38create index INDEX_UPDATETIME on IDOUBA.
          
          
        
      </description>
    </item>
    
    <item>
      <title>B树在数据库索引中的应用剖析（原稿）</title>
      <link>https://idouba.com/about-btrees-application-in-database-index/</link>
      <pubDate>Thu, 20 Mar 2014 08:18:48 +0000</pubDate>
      
      <guid>https://idouba.com/about-btrees-application-in-database-index/</guid>
      <description>
        
          
            引言 关于数据库索引，随便Google一个Oracle index，Mysql index总有大量的结果出来，其中不乏某某索引之n条经典建议。笔者认为，较之借鉴，在搞清楚了自己的需求的基础上，对备选方案的原理有个尽可能深入全面的了解会更有利于我们的选择和决策。因为某种方案或者技术呈现出某种优势（包括可能没有被介绍到但一定存在的限制），不是定义出来的，而是因为其实现机制决定的。就像LinkedList和ArrayList分别适用于什么应用不是Document里面定义的，是由其本身的结构决定的。数据库的索引也是一样，不是厂商的白皮书这样规定，而是其原理决定的。 本文只是重点介绍数据结构中经典的树（B树）结构在数据库索引中的经典应用，也会涉及到几种数据库中对此支持的细微不同，以期比较完整的描述实现原理。最终会发现这几种被不同数据库厂商冠以不同名字东西原理上其实差不多，理论上其实是一个东西。文中只是略微空洞的介绍其实现原理，不涉及应用上具体的使用建议。
#####关键字：B树 数据库索引? 索引组织表（Index-Organized Tables） 聚集索引 非聚集索引 Oracle ?Mysql Mssql
一、关于数据库索引 数据库索引在维基中的定义：A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and the use of more storage space to maintain the extra copy of data. Indexes are used to quickly locate data without having to search every row in a database table every time a database table is accessed.
          
          
        
      </description>
    </item>
    
    <item>
      <title>牵一只蜗牛去散步</title>
      <link>https://idouba.com/learn-and-walk-with-doudou/</link>
      <pubDate>Tue, 25 Feb 2014 06:47:43 +0000</pubDate>
      
      <guid>https://idouba.com/learn-and-walk-with-doudou/</guid>
      <description>
        
          
            douma发给我的一篇文章，让douba好好阅读。
上帝给我一个任务
叫我牵一只蜗牛去散步。
我不能走太快，
蜗牛已经尽力爬，为何每次总是那么一点点？
我催它，我唬它，我责备它，
蜗牛用抱歉的眼光看着我，
彷佛说：「人家已经尽力了嘛！」
我拉它，我扯它，甚至想踢它，
蜗牛受了伤，它流着汗，喘着气，往前爬…
真奇怪，为什么上帝叫我牵一只蜗牛去散步？
「上帝啊！为什么？」
天上一片安静。
「唉！也许上帝抓蜗牛去了！」
好吧！松手了！
反正上帝不管了，我还管什么？
让蜗牛往前爬，我在后面生闷气。
咦？我闻到花香，原来这边还有个花园，
我感到微风，原来夜里的微风这么温柔。
慢着！我听到鸟叫，我听到虫鸣。
我看到满天的星斗多亮丽！
咦？我以前怎么没有这般细腻的体会？
我忽然想起来了，莫非我错了？
是上帝叫一只蜗牛牵我去散步。分享：
教育孩子就像牵着一只蜗牛在散步。
和孩子一起走过他孩提时代和青春岁月，
虽然也有被气疯和失去耐心的时候，
然而，
孩子却在不知不觉中向我们展示了生命中最初最美好的一面。
孩子的眼光是率真的，
孩子的视角是独特的，
家长又何妨放慢脚步，
把自己主观的想法放在一边，
陪着孩子静静体味生活的滋味，
倾听孩子内心声音在俗世的回响，
给自己留一点时间，
从没完没了的生活里探出头，
这其中成就的，何止是孩子。
送给所有正处于忙碌中的爸爸妈妈
          
          
        
      </description>
    </item>
    
    <item>
      <title>Oracle索引原理精简总结</title>
      <link>https://idouba.com/oracle-index-brief/</link>
      <pubDate>Wed, 19 Feb 2014 13:48:09 +0000</pubDate>
      
      <guid>https://idouba.com/oracle-index-brief/</guid>
      <description>
        
          
            结合使用整理Oracle的索引，主要权威的来自于Oracle Database Concepts与Oracle Database Performance Tuning Guide
尝试用最少的字数介绍oracle的几种常用索引原理，主要是想简单分析其存储结构来说明其检索方式，和解释为什们某种索引使用与某种场合。（数据结构中最简单的ArrayList和LinkedList的使用场景）。阐述原因只有一个，就是因为其存储结构决定的。
B树索引(默认类型) 存储结构： B+树，不多描述。和其他几种关系数据库一样，就是根据索引列(一个或多个)来构造一个B+树来存储索引。非叶子节点两个区域：存储下级子节点的值的范围，和到对应子节点地址（典型B+树的结构），主要作用是导航；叶子节点存储索引的键值和行的ROWID。另外，索引的叶子节点间构成了一个双向链表。类似mysql的myisam引擎的辅助索引，也类似mssql的非聚集索引。
检索方式： 典型的平衡树的检索，栋根节点开始导航，选择下一个中间节点，直到找到对应的叶节点。需要说明的是，如果检索的所有列都在是索引中，则不用不用检索表，被称为Fast Full Index Scan；如果检索的列不都包含在索引中，则从树上找到索引列对应的key的叶子节点，需要根据其对应的ROWID，再次访问表，根据ROWID关联到其他属性。当Index Range Scan这种检索索引列的某个范围，则不用从根节点开始导航，直接选定开始的叶节点后，直接从叶节点的双向链表就可以完成。只需从根节点导航一次，找到开始的叶节点。
B+树是一个balance树，所有的叶子都在同一层上，无论根据索引查找表中的哪一条记录，where columnIndex=selectValue中间导航的层数都是相同的，所执行的I/O此次数都是相同的。
适合应用： 因为树状结构的特征，适合于适合与大量的增、删、改（OLTP），因为树状结构节点分裂、合并等很方便；适合高基数的列（唯一值多）的列索引，数据重叠太多，树状就快变为列表了，其查找功能就不能体现了。
反向键索引 存储结构： 反向键索引是一种能够将索引键‘反转’的B*Tree索引。通过把键‘反转’，本来连续的键值变得非常‘离散’。当大量数据并行插入的时候，把本来一个索引块上的连续键值分散到不同的索引块上，减少了索引块的争用。
检索方式： 和普通的B树索引没有差别。
使用场景 因为存储结构同B树索引，使用场合也同B树索引。但是如WHERE?COL1?&amp;gt;?888这样的Index Range Scan不能用反向索引，因为存储结构决定这种本来连续的已经反向的不连续了。
位图索引bitmap 存储结构 类似于java的BitSet采用最简单的方式存储某个值在哪些行出现，哪些行不出现。
如在列性别上建索引。
Value Row 1 Row 2 Row 3 Row 4 Row 5 Row 6 Row 7 M 1 1 1 1 F 1 1 1 在F行上Row12 row6 row7为1表示这些行的索引列取值是F。搜索一条记录的时候。
**检索方式 当发出where sex=’F’ 这样的SQL语句时，会去搜索F所在的索引条目，然后扫描该索引条目中的bitmap里所有的bit位。第一个bit位为 1，则说明第一条记录上的C1值为01，于是返回第一条记录所在的ROWID（根据该索引条目里记录的start ROWID加上行号得到该记录所在的ROWID）。然后根据ROWID关联其他属性。
适用应用： 适用于基数的列(low?cardinality)，因为存储的索引块会比较少。因此不适用创建复合索引，复合索引包含多列，它们的组合一般来说已经是高基数。
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】Mapreduce shuffle过程之Map输出过程</title>
      <link>https://idouba.com/hadoop_mapreduce_shuffle_map_output/</link>
      <pubDate>Wed, 05 Feb 2014 15:58:39 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_mapreduce_shuffle_map_output/</guid>
      <description>
        
          
            &lt;h3 id=&#34;一概要描述&#34;&gt;&lt;strong&gt;一、概要描述&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;shuffle是MapReduce的一个核心过程，因此没有在&lt;a href=&#34;../hadoop_job_submit_conclusion/&#34; title=&#34;【hadoop代码笔记】hadoop作业提交之汇总&#34;&gt;前面的MapReduce作业提交的过程&lt;/a&gt;中描述，而是单独拿出来比较详细的描述。 根据官方的流程图示如下：&lt;/p&gt;
&lt;p&gt;&lt;figure&gt;
  &lt;picture&gt;

    
      
        
        
        
        
        
        
    &lt;img
      loading=&#34;lazy&#34;
      decoding=&#34;async&#34;
      alt=&#34;&#34;
      
        class=&#34;image_figure image_internal image_unprocessed&#34;
        src=&#34;../wp-content/uploads/2014/02/shuffle.png&#34;
      
      
    /&gt;

    &lt;/picture&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本篇文章中只是想尝试从代码分析来说明在map端是如何将map的输出保存下来等待reduce来取&lt;/strong&gt;。 在执行每个map task时，无论map方法中执行什么逻辑，最终都是要把输出写到磁盘上。如果没有reduce阶段，则直接输出到hdfs上，如果有有reduce作业，则每个map方法的输出在写磁盘前线在内存中缓存。每个map task都有一个环状的内存缓冲区，存储着map的输出结果，默认100m，在每次当缓冲区快满的时候由一个独立的线程将缓冲区的数据以一个溢出文件的方式存放到磁盘，当整个map task结束后再对磁盘中这个map task产生的所有溢出文件做合并，被合并成已分区且已排序的输出文件。然后等待reduce task来拉数据。&lt;/p&gt;
&lt;h3 id=&#34;二-流程描述&#34;&gt;&lt;strong&gt;二、 流程描述&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;在child进程调用到runNewMapper时，会设置output为NewOutputCollector，来负责map的输出。&lt;/li&gt;
&lt;li&gt;在map方法的最后，不管经过什么逻辑的map处理，最终一般都要调用到TaskInputOutputContext的write方法，进而调用到设置的output即NewOutputCollector的write方法&lt;/li&gt;
&lt;li&gt;NewOutputCollector其实只是对MapOutputBuffer的一个封装，其write方法调用的是MapOutputBuffer的collect方法。&lt;/li&gt;
&lt;li&gt;MapOutputBuffer的collect方法中把key和value序列化后存储在一个环形缓存中，如果缓存满了则会调用startspill方法设置信号量，使得一个独立的线程SpillThread可以对缓存中的数据进行处理。&lt;/li&gt;
&lt;li&gt;SpillThread线程的run方法中调用sortAndSpill方法对缓存中的数据进行排序后写溢出文件。&lt;/li&gt;
&lt;li&gt;当map输出完成后，会调用output的close方法。&lt;/li&gt;
&lt;li&gt;在close方法中调用flush方法，对剩余的缓存进行处理，最后调用mergeParts方法，将前面过程的多个溢出文件合并为一个。&lt;/li&gt;
&lt;/ol&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】hadoop作业提交之汇总</title>
      <link>https://idouba.com/hadoop_job_submit_conclusion/</link>
      <pubDate>Sat, 01 Feb 2014 13:25:44 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_job_submit_conclusion/</guid>
      <description>
        
          
            一、概述 在本篇博文中，试图通过代码了解hadoop job执行的整个流程。即用户提交的mapreduce的jar文件、输入提交到hadoop的集群，并在集群中运行。重点在代码的角度描述整个流程，有些细节描述的并不那么详细。 汇总的代码流程图附件:hadoop_mapreduce_jobsubmit
二、主要流程 Jobclient通过RPC方式调用到jobtracker的submitJob方法提交作业，包括作业的jar、分片和作业描述。 JobTracker的submitJob方法吧job加入到内存队列中，由独立的线程取出每个JobInProgress的对象调用其initTasks方法，根据传入的作业分片创建对应数量的TaskInProgress类型的maptask和指定数量的Reduce task。 Tasktracker的offerService定时调用jobTracker的heartbeat发心跳给jobtracker报告状态并获取要执行的task。在haeartbeat中其实是通过配置的Taskscheduler来分配task的。 TaskTracker初始化时，会初始化并启动两个TaskLauncher类型的线程，mapLauncher，reduceLauncher。在TaskTracker从JobTracher获取到任务后，对应的会把任务添加到两个TaskLauncher的Queue中。TaskLauncher线程一直会定时检查TaskTracher上面有slot可以运行新的Task，则启动Task。 先把task运行需要的文件解压到本地，并创建根据Task类型（Map或者Reduce）创建一个TaskRunner线程，在TaskRunner中JvmManager调用JvmManagerForType、JvmRunner来启动一个java进程来执行Map或Reduce任务。在TaskRunner线程执行中，会构造一个_java –D Child address port tasked_这 样第一个java命令，单独启动一个java进程。在Child的main函数中通过TaskUmbilicalProtocol协议，从 TaskTracker获得需要执行的Task，并调用Task的run方法来执行。 对于MapTask的的run方法会通过java反射机制构造根据配置 Mapper，InputFormat，mapperContext等对象，然后调用构造的mapper的run方法执行mapper操作。 对于ReduceTask，由ReduceCopier对象的不同线程来获取map输出地址，拷贝输出，merge输出等操作。并利用反射机制根据配置的Reducer类构造一个Reducer实例和运行的上下文。并调用reducer的run方法来执行到用户定义的reduce操作。 三、详细流程 一）JobTracker等相关功能模块初始化(详细) 本来按照流程，第一步骤应该是Jobclient向Jobtracker发起作业提交的请求。为了更好的理解jobtracker是如何接收从jobclient提交的作业，有必要了解jobtracker相关的服务（和功能模块）的初始化过程。即Jobtracker作为一个服务启动起来，包括其附属的其他服务（和功能模块）。以接受jobclient的作业提交，初始化作业，向tasktracker分配任务。
JobTracker 的main函数中调用其startTracker方法。 在main函数中调用offerService，启动各个子服务项（大部分形态都是线程，有些是其他的初始化，如taskScheduler） ?在startTracker中调用其构造函数，在构造函数中对其中重要的属性根据配置进行初始化。(个人感觉再构造中设置scheduler，在statTracker调用构造的下一句有给Scheduler传JobTracker的引用，有点不自然)。Scheduler和JobTracker实例间，Scheduler包含JobTracker（实际上就是TaskTrackerManager）对象，通过TaskTrackerManager对象获取Hadoop集群的一些信息，如slot总数，QueueManager对象，这些都是调度器中调度算法输入的指标；JobTracker中要包含Scheduler对象，使用Scheduler来为TaskTracker分配task。 在offerService()中启动taskSchedulerexpireTrackersThread retireJobsThread expireLaunchingTaskThread completedJobsStoreThread interTrackerServer等几个线程来共同完成服务。同时调用TaskScheduler的start方法进行初始化。 在FairScheduler调度器的start方法中调用EagerTaskInitializationListenerr的start方法来初始化EagerTaskInitializationListener 在FairScheduler调度器的start方法中调用DefaultTaskSelector的start方法来初始化DefaultTaskSelector，因为该类实现的TaskSelector太简单，start方法里也没有做任何事情。 二）客户端作业提交(详细) Jobclient使用内置的JobSubmissionProtocol 实例jobSubmitClient 和JobTracker交互。向jobtracker请求一个新的作业ID，计算作业的输入分片，并将运行作业所需的资源（包括作业jar文件，配置文件和计算所得的输入分片）复制到jobtracker的文件系统中一个以作业ID命名的目录下。
通过调用JobTracker的getNewJobId()向jobtracker请求一个新的作业ID 获取job的jar、输入分片、作业描述等几个路径信息，以jobId命名。 其中getSystemDir()是返回jobtracker的系统目录，来放置job相关的文件。包括：mapreduce的jar文件submitJarFile、分片文件submitSplitFile、作业描述文件submitJobFile 检查作业的输出说明，如果没有指定输出目录或输出目录以及存在，则作业不提交。参照org.apache.hadoop.mapreduce.lib.output.FileOutputFormat的checkOutputSpecs方法。如果没有指定，则抛出InvalidJobConfException，文件已经存在则抛出FileAlreadyExistsException 计算作业的输入分片。通过InputFormat的getSplits(job)方法获得作业的split并将split序列化封装为RawSplit。返回split数目，也即代表有多个分片有多少个map。详细参见InputFormat获取Split的方法。 writeNewSplits 方法把输入分片写到JobTracker的job目录下。 将运行作业所需的资源（包括作业jar文件，配置文件和计算所得的输入分片）复制到jobtracker的文件系统中一个以作业ID命名的目录下。 使用句柄JobSubmissionProtocol通过RPC远程调用的submitJob()方法，向JobTracker提交作业。JobTracker作业放入到内存队列中，由作业调度器进行调度。并初始化作业实例。JobTracker创建job成功后会给JobClient传回一个JobStatus对象用于记录job的状态信息，如执行时间、Map和Reduce任务完成的比例等。JobClient会根据这个JobStatus对象创建一个 NetworkedJob的RunningJob对象，用于定时从JobTracker获得执行过程的统计数据来监控并打印到用户的控制台。 三）JobTracker接收作业(详细) JobTracker根据接收到的submitJob()方法调用后，把调用放入到内存队列中，由作业调度器进行调度。并初始化作业实例，从共享文件系统中获取JobClient计算好的输入分片信息，为每个分片创建一个map任务，根据mapred.reduce.task设置来创建指定数量的reduce任务。
JobClient通过RPC的方式向JobTracker提交作业； 调用JobTracker的submitJob方法。该方法是JobTracker向外提供的供调用的提交作业的接口。 submit方法中调用JobTracker的addJob方法。 在addJob方法中会把作业加入到集合中供调度，并会触发注册的JobInProgressListener的jobAdded事件。由上篇博文的jobtracker相关服务和功能的初始化的FairScheduler的start方法中看到，这里注册的是两个JobInProgressListener。分别是FairScheduler的内部类JobListener和EagerTaskInitializationListener。 FairScheduler的内部类JobListener响应jobAdded事件事件。只是为每个加入的Job创建一个用于FairScheduler调度用的JobInfo对象，并将其和job的对应的存储在Map&amp;lt;JobInProgress, JobInfo&amp;gt; infos集合中。 EagerTaskInitializationListener响应jobAdded事件事件。jobAdded 只是简单的把job加入到一个List类型的 jobInitQueue中。并不直接对其进行初始化，对其中的job的处理由另外线程JobInitManager来做。该线程，一直检查 jobInitQueue是否有作业，有则拿出来从线程池中取一个线程InitJob处理。关于作业的初始化过程专门在下一篇文章中介绍。 四）Job初始化(详细) Jobtracker响应作业提交请求，将提交的作业加入到一个列表中，由单独的线程来对列表中的job进行初始化。至此在Jobtracker一端对提交的job的准备工作就完毕了。
EagerTaskInitializationListener的 jobAdded方法把JobInProgress类型的job放到List类型的 jobInitQueue中，有个单独的线程会对新加入的每个job进行初始化，其初始化调用的方法就是JobInProgress的方法 initTasks。 在JobInProgress的方法initTasks方法中，会根据传入的作业分片创建对应数量的TaskInProgress类型的maptask，同时会创建TaskInProgress类型的指定数量的reducetask。 TaskInProgress的初始化是由其构造函数和构造函数中调用的init方法完成的。有构造MapTask的构造函数和构造ReduceTask的构造函数。分别是如下。其主要区别在于构造mapTask是要传入输入分片信息的RawSplit，而Reduce Task则不需要。两个构造函数都要调用init方法，进行其他的初始化。 五） TaskTracker获取Task，即jobtracker派发task（详细） tasktracker定时发心跳给jobtracker，并从jobtracker获取要执行的task。jobtracker在分配map任务会考虑数据本地化，对于reduce任务不用考虑本地化。
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】Hadoop作业提交之Child启动reduce任务</title>
      <link>https://idouba.com/hadoop_mapreduce_tasktracker_child_reduce/</link>
      <pubDate>Thu, 23 Jan 2014 14:54:46 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_mapreduce_tasktracker_child_reduce/</guid>
      <description>
        
          
            一、概要描述
在上篇博文描述了TaskTracker启动一个独立的java进程来执行Map任务。接上上篇文章，TaskRunner线程执行中，会构造一个java –D** Child address port tasked这样第一个java命令，单独启动一个java进程。在Child的main函数中通过TaskUmbilicalProtocol协议，从TaskTracker获得需要执行的Task，并调用Task的run方法来执行。在ReduceTask而Task的run方法会通过java反射机制构造Reducer，Reducer.Context，然后调用构造的Reducer的run方法执行reduce操作。不同于map任务，在执行reduce任务前，需要把map的输出从map运行的tasktracker上拷贝到reducer运行的tasktracker上。
Reduce需要集群上若干个map任务的输出作为其特殊的分区文件。每个map任务完成的时间可能不同，因此只要有一个任务完成，reduce任务就开始复制其输出。这就是reduce任务的**复制阶段。**其实是启动若干个MapOutputCopier线程来复制完所有map输出。在复制完成后reduce任务进入排序阶段。这个阶段将由LocalFSMerger或InMemFSMergeThread合并map输出，维持其顺序排序。【即对有序的几个文件进行归并，采用归并排序】在reduce阶段，对已排序输出的每个键都要调用reduce函数，此阶段的输出直接写到文件系统，一般为HDFS上。（如果采用HDFS，由于tasktracker节点也是DataNoe，所以第一个块副本将被写到本地磁盘。 即数据本地化）
Map 任务完成后，会通知其父tasktracker状态更新，然后tasktracker通知jobtracker。通过心跳机制来完成。因此jobtracker知道map输出和tasktracker之间的映射关系。Reducer的一个getMapCompletionEvents线程定期询问jobtracker以便获取map输出位置。
二、 流程描述
在ReduceTak中 构建ReduceCopier对象，调用其fetchOutputs方法。
在ReduceCopier的fetchOutputs方法中分别构造几个独立的线程。相互配合，并分别独立的完成任务。
2.1 GetMapEventsThread线程通过RPC询问TaskTracker，对每个完成的Event，获取maptask所在的服务器地址，即MapTask输出的地址，构造URL，加入到mapLocations，供copier线程获取。
2.2构造并启动若干个MapOutputCopier线程，通过http协议，把map的输出从远端服务器拷贝的本地，如果可以放在内存中，则存储在内存中调用，否则保存在本地文件。
2.3LocalFSMerger对磁盘上的map 输出进行归并。
2.4nMemFSMergeThread对内存中的map输出进行归并。
3.根据拷贝到的map输出构造一个raw keyvalue的迭代器，作为reduce的输入。
调用runNewReducer方法中根据配置的Reducer类构造一个Reducer实例和运行的上下文。并调用reducer的run方法来执行到用户定义的reduce操作。。
在Reducer的run方法中从上下文中取出一个key和该key对应的Value集合（Iterable类型），调用reducer的reduce方法进行处理。
Recuer的reduce方法是用户定义的处理数据的方法，也是用户唯一需要定义的方法。
三、代码详细
1. Child的main方法每个task进程都会被在单独的进程中执行，这个方法就是这些进程的入口方法。Reduce和map一样都是由该main函数调用。所以此处不做描述，详细见上节Child启动map任务。
**2. ReduceTask的run方法。**在Child子进程中被调用，执行用户定义的Reduce操作。前面代码逻辑和MapTask类似。通过TaskUmbilicalProtocol向tasktracker上报执行进度。开启线程向TaskTracker上报进度，根据task的不同动作要求执行不同的方法，如jobClean，jobsetup，taskCleanup。对于部分的了解可以产看taskTracker获取Task文章中的 JobTracker的 heartbeat方法处的详细解释。不同于map任务，在执行reduce任务前，需要把map的输出从map运行的tasktracker上拷贝到reducer运行的tasktracker上。
1@SuppressWarnings(&amp;#34;unchecked&amp;#34;) 2 public void run(JobConf job, final TaskUmbilicalProtocol umbilical) 3 throws IOException, InterruptedException, ClassNotFoundException { 4 job.setBoolean(&amp;#34;mapred.skip.on&amp;#34;, isSkipping()); 5 6 if (isMapOrReduce()) { 7 copyPhase = getProgress().addPhase(&amp;#34;copy&amp;#34;); 8 sortPhase = getProgress().addPhase(&amp;#34;sort&amp;#34;); 9 reducePhase = getProgress().addPhase(&amp;#34;reduce&amp;#34;); 10 } 11 // start thread that will handle communication with parent 12 TaskReporter reporter = new TaskReporter(getProgress(), umbilical); 13 reporter.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】hadoop作业提交之Child启动map任务</title>
      <link>https://idouba.com/hadoop_mapreduce_tasktracker_child_map/</link>
      <pubDate>Wed, 22 Jan 2014 07:00:53 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_mapreduce_tasktracker_child_map/</guid>
      <description>
        
          
            一、概要描述
在上篇博文描述了TaskTracker启动一个独立的java进程来执行Map或Reduce任务。在本篇和下篇博文中我们会关注启动的那个入口是org.apache.hadoop.mapred.Child的这个Java进程是如何执行用户定义的map或Reduce任务的。
接上篇文章，TaskRunner线程执行中，会构造一个_java –D** Child address port tasked_这 样第一个java命令，单独启动一个java进程。在Child的main函数中通过TaskUmbilicalProtocol协议，从 TaskTracker获得需要执行的Task，并调用Task的run方法来执行，而Task的run方法会通过java反射机制构造 Mapper，InputFormat，mapperContext，然后调用构造的mapper的run方法执行mapper操作。
二、 流程描述
Child类根据前面输入的三个参数，即tasktracher的地址、端口、taskid。通过TaskUmbilicalProtocol协议，从TaskTracker获得需要执行的Task，在Child的main函数中调用执行。 在Chilld中，执行Task的run方法。Task 的run方法。是真正执行用户定义的map或者reduce任务的入口，通过TaskUmbilicalProtocol向tasktracker上报执行进度。 在MapTask的run中执行runMapper方法来调用mapper定义的方法。 在runNewMapper方法中构造mapper实例和mapper执行的配置信息。并执行mapper.run方法来调用到用户定义的mapper的方法。 mapper的run方法中，从输入数据中逐一取出调用map方法来处理每一条数据 mapper的map方法是真正用户定义的处理数据的类。也是用户唯一需要定义的方法。 三、代码详细
Child的main方法每个task进程都会被在单独的进程中执行，这个方法就是这些进程的入口方法。观察下载在这个方法中做了哪些事情？ 1)从传入的参数中获得tasktracker的地址、从传入的参数中获得tasktracker的地址
根据获取的taskTracker的地址和端口通过RPC方式和tasktracker通信，umbilical是作为tasktracker的代理来执行操作。
根据JvmId从taskTracker查询获取到JvmTask
执行任务
1public static void main(String[] args) throws Throwable { 2 LOG.debug(&amp;#34;Child starting&amp;#34;); 3JobConf defaultConf = new JobConf(); 4 5//从传入的参数中获得taskTracker的地址 6String host = args[0]; 7//从传入的参数中获得taskTracker的响应请求的端口。 8 int port = Integer.parseInt(args[1]); 9 InetSocketAddress address = new InetSocketAddress(host, port); 10 final TaskAttemptID firstTaskid = TaskAttemptID.forName(args[2]); 11 final int SLEEP_LONGER_COUNT = 5; 12 int jvmIdInt = Integer.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】hadoop作业提交之TaskTracker 启动task</title>
      <link>https://idouba.com/hadoop_mapreduce_tasktracker_launch_task/</link>
      <pubDate>Tue, 21 Jan 2014 13:58:12 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_mapreduce_tasktracker_launch_task/</guid>
      <description>
        
          
            一、概要描述
在上篇博文描 述了TaskTracker从Jobtracker如何从JobTracker获取到要执行的Task。在从JobTracker获取到 LaunchTaskAction后，执行addToTaskQueue方法来把要执行的Task加入到queue。在本篇博文中，我们来关注下该方法 后，TaskTracker怎么来处理这些Task。
实际上，TaskTracker初始化时，会初始化并启动两个TaskLauncher类型的线程，mapLauncher，reduceLauncher。在TaskTracker从JobTracher获取到任务后，对应的会把任务添加到两个 TaskLauncher的Queue中，其实是TaskLauncher维护的一个列表List tasksToLaunch。
TaskLauncher线程一直会定时检查TaskTracher上面有slot开业运行新的Task，则启动 Task。在这个过程中，先把task运行需要的文件解压到本地，并创建根据Task类型（Map或者Reduce）创建一个TaskRunner线程， 在TaskRunner中JvmManager调用JvmManagerForType、JvmRunner来启动一个java进程来执行Map或Reduce任务。
本文只是介绍到启动一个java进程，至于是什么样的java进程，对于maptask和reducetask分别是怎么执行的，在后面的child启动maptask，和child启动reducetask 会比较详细的介绍。
二、 流程描述
tasktracker的offerService方法获取到要执行的task后调用addToTaskQueue方法，其实是调用taskrunner的addToTaskQueue方法 TaskLauncher内部维护了一个List tasksToLaunch，只是把task加入到该 taskLauncher是一个线程，在其run方法中从tasksToLaunch集合中取出task来执行，调用Tasktracker的startNewTask方法启动task。 startNewtask方法中调用localizeJob方法把job相关的配置信息和要运行的jar拷贝到tasktracker本地，然后调用taskInProgress的launchTask方法来启动task。 TaskInProgress的launchTask方法先调用localizeTask(task把task相关的配置信息获取到本地。然后创建一个TaskRunner线程来启动task。 在TaskRunner的run方法中构建一个java命令的执行的条件，包括引用类，执行目录等，入口类是Child。然后调用JvmManager 的launchJvm方法来调用。 JvmManager 进而调用 JvmManagerForType的reapJvm，和spawnNewJvm 方法，发起调用. 在JvmManagerForType的spawnNewJvm 方法中创建了一个JvmRunner线程类执行调用. JvmRunner线程的run反复调用runChild方法来执行 一个命令行的调用。 三、代码详细
TaskTracker的 addToTaskQueue方法。 接上文的最后一个方法的在heartbeat中把根据jobtracker的指令把需要launch的task调用addToTaskQueue方法加入task queue。
1//根据task的类型不同加入到不同的launcher中。 2private void addToTaskQueue(LaunchTaskAction action) { 3if (action.getTask().isMapTask()) { 4mapLauncher.addToTaskQueue(action); 5}else { 6reduceLauncher.addToTaskQueue(action); 7} 8} TaskLauncher 的addToTaskQueue方法，即把要launch的task加入到TaskLauncher内维护的一个列表List tasksToLaunch;中。 1public void addToTaskQueue(LaunchTaskAction action) { 2 synchronized (tasksToLaunch) { 3 TaskInProgress tip = registerTask(action, this); 4 tasksToLaunch.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】hadoop作业提交之Job初始化</title>
      <link>https://idouba.com/hadoop_mapreduce_job_init/</link>
      <pubDate>Sun, 19 Jan 2014 14:54:46 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_mapreduce_job_init/</guid>
      <description>
        
          
            一、概要描述
在上一篇博文中主要描述了JobTracker和其几个服务（或功能）模块的接收到提交的job后的一些处理。其中很重要的一部分就作业的初始化。因为代码片段图的表达问题，本应该在上篇描述的内容，分开在本篇描述。
二、 流程描述
代码也接上文的最后一个方法EagerTaskInitializationListener的 jobAdded方法把JobInProgress类型的job放到List类型的 jobInitQueue中，有个单独的线程会对新加入的每个job进行初始化，其初始化调用的方法就是JobInProgress的方法 initTasks。
在JobInProgress的方法initTasks方法中，会根据传入的作业分片创建对应数量的TaskInProgress类型的maptask，同时会创建TaskInProgress类型的指定数量的reducetask。
TaskInProgress的初始化是由其构造函数和构造函数中调用的init方法完成的。
三、代码详细
1. EagerTaskInitializationListener的内部InitJob线程的run方法。调用JobInProgress的初始化方法。
1static class InitJob implements Runnable { 2 private JobInProgress job; 3 public InitJob(JobInProgress job) { 4 this.job = job; 5 } 6public void run() 7 { 8 job.initTasks(); 9 } 10 } 2. JobInProgress 类的initTasks方法。
主要流程：
1）根据读入的split确定map的数量，每个split一个map
2）如果Task数大于该jobTracker支持的最大task数，则抛出异常。
3）根据split的数量初始化maps
4）如果没有split，表示job已经成功结束。
根据指定的reduce数量numReduceTasks创建reduce task 6）计算并且最少剩下多少map task ，才可以开始Reduce task。默认是总的map task的5%，即大部分Map task完成后，就可以开始reduce task了。
//1） 根据读入的split确定map的数量，每个split一个map
1String jobFile = profile.getJobFile(); 2 Path sysDir = new Path(this.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】hadoop作业提交之TaskTracker获取Task</title>
      <link>https://idouba.com/hadoop_mapreduce_tasktracker_retrieve_task/</link>
      <pubDate>Sat, 18 Jan 2014 14:50:50 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_mapreduce_tasktracker_retrieve_task/</guid>
      <description>
        
          
            一、概要描述
在上上一篇博文和上一篇博文中 分别描述了jobTracker和其服务（功能）模块初始化完成后，接收JobClient提交的作业，并进行初始化。本文着重描 述，JobTracker如何选择作业的Task分发到TaskTracker。本文只是描述一个TaskTracker如何从JobTracker获取 Task任务。Task任务在TaskTracker如何执行将在后面博文中描述。
二、 流程描述
TaskTracker在run中调用offerService()方法一直死循环的去连接Jobtracker，先Jobtracker发送心跳，发送自身状态，并从Jobtracker获取任务指令来执行。 在JobTracker的heartbeat方法中，对于来自每一个TaskTracker的心跳请求，根据一定的作业调度策略调用assignTasks方法选择一定Task Scheduler调用对应的LoadManager的canAssignMap方法和canAssignReduce方法以决定是否可以给 tasktracker分配任务。默认的是CapBasedLoad，全局平均分配。即根据全局的任务槽数，全局的map任务数的比值得到一个load系 数，该系数乘以待分配任务的tasktracker的最大map任务数，即是该tasktracker能分配得到的任务数。如果太tracker当前运行 的任务数小于可运行的任务数，则任务可以分配新作业给他。（图中缺失了LoadManager的表达，也画不下了，就不加了。在代码详细分析中有） Scheduler的调用TaskSelector的obtainNewMapTask或者obtainNewReduceTask选择Task。 在DefaultTaskSelector中选择Task的方法其实只是封装了JobInProgress的对应方法。 JobTracker根据得到的Task构造TaskTrackerAction设置到到HeartbeatResponse返回给TaskTracker。 TaskTracker中将来自JobTracker的任务加入到TaskQueue中等待执行。 三、代码详细
1. TaskTracker的入口函数main
1JobConf conf=new JobConf(); 2 // enable the server to track time spent waiting on locks 3 ReflectionUtils.setContentionTracing 4 (conf.getBoolean(&amp;#34;tasktracker.contention.tracking&amp;#34;, false)); 5 new TaskTracker(conf).run(); TaskTracker的构造函数 1maxCurrentMapTasks = conf.getInt( 2 &amp;#34;mapred.tasktracker.map.tasks.maximum&amp;#34;, 2); 3maxCurrentReduceTasks = conf.getInt( 4 &amp;#34;mapred.tasktracker.reduce.tasks.maximum&amp;#34;, 2); 5this.jobTrackAddr = JobTracker.getAddress(conf); 6 7//启动httpserver 展示tasktracker状态。 8this.server = new HttpServer(&amp;#34;task&amp;#34;, httpBindAddress, httpPort, 9 httpPort == 0, conf); 10server.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记hadoop作业提交之JobTracker等相关功能模块初始化</title>
      <link>https://idouba.com/hadoop_job_submit_service_init/</link>
      <pubDate>Fri, 17 Jan 2014 14:36:20 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_job_submit_service_init/</guid>
      <description>
        
          
            一、概要描述
本文重点描述在JobTracker一端接收作业、调度作业等几个模块的初始化工作。想过模块的介绍会在其他文章中比较详细的描述。受理作业提交在下一篇文章中会进行描述。
为了表达的尽可能清晰一点只是摘录出影响逻辑流转的主要代码。重点强调直接的协作调用，每个内部完成的逻辑（一直可以更细的说明、有些细节可能自己也理解并不深刻:-(）在后续会描述。
主要包括JobTracker、TaskScheduler（此处以FairScheduler为例）、JobInProgressListener（以用的较多的EagerTaskInitializationListener为例）、TaskSelector(以最简单的DefaultTaskSelector为例)等。
二、 流程描述
JobTracker 的main函数中调用其startTracker方法。 在mai函数中调用offerService，启动各个子服务项（大部分形态都是线程，有些是其他的初始化，如taskScheduler） 在startTracker中调用其构造函数，在构造函数中对其中重要的属性根据配置进行初始化。()个人感觉再构造中设置scheduler，在statTracker调用构造的下一句有给Scheduler传JobTracker的引用，有点不自然) 在offerService()中启动taskSchedulerexpireTrackersThread retireJobsThread expireLaunchingTaskThread completedJobsStoreThread interTrackerServer等几个线程来共同完成服务。同时调用TaskScheduler的start方法进行初始化。 在FairScheduler调度器的start方法中调用EagerTaskInitializationListenerr的start方法来初始化EagerTaskInitializationListener 在FairScheduler调度器的start方法中调用DefaultTaskSelector的start方法来初始化DefaultTaskSelector，因为该类实现的TaskSelector太简单，start方法里也没有做任何事情。 JobTracker等相关功能模块初始化
三、 代码详述
1. JobTracker 的入口main函数。主要是实例化一个JobTracker类，然后调用offerService方法做事情。
在Jobtracker的main函数中去掉记日志和异常捕获外关键代码就一下两行。
1 JobTracker tracker = startTracker(new JobConf()); 2 tracker.offerService(); 2. JobTracker 的startTracker方法。 调用JobTracker的构造函数，完成初始化工作。
1JobTracker result = null; 2 while (true) { 3 try { 4 result = new JobTracker(conf); 5 result.taskScheduler.setTaskTrackerManager(result); 6 Thread.sleep(1000); 7 } 8 9 JobEndNotifier.startNotifier(); 10 return result; 3. JobTracker的构造方法JobTracker(JobConf conf)。是一个有两三屏的长的方法。值得关注下，当然jobtracker服务运维的有些部分会适当忽略，着重看处理作业的部分。(其实这样的说法也 不太对，Jobtracker的主要甚至是唯一的作用就是处理提交的job)
主要的工作有：
1)创建一个初始化一个队列管理器，一个HadoopMapReduce作业可以配置一个或者多个Queue，依赖于其使用的作业调度器Scheduler 2)根据配置创建一个调度器 3)创建一个RPC Server,其中handlerCount是RPC server服务端处理请求的Handler线程的数量，默认是10。详细机制参照RPC机制描述。 4)创建一个创建一个HttpServer，用于JobTracker的信息发布。 5)创建一个RecoveryManager，用于JobTracker重启时候恢复 6)创建一个CompletedJobStatusStore，用户持久化作业状态。
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】Hadoop作业提交之客户端作业提交</title>
      <link>https://idouba.com/hadoop_jobclient_submit/</link>
      <pubDate>Thu, 16 Jan 2014 14:54:46 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_jobclient_submit/</guid>
      <description>
        
          
            一、概要描述
仅仅描述向Hadoop提交作业的第一步，即调用Jobclient的submitJob方法，向Hadoop提交作业。
二、 流程描述
Jobclient使用内置的JobSubmissionProtocol 实例jobSubmitClient 和JobTracker交互，最主要是提交作业、获取作业执行信息等。
在JobClient中作业提交的主要过程如下：
1）通过调用JobTracker的getNewJobId()向jobtracker请求一个新的作业ID 2）获取job的jar、输入分片、作业描述等几个路径信息，以jobId命名。 3）其中getSystemDir()是返回jobtracker的系统目录，来放置job相关的文件。包括：mapreduce的jar文件submitJarFile、分片文件submitSplitFile、作业描述文件submitJobFile 4）检查作业的输出说明，如果没有指定输出目录或输出目录以及存在，则作业不提交。参照org.apache.hadoop.mapreduce.lib.output.FileOutputFormat的checkOutputSpecs方法。如果没有指定，则抛出InvalidJobConfException，文件已经存在则抛出FileAlreadyExistsException 5）计算作业的输入分片。通过InputFormat的getSplits(job)方法获得作业的split并将split序列化封装为RawSplit。返回split数目，也即代表有多个分片有多少个map。详细参见InputFormat获取Split的方法。 6）writeNewSplits 方法把输入分片写到JobTracker的job目录下。 7）将运行作业所需的资源（包括作业jar文件，配置文件和计算所得的输入分片）复制到jobtracker的文件系统中一个以作业ID命名的目录下。 8）使用句柄JobSubmissionProtocol通过RPC远程调用的submitJob()方法，向JobTracker提交作业。JobTracker作业放入到内存队列中，由作业调度器进行调度。并初始化作业实例。JobTracker创建job成功后会给JobClient传回一个JobStatus对象 用于记录job的状态信息，如执行时间、Map和Reduce任务完成的比例等。JobClient会根据这个JobStatus对象创建一个 NetworkedJob的RunningJob对象，用于定时从JobTracker获得执行过程的统计数据来监控并打印到用户的控制台。
三、代码详细
Jobclient ：JobClient是向JobTracker提交作业的接口，可以理解为Hadoop的Mapreduce作业框架向用户开放的作业提交入口。可以提交作业，监视作业状态等
JobSubmissionProtocol（为什么0.20.1的javadoc中找不到这个接口，虽然0.20.1 0.20.2代码中都是相同的用法，知道2.2.0貌似重命名为被ClientProtocol替换）：JobClient和JobTracker进行通信的一个协议。JobClient实际上是用这个句柄来提交锁业并且监视作业的执行状况。
这个接口有两个实现：LocalJobRunner(conf)当mapred-site.xml中的mapred.job.tracker值为local是为此对象。表示在单机上执行；如果为一个地址的话则是 JobTracker的对象，表示分布式执 行。
详细可参照JobClient中 的初始化代码：
1 /** 2 *如果是非local的就会 连接到指定的JobTracker 3 */ 4 public void init(JobConf conf) throws IOException { 5 String tracker = conf.get(&amp;#34;mapred.job.tracker&amp;#34;, &amp;#34;local&amp;#34;); 6 if (&amp;#34;local&amp;#34;.equals(tracker)) { 7 this.jobSubmitClient = new LocalJobRunner(conf); 8 } else { 9 this.jobSubmitClient = createRPCProxy(JobTracker.getAddress(conf), conf); 10 } 11 } 12 13 /* 14 * RPC不是本次主题重点，可参照后续发表的专题内容 15 */ 16 private JobSubmissionProtocol createRPCProxy(InetSocketAddress addr, 17 Configuration conf) throws IOException { 18 return (JobSubmissionProtocol) RPC.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】hadoop作业提交之JobTracker接收作业提交</title>
      <link>https://idouba.com/hadoop_mapreduce_jobadded/</link>
      <pubDate>Thu, 16 Jan 2014 13:39:25 +0000</pubDate>
      
      <guid>https://idouba.com/hadoop_mapreduce_jobadded/</guid>
      <description>
        
          
            一、概要描述
在上一篇博文中主要描述了JobTracker接收作业的几个服务（或功能）模块的初始化过程。本节将介绍这些服务（或功能）是如何接收到提交的job。本来作业的初始化也可以在本节内描述，但是涉及到JobInProgress的初始化过程放在一张图上太拥挤，就分开到下一篇文章中描述。
二、 流程描述
JobClient通过RPC的方式向JobTracker提交作业； 调用JobTracker的submitJob方法。该方法是JobTracker向外提供的供调用的提交作业的接口。 submit方法中调用JobTracker的addJob方法。 在addJob方法中会把作业加入到集合中供调度，并会触发注册的JobInProgressListener的jobAdded事件。由上篇博文的jobtracker相关服务和功能的初始化的FairScheduler的start方法中看到，这里注册的是两个JobInProgressListener。分别是FairScheduler的内部类JobListener和EagerTaskInitializationListener。 FairScheduler的内部类JobListener响应jobAdded事件事件。只是为每个加入的Job创建一个用于FairScheduler调度用的JobInfo对象，并将其和job的对应的存储在Map&amp;lt;JobInProgress, JobInfo&amp;gt; infos集合中。 EagerTaskInitializationListener响应jobAdded事件事件。jobAdded 只是简单的把job加入到一个List类型的 jobInitQueue中。并不直接对其进行初始化，对其中的job的处理由另外线程JobInitManager来做。该线程，一直检查 jobInitQueue是否有作业，有则拿出来从线程池中取一个线程InitJob处理。关于作业的初始化过程专门在下一篇文章中介绍。 JobTracker接收作业提交
三、代码详细
1. JobClient的submitJob方法，调用submitJobInternal方法。
主要流程：
1）通过调用JobTracker的getNewJobId()向jobtracker请求一个新的作业ID
2）获取job的jar、输入分片、作业描述等几个路径信息，以jobId命名。
3）其中getSystemDir()是返回jobtracker的系统目录，来放置job相关的文件。包括：mapreduce的jar文件submitJarFile、分片文件submitSplitFile、作业描述文件submitJobFile
4）检查作业的输出说明，如果没有指定输出目录或输出目录以及存在，则作业不提交。参照org.apache.hadoop.mapreduce.lib.output.FileOutputFormat的checkOutputSpecs方法。如果没有指定，则抛出InvalidJobConfException，文件已经存在则抛出FileAlreadyExistsException
5）计算作业的输入分片。通过InputFormat的getSplits(job)方法获得作业的split并将split序列化封装为RawSplit。返回split数目，也即代表有多个分片有多少个map。详细参见InputFormat获取Split的方法。
6）writeNewSplits 方法把输入分片写到JobTracker的job目录下。
7）将运行作业所需的资源（包括作业jar文件，配置文件和计算所得的输入分片）复制到jobtracker的文件系统中一个以作业ID命名的目录下。
8） 使用句柄JobSubmissionProtocol通过RPC远程调用的submitJob()方法，向JobTracker提交作业。 JobTracker作业放入到内存队列中，由作业调度器进行调度。并初始化作业实例。JobTracker创建job成功后会给JobClient传回 一个JobStatus对象用于记录job的状态信息，如执行时间、Map和Reduce任务完成的比例等。JobClient会根据这个 JobStatus对象创建一个 NetworkedJob的RunningJob对象，用于定时从JobTracker获得执行过程的统计数据来监控并打印到用户的控制台。
1 public RunningJob submitJobInternal(JobConf job) 2 throws FileNotFoundException, ClassNotFoundException, 3 InterruptedException, IOException { 4 5 // 1）通过调用JobTracker的getNewJobId()向jobtracker请求一个新的作业ID 6 JobID jobId = jobSubmitClient.getNewJobId(); 7 // 2）获取job的jar、输入分片、作业描述等几个路径信息，以jobId命名。 8 // 3）其中getSystemDir()是返回jobtracker的系统目录，来放置job相关的文件。包括：mapreduce的jar文件submitJarFile、分片文件submitSplitFile、作业描述文件submitJobFile 9 10 Path submitJobDir = new Path(getSystemDir(), jobId.toString()); 11 Path submitJarFile = new Path(submitJobDir, &amp;#34;job.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】Hadoop作业提交中EagerTaskInitializationListener的作用</title>
      <link>https://idouba.com/eagertaskinitializationlistener/</link>
      <pubDate>Wed, 15 Jan 2014 14:05:42 +0000</pubDate>
      
      <guid>https://idouba.com/eagertaskinitializationlistener/</guid>
      <description>
        
          
            一、概述
继承自JobInProgressListener，实现了jobAdded，jobRemoved，jobUpdated方法。哦，不能说实现，应该说继承，JobInProgressListener居然是个抽象类，看着怎么这样的listener也应该是个interface。
在该listener被注册后，就响应jobAdded，jobRemoved，jobUpdated动作。在EagerTaskInitializationListener中，响应这三种动作来维护内部的一个job列表（List jobInitQueue），并启动线程对job列表中的job异步的进行初始化。
二、主要代码逻辑
在job被添加到JobTracker时，注册的Lister会响应该方法。即当有作业提交到JobTracker时，该方法会把JIP加到jobInitQueue列表中，并且根据作业优先级和启动时间来调整其顺序。 jobInitManagerThread会一直产看jobInitManagerThread列表中的job，逐一取出来初始化其task。 三、主要成员
1 private JobInitManager jobInitManager = new JobInitManager(); //一个job初始化线程，关注job队列jobInitQueue，取出进行初始化 2 private Thread jobInitManagerThread; // JobInitManager线程 3 private List&amp;lt;JobInProgress&amp;gt; jobInitQueue = new ArrayList&amp;lt;JobInProgress&amp;gt;(); //响应lister的几种方法，维护的job队列 4 private ExecutorService threadPool; //一个线程池，里面的一个线程取一个job进行初始化 5 private int numThreads; //线程池的线程数，可配置 四、主要方法
1. EagerTaskInitializationListener的jobAdded方法：
首先关注的代码片段是该listener的jobAdded方法，前面说过，在FairScheduler的start方法中（taskTrackerManager.addJobInProgressListener(eagerInitListener)）会把EagerTaskInitializationListener注册到JobTracker，在jobTracker中加入job的时候（addJob被调用），触发其上所有的jobListener的jobAdded方法。
在EagerTaskInitializationListener中，jobAdded只是简单的把job加入到一个List类型的 jobInitQueue中。并不直接对其进行初始化，对其中的job的处理由另外线程来做。
1@Override 2 public void jobAdded(JobInProgress job) { 3 synchronized (jobInitQueue) { 4 jobInitQueue.add(job); 5 resortInitQueue(); 6 jobInitQueue.notifyAll(); 7 } 8 9 } 2. JobInitManager类：
          
          
        
      </description>
    </item>
    
    <item>
      <title>【hadoop代码笔记】通过JobClient对Jobtracker的调用详细了解Hadoop RPC</title>
      <link>https://idouba.com/haddoop_rpc_jobclient_jobtracker/</link>
      <pubDate>Sat, 11 Jan 2014 12:02:36 +0000</pubDate>
      
      <guid>https://idouba.com/haddoop_rpc_jobclient_jobtracker/</guid>
      <description>
        
          
            Hadoop的各个服务间，客户端和服务间的交互采用RPC方式。关于这种机制介绍的资源很多，也不难理解，这里不做背景介绍。只是尝试从Jobclient向JobTracker提交作业这个最简单的客户端服务器交互的代码中，去跟踪和了解下RPC是怎么被使用的。不同于准备发表博客时搜索的几篇博文，试图通过一种具体的场景来介绍，属于比较初级。其他DataNode和Namenode之间，Tasktracker和JobTracker之间的交互基本也都一样。为了引用的代码篇幅尽可能少，忽略了代码中写日志（包括Metrics）、某些判断等辅助代码。
1 RPC客户端请求（从JobClient的jobSubmitClient 入手） Jobclient包含一个JobSubmissionProtocol jobSubmitClient类型的句柄，从作业提交一节的介绍中看到Jobclient的计划所有重要操作都是通过jobSubmitClient来完成的。包括
JobSubmissionProtocol Outline
所有这些方法都在JobSubmissionProtocol接口中定义。在0.20.1的时候已经到Version 20了，在2.2.0好像到了Version 40了,说明功能一直在增强。 客户端的某个方法调用如何会调用到服务端的方法呢？在客户端机器上调用JobClient的getAllJobs(),怎么调用到了服务端JobTracker的getAllJobs()。这也是我尝试讲明白的核心内容。为了体现代码的一步一步分析总结在最后。可能循序渐进的作用没起到，还会笔记读起来笔记乱，感受有点不太好可能:-(。 首先看客户端JobClient中的jobSubmitClient初始化方法。在JobClient的init方法中判断不是local的方式则会调用createRPCProxy方法，进而调用RPC的getProxy方法。方法连接对应IP的服务器。比较客户端和服务端的RPC版本一致，返回一个JobSubmissionProtocol类型的句柄，抛出VersionMismatch异常。
1private JobSubmissionProtocol createRPCProxy(InetSocketAddress addr, 2 Configuration conf) throws IOException { 3 return (JobSubmissionProtocol) RPC.getProxy(JobSubmissionProtocol.class, 4 JobSubmissionProtocol.versionID, addr, getUGI(conf), conf, 5 NetUtils.getSocketFactory(conf, JobSubmissionProtocol.class)); 6 } 7 public static VersionedProtocol getProxy(Class&amp;lt; &amp;gt; protocol, 8 long clientVersion, InetSocketAddress addr, UserGroupInformation ticket, 9 Configuration conf, SocketFactory factory) throws IOException { 10 11 VersionedProtocol proxy = 12 (VersionedProtocol) Proxy.newProxyInstance( 13 protocol.getClassLoader(), new Class[] { protocol }, 14 new Invoker(addr, ticket, conf, factory)); 15 long serverVersion = proxy.
          
          
        
      </description>
    </item>
    
    <item>
      <title>【译】数据库事务隔离级别</title>
      <link>https://idouba.com/wikipedia_isolation/</link>
      <pubDate>Sun, 05 Jan 2014 12:23:26 +0000</pubDate>
      
      <guid>https://idouba.com/wikipedia_isolation/</guid>
      <description>
        
          
            看到wikipedia中文关于数据库相关的几个经典条目有点老旧，尤其和英文条目相比。确定开始翻译其中几篇，先从事务隔离等级开始。格式采用维基Sandbox发布后的格式。翻译完后自己校对过几遍，质量还可以。:-)
已经在中文维基发布。
翻译的中文条目地址：事务隔离等级；
对应的英文条目地址：Isolation (database systems)
欢迎大家指正，可以直接在维基上对应条目更新的！。
事务隔离（isolation）定义了数据库系统中一个操作产生的影响什么时候以哪种方式可以对其他并发操作可见。隔离是事务ACID (原子性、一致性性、隔离性、持久性)四大属性中的一个重要属性。
并发控制(Concurrency control) 并发控制描述了数据库处理隔离以保证数据正确性的机制。为了保证并行事务执行的准确执行数据库和存储引擎在设计的时候着重强调了这一点。典型的事务相关机制限制数据的访问顺序(执行调度)以满足可序列化 和可恢复性。限制数据访问意味着降低了执行的性能，并发控制机制就是要保证在满足这些限制的前提下提供尽可能高的性能。经常在不损害正确性的情况下，为了达到更好的性能，可序列化的的要求会减低一些，但是为了避免数据一致性的破坏，可恢复性必须保证。
两阶段锁是关系数据库中最常见的提供了可序列化 和可恢复性的并发控制机制，为了访问一个数据库对象，事务首先要获得这个对象的 锁。对于不同的访问类型（如对对象的读写操作）和锁的类型，如果另外一个事务正持有这个对象的锁，获得锁的过程会被阻塞或者延迟。
隔离级别(Isolation levels) 在数据库事务的ACID四个属性中，隔离性是一个最常放松的一个。为了获取更高的隔离等级，数据库系统的 锁机制或者多版本并发控制机制都会影响并发。 应用软件也需要额外的逻辑来使其正常工作。
很多DBMS定义了不同的“事务隔离等级”来控制锁的程度。在很多数据库系统中，多数的数据库事务都避免高等级的隔离等级（如可序列化）从而减少对系统的锁定开销。程序员需要小心的分析数据库访问部分的代码来保证隔离级别的降低不会造成难以发现的代码bug。相反的，更高的隔离级别会增加死锁发生的几率，同样需要编程过程中去避免。
ANSI/ISO SQL定义的标准隔离级别如下。
可序列化(Serializable) 最高的隔离级别。
在基于锁机制并发控制的DBMS实现可序列化要求在选定对象上的读锁和写锁保持直到事务结束后才能释放。在SELECT 的查询中使用一个“WHERE”子句来描述一个范围时应该获得一个“范围锁(range-locks)”。这种机制可以避免“幻影读(phantom reads)”现象。
当采用不基于锁的并发控制时不用获取锁。但当系统探测到几个并发事务有“写冲突”的时候，只有其中一个是允许提交的。这种机制的详细描述见“’快照隔离”
可重复读(Repeatable reads) 在可重复读(REPEATABLE READS)隔离级别中，基于锁机制并发控制的DBMS需要对选定对象的读锁(read locks)和写锁(write locks)一直保持到事务结束，但不要求“范围锁(range-locks)”，因此可能会发生“幻影读(phantom reads)”
授权读(Read committed) 在授权读(READ COMMITTED)级别中，基于锁机制并发控制的DBMS需要对选定对象的写锁(write locks)一直保持到事务结束，但是读锁(read locks)在SELECT操作完成后马上释放（因此“不可重复读”现象可能会发生，见下面描述）。和前一种隔离级别一样，也不要求“范围锁(range-locks)”。
简而言之，授权读这种隔离级别保证了读到的任何数据都是提交的数据，避免读到中间的未提交的数据，脏读(dirty reads)。但是不保证事务重新读的时候能读到相同的数据，因为在每次数据读完之后其他事务可以修改刚才读到的数据。
未授权读(Read uncommitted) 未授权读(READ UNCOMMITTED)是最低的隔离级别。允许_脏读(dirty reads)_，事务可以看到其他事务“尚未提交”的修改。
通过比低一级的隔离级别要求更多的限制，高一级的级别提供更强的隔离性。标准允许事务运行在更强的事务隔离级别上。(如在可重复读(REPEATABLE READS)隔离级别上执行授权读(READ COMMITTED)的事务是没有问题的)
默认隔离级别 不同的DBMS默认隔离级别也不同。多少数据库允许用户设置隔离级别。有些DBMS在执行一个SELECT语句时使用额外的语法来获取锁(如_SELECT … FOR UPDATE_来获得在访问的数据行上的排他锁)
读现象(Read phenomena) ANSI/ISO 标准SQL 92涉及三种不同的一个事务读取另外一个事务可能修改的数据的“读现象”。
下面的例子中，两个事务，事务1执行语句1。接着，事务2执行语句2并且提交，最后事务1再执行语句1. 查询使用如下的数据表。
id name age 1 Joe 20 2 Jill 25 脏读(Dirty reads (Uncommitted Dependency)) 当一个事务允许读取另外一个事务修改但未提交的数据时，就可能发生脏读(dirty reads)。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Data Mining 笔记聚类k-medoids</title>
      <link>https://idouba.com/notes-clustering-k-medoids/</link>
      <pubDate>Wed, 18 Sep 2013 13:28:36 +0000</pubDate>
      
      <guid>https://idouba.com/notes-clustering-k-medoids/</guid>
      <description>
        
          
            一、概述 k-means利用簇内点的均值或加权平均值ci（质心）作为类Ci的代表点。对数值属性数据有较好的几何和统计意义。对孤立点是敏感的，如果具有极大值，就可能大幅度地扭曲数据的分布.
k-medoids(k-中心点)算法是为消除这种敏感性提出的，它选择类中位置最接近类中心的对象(称为中心点)作为类的代表点，目标函数仍然可以采用平方误差准则。
PAM（Partitioning Around Medoids，围绕中心点的划分）是最早提出的k中心点算法之一。
二、算法思想： 随机选择k个对象作为初始的k个类的代表点，将其余对象按与代表点对象的距离分配到最近的类；反复用非代表点来代替代表点，以改进聚类质量。 即：算法将判定是否存在一个对象可以取代已存在的一个中心点。
通过检验所有的中心点与非中心点组成的对，算法将选择最能提高聚类效果的对，其中成员总是被分配到与中心点距离最短的类中。 假设类Ki 的当前中心点是Oi , 希望确定Oi是否应与非中心点Oh交换.如果交换可以改善聚类的效果，则进行交换。 距离代价的变化是指所有对象到其类中心点的距离之和的变化，这里使用Cjih表示中心点Oi与非中心点Oh交换后，对象Oj到中心点距离代价的变化。
总代价定义如下：
三、算法描述： 输入： 簇的数目k和包含n个对象的数据库。
输出： k个簇的集合
方法： 1任意选择k个对象作为初始的代表对象（簇中心点） 2repeat 3将每个剩余对象指派到最近的代表对象所代表的簇 4随机地选择一个非代表对象Orandom 5计算用Orandom交换代表对象Oi的总代价S 6if S &amp;lt; 0，then用Orandom替换Oi ，形成新的k个代表对象的集合 7UNTIL不发生变化 四、算法实例 样本点 A B C D E A 1 2 2 3 B 1 2 4 3 C 2 2 1 5 D 2 4 1 3 E 3 3 5 3 第一步 建立阶段： 假如从5个对象中随机抽取的2个中心点为{A，B},则样本被划分为{A、C、D}和{B、E}
第二步 交换阶段： 假定中心点A、B分别被非中心点C、D、E替换，根据PAM算法需要计算下列代价TC(AC)、 TC(AD)、 TC(AE)、TC(BC)、TC(BD)、 TC(BE)。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Data Mining 笔记之Classification</title>
      <link>https://idouba.com/notes-about-classification/</link>
      <pubDate>Wed, 18 Sep 2013 11:12:40 +0000</pubDate>
      
      <guid>https://idouba.com/notes-about-classification/</guid>
      <description>
        
          
            一、概念 监督式学习VS非监督式学习 Supervised learning (classification): The training data (observations, measurements, etc.) are accompanied by labels indicating the class of the observations. New data is classified based on the training set.
Unsupervised learning (clustering):The class labels of training data is unknown Given a set of measurements, observations, etc. with the aim of establishing the existence of classes or clusters in the data –Jiawei Han
监督式学习：提供了训练元组的类标号，通过分析已知数据，得到一个分类模型，用来确定其它的对象属于哪个类别。
非监督式学习：不依赖有类标号的训练实例
分类Classification predicts categorical class labels (discrete or nominal), classifies data (constructs a model) based on the training set and the values (class labels) in a classifying attribute and uses it in classifying new data。
          
          
        
      </description>
    </item>
    
    <item>
      <title>A Program demonstrating Gini Index Classification</title>
      <link>https://idouba.com/classfication-giniindex-program/</link>
      <pubDate>Wed, 03 Jul 2013 15:50:08 +0000</pubDate>
      
      <guid>https://idouba.com/classfication-giniindex-program/</guid>
      <description>
        
          
            无意发现研究生时候数据挖掘课程关于基于Gini Index的一个Classification的实验报告，还算完整。基于尚老师给的数据集完整完成了模型设计、训练和验证。还用Java写了个简单界面，能导入数据集训练，并画出决策树，并能导入数据集验证，评价准确性。
A Program demonstrating Gini Index Classification Abstract In this document, a small program demonstrating Gini Index Classification is introduced. Users can select specified training data set, build the decision tree, and then select independent testing data set to verify the accuracy of model. Furthermore, by providing the decision tree visualization (Using JTree of Java), the pattern recognition capacities of users can be greatly improved.When estimating classifier accuracy, the known class label is compared with the learned model’s class prediction for that sample, the conflict records will be filtered to show user what the record’s class label is and what the mined model tells you the result is supposed should be.
          
          
        
      </description>
    </item>
    
    <item>
      <title>给某某导师的一封邮件</title>
      <link>https://idouba.com/history-letter-to-someone-mentor-so-called/</link>
      <pubDate>Sat, 08 Jun 2013 14:22:52 +0000</pubDate>
      
      <guid>https://idouba.com/history-letter-to-someone-mentor-so-called/</guid>
      <description>
        
          
            整理之前常用的网易邮箱的时候，发现几篇比较长的邮件，感受到了当年的年轻气盛，被自己小激励了一把。当年觉得很私密的邮件，现在倒愿意在自己的空间归档下,不然可能就真的扔掉了。是研究生入学前给当年向某位知名人生导师写的邮件，并未得到回复:-(。看到邮件里描述自己的还挺可爱的，虽然使劲回忆起来有些太心酸太囧的经历没有好意思写进去。但是有的啰嗦，怪不得人家不回呢，呵呵。好像更像是自己和自己说话。有热情，有干劲，但是似乎有一点偏执。现在回头看。豆妈说一定不要让我们豆豆也这么辛苦。很感激当年的这些经历，也不太愿意掖着藏着。倒是现在的自己有些地方需要重新拾起来一点当年的热情。
XX 老师您好：
问候您，希望不会很冒昧。
“要做就做到最好，做到山穷水尽”，我是在一个免费的考研讲座前的一个宣传片里听到这句话的，其实应该也是因此而认识您的，准确的讲应该说 是愿意去认识您的，想着去了解和认识这个人（那个人是您吗？我身边的人讲是***，要是错了的话，就很尴尬啦）。然后居然搜到了，这样可以找到您。
我想，您讲的我也是完全这样认同的，一直也是要求自己这样去做的。可能作的不够好。但我有一个疑问，这样做就够了吗？
还没有自报家门，太不礼貌了。我叫***。**陕西人，**年生，应该是很大了。有些事还总是问别人，应该是比较惭愧了。
“我没有上过大学，但我从没有放弃过学习。我现在不会，但我可以很快学会。”这是我找到最后一份工作时，在一页纸的简历上自我介绍的一部分。也许是我有胆量递上简历的时候是人才市场要散场，招聘的老师急着去吃饭，或许是他对我这个最简陋的简历好奇，在口头考了我几个问题后，给了我后面的复试和面试的机会，我也 得到了当时作为门外汉认为的很有意义也很有挑战的软件这份工作。后来这个老师也就成了我的上司，在后面我辞职时他给我的辞职报告书的回信中说，在他应聘桌 前第一眼看到我时，就认为我是一个执着刻苦的人。谢谢李老师。后面的工作我应该没有太令他失望，他也一直给我支持和鼓励。
好了，本来只是介绍我没有上过大学，怎么扯到找工作上了，不好意思。开始吧，我应该是属于那种比较爱学习的吧。现在的我已经不再像三年前那样觉得小时侯被人 这样承认是一件很讽刺很丢人的事情，当然也不认为这就是一件完全很好的事情。是的，从村里的学前班开始到乡里的初中，不管是一级学生是村里的十几个人，还 是乡里初中的四五百人，考试时，我很少接受把第一给被别人的情况。就像现在的穆里尼奥的切尔西（那时候是穆里尼奥的切尔西一代，比现在要强盛、性感！）一 样，我觉得自己做的很稳健。但却仅仅是在考试上，其他的，我感到自己就像个傻子一样，小时这样认为，现在还是这样认为。
所以，当初中毕业时考上了中专，我就很光荣的去了，我们初中只有第一二名才过线可以上的。包里还装着我的奥数的书和很多的憧憬。也很有意思，去另外一个城市报名的路上，半夜，临时停车，包被人从车窗外拽走了。一堆精攒的好书就这样没了，爸爸说可惜是个新包，不过幸好通知书不在里面，我却心痛极了。
这可能也是我后面四年的基调，失落，空虚。我学的是机械维修，就是修车床，一些机加工之类的。本应该是可以学到一些东西的，可能是因为发现这儿讲的英语比初中的还简单，好多课程与自己想象中的完全是两回事，还有与想象中完全不一样的氛围，尽管很容易可以考个好成绩，拿到奖学金，但我从来没有用心投入其中。现在想想，当时确实可以做一些事情。
就这样，我的15-19岁就这样过来了，毕业后，我们省的都被分配到铁一局，在工地管工程机械和仓库。工程单位是没有周末的，下大雨等天气影响工地不能干活的时候是我们休息的时候。其实我挺喜欢那样的工作的。有一次，替一个大学生的同事搬床时，他的一本要扔的大学英语单词书被我捡了，当时也没想为什么，后来的大半年里，在我用的帐本上，把那书抄了一遍。我给自己开了个头，我居然对这些东西有感情了。过年回家，把弟弟高中的语法书，就是为了高考编的那样的较综合的那种，分单元的，看了一遍，居然都可以看的懂。
在东北呆了两年多，那个桥修完了，我们也各自回家了，有活再召集。这也是我们的工作方式。一起长大的村里的好朋友，这时候已经上大学了。一番谈话，建议我把学习捡起来，他促使我下 决心了。（应该比较准确这样说，因为我也曾想过）。一个在外面上班的人一直呆在家里是很丢人的。过年后一个月，我就到县城的阿姨家，给她家上学的小学的弟弟和在高中上学的弟弟做饭，然后就是去西安，好朋友那里，了解能不能找一个学校。从五月中旬到六月中旬，记得很清楚，我开始读好朋友俊卫给我买的大学英语1-4册和一本牛津词典（4 元4+25元1，都是旧书）。第一天，我看了第一课A，B只看了一点，但是在晚上睡觉前，我还是认为都看过一遍，也都看懂了，可以安心的睡了。后面的 每一天，把单词记在小本上，后面的练习，会做不会做的都填上了，看图作文也蒙人似的写几句。我坚持下来了，三十天，不间断的，大学英语精度三本书就这样囫囵吞枣地硬灌进去了，或许这是我后面英语的基础，或许是全部。因为第四册，我只是在一年才翻了一遍，而后来买的五六册，现在只是当枕头用着了。我很怀念那一个月，也很感激那一个月，专注地只做一件事，原来屁股真的 可以坐破，坐的流血，可能也是阿姨家的木凳子太硬了吧。
在那个暑假，就是好朋友俊卫他们学校放假的时候，他骑自行 车带者我在西安各个学校里打听哪个成教之类的地方可以要我。当时对西安不太熟悉，也不知道方位，但像体育场这样路过的大点的地方还是记住了，也成 为记忆中很有感情的一部分，俊卫在一路上鼓励我的话也随着那个地方而在我的记忆中占据一定的位置。
最终在西安开始了直到现在为止的另一种生活。租最便宜的房子，月租79元。白天找个事情做，晚上回来看书。但不得不羞愧的讲，开始的半年，我是没有能够实 现自己的那种半工半读的生活，因为我找不到工作。好在，靠着当时修铁路工地上班时有点积蓄和最低的生活成本，我活下来了。
02 年4月，我报了《计算机通信工程》本科的自学考试，算上要求加考的共19门课，03年10月，我完成了。其中四门以上都是纯数学的东西，我想我是啃过来 的,第一二遍是一点不懂的。02 年中和末我完成了CET4和CET6，可能对于普通学生来说这是再正常不过的事情了，可是还是让我很兴奋，用俊卫的话讲，是收获了应有的自信。在这段时间结束了自学的本科课程，也拿到了学位。计算机和通讯的课程虽然高分完成了考试和毕业，但是基础东西理解还是有限，就开始了另外一种方式的学习。
当时工作是跑业务给饭店美容院这些地方推销卡片，经常报完到，上午出门，在解放路的图书大厦泡大半天，从这本书了解到这个，看不懂，再去看另外的书，这本书讲到这个，就去这方面的详细介绍的书中去找，后来发现，这方面的那一片的书都被翻过了。 但是还一样没有太多实际的操作，只是停留在知道，或是一点的深入了解。后面的工作中还是从这段积蓄中受益非浅，也很感激自己那样不懂却硬着头皮纸上谈兵的 精神。到现在，有了实践和一点经验了，却没有热情去把理论再升华一下了。在书店里不让抄书，没法用笔做笔记，有些东西就用手机存成短信，回来再整理到纸 上。有时无意中看到电话里的已存短信，还挺佩服这些小聪明。尽管可以被算做不认真上班，可我的业绩还是几个同事中最好的，因为我愿意多跑，而且每天在书城 呆的时间总是在一个限度内。后来辞职走时，领导给我的电话里多交了100块钱的话费，说是给我工作的一个奖励吧，当时的工资是500块。
应该是一个很偶然的机会，我撞进了软件公司。其实很正常，和从前修桥比没有什么不一样。都是干工程，好多理论好像也很像。过程的、质量的、进度的、组织的。但是作为梦想中追逐的东西还是很激动的。我租房子的隔壁是个在校外住的大学生，他毕业找工作，说参加西安软件园的一个招聘会，临时就拉我做伴。几分钟写了一个自我介绍放在U盘里，没有打印，因为也没想到会用上。在中午散场人都走的差不多的时候，磨磨唧唧羞羞答答终于有勇气把刚打印的还热着的一份递给了李老师，他给了我机会。
工作很忙，正好那一年，我们组平均都要加班到10点，工作氛围，习惯与以前的单位都很不一样，我们组是在日本的公司里办公，做事的方式和思路还是有些新的体会和收获，实实在在的有收获的。尽管一直或者说永远我不会对日本人有好印象。
七月进公司，第二年的四月，我给李老师的邮箱递交了辞职报告，我想考研。领导们说，像我的工作热情和学习能力，不用考研一样可做的很好，同时也告诉我以我的基础，难度应该很大，鼓励我做一个长远的计划和大打算。其实，我心里也很没有底，可我还是有一点认识，就是开始一件事情而中途放弃比撞的头破血流后失败更失败。我不允许有这样一个先例，然后养成这样一个习惯。因为任何事情，退一步，退回来，总是很容易，很舒服，至少当时会是。我其实也开始考虑了，不用交违约金，不用改变好不容易得来的还算舒适体面的工作现状。
但我还是决定要走，不想有个这样一个退缩的记录，即使定位为战略撤退也不行。但我的心里真的没底，其中的几门数学课，有一门线性代数从来没有学过，另外两门高数和概率统计简单看过，但是很浅的，只是应付自学考试这样的简单考试。专业课，我还不清楚报哪个学校，当然也不知道，大部分是没有学过的，政治，好几门，哲学这些连内容是什么也不知道。英语，我的那些土办法学 出来的能应付吗？而且，还荒芜了很长时间了。总之，所有的东西，很多还没有概念。不过最要紧的恐怕是时间了，我的安排是最晚五月开始，可八月了我还在公 司，别人是复习，我是全新学习，我的定位只能是今年为明年做一些准备了，把数学学完，巩固到要求的程度。考完再找工作，到明年这时再辞职，重新来过应该比较有把握。
05年9月1日，我的辞职批准了。一个人的学习，安排进度，对效果的考察。我认为数量是比质量更好考察的一个指标。要质量，可能会在一个点上，一直停滞，反复，有最终不能完成的风险。从整体上再看质量不完整，当然质量不好了。而数量，按时间安排进度，只要数量作到了，或者是作到了压倒性的数量，质量应该是不用太担心的。而且每天只是简单的要求我要做作业1、作业2、作业3总比空洞的说我要作到 程度1、程度2、程度3来的容易。我以前各个阶段自学的过程都是这样做的，有个详尽的可量化的计划，每天作完即可，剩下的就关心不到了。
开始几本书， 第一章一点也看不懂，根本找不大能看懂的切入点。就尝试从中间部分个别能看懂的地方看，总之是把一本书看完为止，因为并不是每本书都是严格的循序渐进的、由易到难的。对于自学者，我认为很重要，只要的是先围歼，可以多看几遍，后面就相对很容易了。有种自信，发现对那些书开始有感情了，剩下的事就很容易了。每本书，读过的就记笔记，尤其是看不懂的书，可能是读的时候不够细，就一点一点记下来，越不懂，笔记可以记的越详细。先混个脸熟，培养一点感情，也是蚕食战略吧。而且复习时，看着自己整理出来的笔记总比去翻书要有效的多，自己的写的字总比印刷的字亲切。
每 天都有一个计划，复习更可操作一些，复习也更从容，只关心把当天的事情做完，而不用考虑其他，使操作更简单，不用一个人发楞，没有概念的瞎想，吓自己。9 月有一个计划到10月16号，是一个很细的计划，作的很有效率，很忙，当然都很忙，但不乱。10月下旬到11月，只有两行字的很粗计划使我的复习失控了，一个人容易发愣，时间过得很快。 要求没有达到，每天还是很辛苦，心里总是很惶恐，复习几乎成了问题。每天都会简单记下完成情况和一点心得，那卷笔记本现在找不到了，后面看过一次，体会当时的疯狂，很过瘾。 四个月的考研课程自学，用了七八十个多个油笔芯和近70作业本，时间利用的应该很充分。但对自己的程度不满意，总是重复出现前面犯的错，尽管将所有数学出错的地方都有一个checklist对照。
考试完后的感觉，比想象的最好的要差，比最差的要好。
三月，俊卫从日本给我打来过电话，我们早就约定，我只负责完成任务，剩下的他负责。409，政治82、英语82、数学116、专业课129，他告诉我，在那边狂喜，而我却在怀疑。是真的，他把成绩的那个结果页面发到我的邮箱里了，还有一堆鼓励的话，就像这些年他一直做的一样，很让人振奋的话，总结了我们一起商量的道路的每一步前进。谢谢你，我最好的朋友，我把我的这点小成绩的一半要分给你。
然后是我想到的其他的，随之想到的。（也是我最迷茫的，想到请教您的)我的成绩，我只有成绩，就像小时侯一样，好的成绩总是让人兴奋，也会有一丝成就感，但那就是全部吗？这就是我全部追求的吗？我有些迷茫，其实这个问题以前也考虑过。
很讽刺，我已经XX岁了，还没有想好自己要做什么？我在追求什么呢？我可以在一个较短的时间内把一个明确的任务作的尽可能的好，尽管可能不能想您说的作到极至。无论其中困难有多大，总会使之有个结果。
总可以不错的完成一些短期的目标，制定和实施一个短期的计划。但却我没有长远的计划，这应该是很危险的，就像一个曲线一样，在时间的坐标上总是在前进，每个短的阶段不错，但总的趋势呢？没有一个明确的目标，绕弯路，可能会走上岔路。
我是想好好利用这样一个学习的机遇，但我做好准备了吗？有些心虚。下个月就开学了。还会和我当时上中专时一样吗？我已经习惯了自己学习，也不知道学校里的学习能否适应。 看着很能学，只有初中文化，靠自学在铁路工地的账本上抄一本捡来的单词书，在亲戚家的木凳子硬坐一个月硬灌了大学英语课程，混过了英语、英语四级、六级。靠跑业务的间隙蹭图书馆，入门初步贯通了计算机相关基础。现在（算高分）公费考到了西工大计算机学院。但不知收获了什么， 难道就是那一堆毕业证破纸吗？单位要求学日语，我们就学，我挺爱学，可是我的中国鹰派情结，当然反日了，我又想学德语或法语。但是每当心里有这个“我想 学”几个字时，总是条件放射的有另一种声音，这么大了，学学，还会点别的吗？是，不应这样过了，可我挺喜欢的，我喜欢这种极致投入并有所成的感觉，其实我不是那种聪明 的人，但我愿意投入的去做一件事情，做出一个结果来。但做什么呢，总是很迷惑。没有事做会空虚，有事作完了，一点成就感，然后就失落，空虚。总是做一些看上去很美的事，也就是朋友，父母认为很对很上进的事情，这个真的就对吗？今年三月，我回到了原来的软件公司，平时上班，挺好，周六周日是我最难过的。
希望能得到您的一些指点。我相信您能给我一些帮助。算是感觉吧。我说的有些多了，只是想让您更多的了解这个人，如果耽误了您太多时间，我先表示歉意了。我已经尽可能讲的详细了，包括自己的一些想法，向您暴露思想中的一些问题。当然如果 还有些问题，我很愿意回答您。我会很珍惜这次学习的机会的。对我很重要，应该是很关键。谢谢您，谢谢您和您的同事们的工作，很佩服你们！ 好了，期盼回音。
最近有九天的假，可以拿出半天的闲暇来总结一下自己。 20060808
我的电话：*****
我的邮箱：*****
工作邮箱(即时收信的)：*****
          
          
        
      </description>
    </item>
    
    <item>
      <title>一张纸勾起的回忆</title>
      <link>https://idouba.com/doudou_history_letter_self_motivated/</link>
      <pubDate>Fri, 24 May 2013 14:08:26 +0000</pubDate>
      
      <guid>https://idouba.com/doudou_history_letter_self_motivated/</guid>
      <description>
        
          
            收拾之前的东西，不小心看到了一张纸条，是自己写给自己的。有点小感慨，记录下。
那时候刚开始工作吧，在沈阳的辽中县修桥，好像是从东北回家的路上，在北京的西单图书大厦泡了一天，买了这样一本书。当时看了，技巧倒没有得到什么，但是好像很受激励（年轻时更容易被激励吧），就下决心，真的下决心拿张破纸记下了目标，有点狂妄，当时不知道四级六级具体是啥，只知道六级比四级难，目标就写个大的。
说实话，读的那本书里面的内容已经完全不记得了，书好像也早都不在了。只是从那里面第一次听说了VOA Special English。后来就从一个还在念大学的好朋友的同学那儿拿到一个破收音机（同时还四块钱一本的从他们学校后门的旧书摊上买了四本大学英语的课本），居然收到那个台了，每天早上七点好像（那时候一直听，里面每周的bill white这些人的声音和风格都能分辨出来，到后来的standard english）现在已经时间都不记得了。唉。
和其他一些年少时候自己写的日记一样，这些纸条，一直这样收拾着。但是当时却应该是起到作用了。没有上过高中，也没有上过大学，但是确实做到了在一年里过了四级又过了六级。记得六级报名的时候是在西电的大礼堂，大清早从南郊坐教育专线过去（那时候没有google地图，只知道好像在那趟公交站的附近），队伍弯弯曲曲的把礼堂前都占满了。好像是03年吧，或者是02年，那些证现在是在抽屉最下面了，懒得去再翻一下（现在怎么这么懒呢！）。如果是02年就按时完成目标，如果是03年就delay一年。回想起来了，后来读研究生的时候NWPU里规定过了六级可以免修英语，我的因为过得太早，被拒绝免修。唉，忘了当时的政策是几年之内可以免修了。得，也推算不出来。
本来只是想拿之前的一点小回忆激励现在懒惰的自己一把，激励没有达到，只是更衬托自己的懒惰了！
豆豆已经一岁了，妈妈有时候会给你讲爸爸原来多么厉害，没有上过大学，十几岁就去工地上班修桥。后来自己为了学习辞了工作在西安跑业务卖东西，一个人考那些自学考试，考了专科又考了本科，后来混到了软件公司里，工作了一年又去考研，线性代数，高数啥也不懂，从九月辞职到元月考试的四个半月里上了个辅导班加上自己上自习还被他四百零九考了个公费，比妈妈和她的同学正经大学毕业的还要高。可爱学习了，可爱工作了。妈妈就是爸爸的研究生同学。
在这几年忙忙碌碌混混沌沌的的过每一天的时候，这样偶尔翻起点东西，让自己还是小鼓舞一下。“哦，我还行！”，尤其是豆豆最近总是崇拜的把遥控器递到爸爸手里，让爸爸帮你做些你做不到，并且你认为妈妈也做不到的事情时。爸爸必须行！和我们豆豆一起加油，一起还要成长！
爸爸不喜欢豆豆过得和爸爸之前一样辛苦。但是爸爸必须再努力一点。爸爸喜欢并且享受努力的感觉，不喜欢懒散（妈妈推崇的悠哉）的感觉。同时回想起来之前总是愿意把目标写在小纸片里，后来发现居然都做到了，有些现在自己是不太敢相信的。爸爸希望自己可以有点像之前的自己，虽然妈妈说爸爸已经很努力了，在现在这个年龄，哈哈，听出来没，不是夸奖，是讽刺呀。呵呵，爸爸喜欢这样。照顾好豆豆和妈妈，花时间陪豆豆和妈妈，同时努力做事。爸爸应该更努力些。和之前一样敢想敢做！
doudou：baba baba，ni yao qu na li ya？
baba： fighting, fighting, whereever you want，with you an mum！
就写这些吧。
          
          
        
      </description>
    </item>
    
    <item>
      <title>关于idouba</title>
      <link>https://idouba.com/about/</link>
      <pubDate>Mon, 01 Oct 2012 15:32:08 +0000</pubDate>
      
      <guid>https://idouba.com/about/</guid>
      <description>
        
          
            idouba，爱豆吧！
爱着豆豆的爸爸，一个叫豆豆的小男孩的爸爸。
生在关中塬上，
居于钱江南岸。
这些十年一直在菊厂搬砖。
曾经那些年在铁一局修桥筑路，搬真的砖。
在豆哥出生时，觅得这样一处空间。
想帮豆哥记录点东西，
想记录豆哥点东西。
豆哥一天天长大，
豆爸一天天忙东（忙）西，
也没有记录下啥东西。
          
          
        
      </description>
    </item>
    
    <item>
      <title>GRE作文目录</title>
      <link>https://idouba.com/my-gre-index-issue-argument/</link>
      <pubDate>Mon, 05 May 2008 09:00:53 +0000</pubDate>
      
      <guid>https://idouba.com/my-gre-index-issue-argument/</guid>
      <description>
        
          
            [在寄托的GRE作文练习 档下。
第二次作业：（20070727） Issue 88: http://bbs.gter.net/bbs/viewthread.php?tid=710682&amp;amp;extra=page%3D1 Argument 26: http://bbs.gter.net/bbs/viewthread.php?tid=710693&amp;amp;extra=page%3D1
第三次作业：（20070728） Issue 159: http://bbs.gter.net/bbs/viewthread.php?tid=711072&amp;amp;extra=page%3D1 Argument 147: http://bbs.gter.net/bbs/viewthread.php?tid=711321&amp;amp;extra=page%3D1
第四次作业:（20070729） Issue 177:http://bbs.gter.net/bbs/viewthread.php?tid=711906&amp;amp;extra=page%3D1 Argument 17: http://bbs.gter.net/bbs/viewthread.php?tid=711910&amp;amp;extra=page%3D1
第五次作业:（20070730） Issue 59 :http://bbs.gter.net/bbs/viewthread.php?tid=712537&amp;amp;extra=page%3D2 Argument 51:http://bbs.gter.net/bbs/viewthread.php?tid=712541&amp;amp;extra=page%3D1
第六次作业:（20070731） Issue 143 : http://bbs.gter.net/bbs/viewthread.php?tid=713063&amp;amp;extra=page%3D1 Issue 43 :http://bbs.gter.net/bbs/viewthread.php?tid=713593&amp;amp;extra=page%3D1 Argument 2: http://bbs.gter.net/bbs/viewthread.php?tid=713213&amp;amp;extra=page%3D1
第七次作业:（20070801） Issue 56 : http://bbs.gter.net/bbs/thread-713667-1-1.html Argument 140: http://bbs.gter.net/bbs/thread-713668-1-1.html
第八次作业:（20070802） Issue 147 :http://bbs.gter.net/bbs/viewthread.php?tid=714625&amp;amp;extra=page%3D1 Issue 51 : http://bbs.gter.net/bbs/viewthread.php?tid=714563&amp;amp;extra=page%3D1 Argument 65: http://bbs.gter.net/bbs/viewthread.php?tid=714619&amp;amp;extra=page%3D1
第九次作业:（20070803） Issue 207 :http://bbs.gter.net/bbs/viewthread.php?tid=715128&amp;amp;extra=page%3D1 Argument 117 :http://bbs.gter.net/bbs/viewthread.php?tid=715261&amp;amp;extra=page%3D1
第十次作业:（20070804） Issue 144:http://bbs.gter.net/bbs/viewthread.php?tid=716645&amp;amp;extra=page%3D1 Argument 50：http://bbs.gter.net/bbs/viewthread.php?tid=716918&amp;amp;extra=page%3D1
          
          
        
      </description>
    </item>
    
    <item>
      <title>HAPPY BIRTHDAY, INTER</title>
      <link>https://idouba.com/happy-birthday-inter/</link>
      <pubDate>Sun, 09 Mar 2008 14:59:50 +0000</pubDate>
      
      <guid>https://idouba.com/happy-birthday-inter/</guid>
      <description>
        
          
            在国米百年诞辰的时候写给俱乐部的一封信。
从1998年开始关注追随国际米兰，注册了俱乐部会员。每个生日的前夕都会受到一个合成背后印着名字，号码是当时年龄的蓝黑间条衫。
Hi Inter, HAPPY BIRTHDAY !!!
I am an Inter fan of China, a postgraduate student of a University in the Northwest of China. I have been the fan of Inter for 12 years. Football was not as popular as it is now in China 12 years ago. I have to admit that one critical reason why I have deep feeling of Inter rather than AC Milan which was highly regarded by lots of my friends is because of Ronaldo.
          
          
        
      </description>
    </item>
    
    <item>
      <title>一次日语朝礼</title>
      <link>https://idouba.com/daily-japanese-speak-in-office-in-chinese/</link>
      <pubDate>Mon, 13 Dec 2004 13:26:10 +0000</pubDate>
      
      <guid>https://idouba.com/daily-japanese-speak-in-office-in-chinese/</guid>
      <description>
        
          
            那时候每天早上都要在办公室用日语朗读一篇文章(后来我们小组要求背诵了)，对学习日语确实有很大帮助。平时也就和合作的日本team那边的人写邮件讨论功能，开始大部分句式也都是从senior的人那儿拷贝来，替换中间的词汇来表达。包括入职才一个多月就写的几十页的功能文档，都是这么干的。每天轮流一个人来朗读一篇文章倒确实对大家的口语锻炼有挺多好处的，尽管我们这些当时年龄资历都很不够的人，一般在两周多的项目总结会上，一般也就只是听，没有说的份。做多每次会前，逐个自我介绍，用日语自我介绍下，我叫什么，负责那个模块的，请多指教云云。大组十几个人，有二十个吗？好像有二十个人。一般也就两三周轮到一次。
在第三次，还是第二次轮到我的时候，发表了这篇文章。原文来自大组的一个同事从日本出差回来组内群发的一份报告（这个邮件组没有日本人）。
发表后当天就被课长约去谈话了。规劝，警告。
TO: 李課長様（りかちょうさま）及び（および）皆様（みなさま）
先日（せんじつ）仕事（しごと）のチャンスで、有難く（ありがたく）友邦（ゆうほう）の日本国（にほんこく）へ出張（しゅっちょう）に足（あし）を運（はこ）びました。
滞在期間（たいざいきかん）がすごく短（みじ）かったですが、初めて海外出張（かいがいしゅっちょう）なので、色々と良い（いい）勉強になりました。
もちろん今は言いたい事も一杯（いっぱい）です。帰ったら、友達同士（ともだちどうし）に誘（さそ）われて、BBSに自分（じぶん）の感想（かんそう）をアップしました。
大変恐れ（たいへんおそれ）を入（い）りますが、一応（いちおう）この場（ば）を借（か）りて、日本で見たり感（かん）じたりした事を言わせて頂（いただ）きます。
一番（いちばん）気（き）になるのはやはり我々（われわれ）中国人は軽蔑（けいべつ）されるということです。
身の回り（みのまわり）の日本人は礼儀正しく（れいぎただしく）見えましたが、強国（きょうこく）なりの自慢根性（じまんこんじょう）が明（あき）らかに感（かん）じました。
彼ら（かれら）たちの目では、中国人のプログラマーはコードの編集能力（へんしゅうのうりょく）やソフトウェアの設計（せっけい）などいずれも日本人と比（くら）べて、桁（けた）が違う（ちがう）です。
でも、優（すぐ）れた中国人のスタッフが会えば、全く（まったく）見下（みさ）げるというわけはないです。
ご周知（しゅうち）の通り（とおり）、ソフトウェアの開発（かいはつ）はチームワークを強調（きょうちょう）するものですが、時にはこのチームワーク精神（せいしん）はずいぶん弱いと思われます。
特（とく）に自己中心主義（じこちゅうしんしゅぎ）と集団主義（しゅうだんしゅぎ）がぶつかってしまう時は、後者（こうしゃ）は手を上げて（あげて）悲嘆（ひたん）したケースも少（すく）なくないです。
それこそ日本のソフトウェア開発の弱（よわ）みだと認識（にんしき）されました。
なお、一ヶ月（いっかげつ）の聞いたり見たりしたことでは、我々（われわれ）中国人は先進国（せんしんこく）を学ぶ（まなぶ）べきことは山積み（やまづみ）です。
技術能力（ぎじゅつのうりょく）でも仕事（しごと）のやる気（き）でも、友邦（ゆうほう）と大きな差（さ）があります。
次回（じかい）皆様が日本で出張（しゅっちょう）に堂々（どうどう）と出（で）かけるために、頑張りましょう！
最後（さいご）に、67年前（まえ）の本日（ほんじつ）を記念（きねん）致（いた）します。
TO: 李科长 ，各位
前些天因测试工作的需要到府中出差，待了一段时间。因为是第一次出国，俨然一沟里娃进城，见了一下世面，自然也小发了些感慨。回来后便被揪住，说是为了资源共享，便于经历继承，挤上一篇感想，先。当然，也是要借此机会与大家唠一下遇到的问题。
**感受最深的是日本人其实看不起中国人。**他们表面的谦卑掩饰不住自己强国的自豪，在他们看来，中国的程序员不论是写代码的水平还是软件结构的设计能力都不如日本人，不过，他们的看不起还算不上是傲慢，只要比他们强，自然不会被小觑。
其次，软件开发是团队合作的过程，某些时候团队精神是脆弱的。当自我主义与团队精神发生摩擦时，后者自然会发出既生瑜何生亮的悲叹。这也可能就是日本软件的致命缺陷。
再次，通过一个月的观察发现，发达国家是有很多东西值得我们学习和借鉴。平均来讲，不论是技术实力还是工作精神，我们都与之有一定的差距。为了下次出差的同志挺直腰板 — 加油。
最后，纪念67年前的今天。
注：今天指九一八。
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
